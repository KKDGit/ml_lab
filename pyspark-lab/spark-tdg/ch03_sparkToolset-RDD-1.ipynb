{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/hdp/current/spark2-client')\n",
    "findspark.find()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"yarn\").appName(\"ch03SparkToolSet-RDD1\").getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://rm01.itversity.com:19288/proxy/application_1533622723243_12045\n"
     ]
    }
   ],
   "source": [
    "print(spark.conf.get('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES'))\n",
    "#Only for Yarn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://gw02.itversity.com:4045\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0.2.6.5.0-292</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ch03SparkToolSet-RDD1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x6c6beb2cb990>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data1 = spark.read.text('/user/kranthidr/samples/auto_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(value=u'18,8,307,130,3504,12,70,1'),\n",
       " Row(value=u'15,8,350,165,3693,11.5,70,1'),\n",
       " Row(value=u'18,8,318,150,3436,11,70,1'),\n",
       " Row(value=u'16,8,304,150,3433,12,70,1'),\n",
       " Row(value=u'17,8,302,140,3449,10.5,70,1')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data2 = sc.textFile('/user/kranthidr/samples/auto_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'18,8,307,130,3504,12,70,1',\n",
       " u'15,8,350,165,3693,11.5,70,1',\n",
       " u'18,8,318,150,3436,11,70,1',\n",
       " u'16,8,304,150,3433,12,70,1',\n",
       " u'17,8,302,140,3449,10.5,70,1']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Gives Error\n",
    "# TypeError: Can not infer schema for type: <class 'str'>\n",
    "\n",
    "# raw_data2DF1 = raw_data2.toDF()\n",
    "# raw_data2DF1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                   k|\n",
      "+--------------------+\n",
      "|18,8,307,130,3504...|\n",
      "|15,8,350,165,3693...|\n",
      "|18,8,318,150,3436...|\n",
      "|16,8,304,150,3433...|\n",
      "|17,8,302,140,3449...|\n",
      "|15,8,429,198,4341...|\n",
      "|14,8,454,220,4354...|\n",
      "|14,8,440,215,4312...|\n",
      "|14,8,455,225,4425...|\n",
      "|15,8,390,190,3850...|\n",
      "|15,8,383,170,3563...|\n",
      "|14,8,340,160,3609...|\n",
      "|15,8,400,150,3761...|\n",
      "|14,8,455,225,3086...|\n",
      "|24,4,113,95,2372,...|\n",
      "|22,6,198,95,2833,...|\n",
      "|18,6,199,97,2774,...|\n",
      "|21,6,200,85,2587,...|\n",
      "|27,4,97,88,2130,1...|\n",
      "|26,4,97,46,1835,2...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data2DF2 = raw_data2.map(lambda x: Row(x)).toDF().toDF(\"k\")\n",
    "raw_data2DF2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_dataDF1 = raw_data1.toDF(\"k\")\n",
    "# raw_dataDF = raw_data1.toDF() \n",
    "# # Gives Error\n",
    "# Py4JJavaError: An error occurred while calling o53.toDF.\n",
    "# : java.lang.IllegalArgumentException: requirement failed: The number of columns doesn't match.\n",
    "# Old column names (1): value\n",
    "# New column names (0): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                   k|\n",
      "+--------------------+\n",
      "|18,8,307,130,3504...|\n",
      "|15,8,350,165,3693...|\n",
      "|18,8,318,150,3436...|\n",
      "|16,8,304,150,3433...|\n",
      "|17,8,302,140,3449...|\n",
      "|15,8,429,198,4341...|\n",
      "|14,8,454,220,4354...|\n",
      "|14,8,440,215,4312...|\n",
      "|14,8,455,225,4425...|\n",
      "|15,8,390,190,3850...|\n",
      "|15,8,383,170,3563...|\n",
      "|14,8,340,160,3609...|\n",
      "|15,8,400,150,3761...|\n",
      "|14,8,455,225,3086...|\n",
      "|24,4,113,95,2372,...|\n",
      "|22,6,198,95,2833,...|\n",
      "|18,6,199,97,2774,...|\n",
      "|21,6,200,85,2587,...|\n",
      "|27,4,97,88,2130,1...|\n",
      "|26,4,97,46,1835,2...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_dataDF1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- k: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- k: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_dataDF1.printSchema()\n",
    "raw_data2DF2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_dataDF = raw_data1.toDF(\"value\")\n",
    "d1  = raw_dataDF.selectExpr(\"split(value, ',') as value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d2 = d1.selectExpr(\"value[0]\", \"value[1]\", \"value[2]\", \"value[3]\", \"value[4]\", \"value[5]\", \"value[6]\", \"value[7]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|value[0]|value[1]|value[2]|value[3]|value[4]|value[5]|value[6]|value[7]|\n",
      "+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|      18|       8|     307|     130|    3504|      12|      70|       1|\n",
      "|      15|       8|     350|     165|    3693|    11.5|      70|       1|\n",
      "|      18|       8|     318|     150|    3436|      11|      70|       1|\n",
      "|      16|       8|     304|     150|    3433|      12|      70|       1|\n",
      "|      17|       8|     302|     140|    3449|    10.5|      70|       1|\n",
      "|      15|       8|     429|     198|    4341|      10|      70|       1|\n",
      "|      14|       8|     454|     220|    4354|       9|      70|       1|\n",
      "|      14|       8|     440|     215|    4312|     8.5|      70|       1|\n",
      "|      14|       8|     455|     225|    4425|      10|      70|       1|\n",
      "|      15|       8|     390|     190|    3850|     8.5|      70|       1|\n",
      "|      15|       8|     383|     170|    3563|      10|      70|       1|\n",
      "|      14|       8|     340|     160|    3609|       8|      70|       1|\n",
      "|      15|       8|     400|     150|    3761|     9.5|      70|       1|\n",
      "|      14|       8|     455|     225|    3086|      10|      70|       1|\n",
      "|      24|       4|     113|      95|    2372|      15|      70|       3|\n",
      "|      22|       6|     198|      95|    2833|    15.5|      70|       1|\n",
      "|      18|       6|     199|      97|    2774|    15.5|      70|       1|\n",
      "|      21|       6|     200|      85|    2587|      16|      70|       1|\n",
      "|      27|       4|      97|      88|    2130|    14.5|      70|       3|\n",
      "|      26|       4|      97|      46|    1835|    20.5|      70|       2|\n",
      "+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value[0]: string (nullable = true)\n",
      " |-- value[1]: string (nullable = true)\n",
      " |-- value[2]: string (nullable = true)\n",
      " |-- value[3]: string (nullable = true)\n",
      " |-- value[4]: string (nullable = true)\n",
      " |-- value[5]: string (nullable = true)\n",
      " |-- value[6]: string (nullable = true)\n",
      " |-- value[7]: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d2.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark2.7_home",
   "language": "python",
   "name": "pyspark2.7_home"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
