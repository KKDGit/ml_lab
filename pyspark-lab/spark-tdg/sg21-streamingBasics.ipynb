{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import platform,os\n",
    "os_name = platform.system()\n",
    "hdfs_home = \"/user/\" + os.getenv(\"HOME\").split(\"/\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/user/kranthidr\n",
      "Linux\n"
     ]
    }
   ],
   "source": [
    "print(hdfs_home)\n",
    "print(os_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = hdfs_home+\"/dataSets/spark-guide/activity-data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/hdp/current/spark2-client'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/hdp/current/spark2-client')\n",
    "#findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"yarn\").appName(\"sg21-streamingBasics\").getOrCreate()\n",
    "#spark = SparkSession.builder.master(\"local[*]\").appName(\"sg21-streamingBasics\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://rm01.itversity.com:19288/proxy/application_1533622723243_20267\n"
     ]
    }
   ],
   "source": [
    "for x in sc._conf.getAll():\n",
    "    if '/proxy/' in x[1]:\n",
    "        print(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "static = spark.read.json(path).cache()\n",
    "dataSchema = static.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+--------+-----+------+----+-----+------------+------------+------------+\n",
      "|Arrival_Time |Creation_Time      |Device  |Index|Model |User|gt   |x           |y           |z           |\n",
      "+-------------+-------------------+--------+-----+------+----+-----+------------+------------+------------+\n",
      "|1424686735090|1424686733090638193|nexus4_1|18   |nexus4|g   |stand|3.356934E-4 |-5.645752E-4|-0.018814087|\n",
      "|1424686735292|1424688581345918092|nexus4_2|66   |nexus4|g   |stand|-0.005722046|0.029083252 |0.005569458 |\n",
      "|1424686735500|1424686733498505625|nexus4_1|99   |nexus4|g   |stand|0.0078125   |-0.017654419|0.010025024 |\n",
      "|1424686735691|1424688581745026978|nexus4_2|145  |nexus4|g   |stand|-3.814697E-4|0.0184021   |-0.013656616|\n",
      "|1424686735890|1424688581945252808|nexus4_2|185  |nexus4|g   |stand|-3.814697E-4|-0.031799316|-0.00831604 |\n",
      "|1424686736094|1424686734097840342|nexus4_1|218  |nexus4|g   |stand|-7.324219E-4|-0.013381958|0.01109314  |\n",
      "|1424686736294|1424688582347932252|nexus4_2|265  |nexus4|g   |stand|-0.005722046|0.015197754 |0.022659302 |\n",
      "|1424686736495|1424688582549592408|nexus4_2|305  |nexus4|g   |stand|-3.814697E-4|0.0087890625|0.0034332275|\n",
      "|1424686736697|1424688582750703248|nexus4_2|345  |nexus4|g   |stand|0.002822876 |-0.008300781|-0.015792847|\n",
      "|1424686736898|1424688582952241334|nexus4_2|385  |nexus4|g   |stand|6.866455E-4 |-0.008300781|0.004501343 |\n",
      "+-------------+-------------------+--------+-----+------+----+-----+------------+------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "static.show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Arrival_Time: long (nullable = true)\n",
      " |-- Creation_Time: long (nullable = true)\n",
      " |-- Device: string (nullable = true)\n",
      " |-- Index: long (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- User: string (nullable = true)\n",
      " |-- gt: string (nullable = true)\n",
      " |-- x: double (nullable = true)\n",
      " |-- y: double (nullable = true)\n",
      " |-- z: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "static.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|User| count|\n",
      "+----+------+\n",
      "|   g|733387|\n",
      "|   f|736442|\n",
      "|   e|768182|\n",
      "|   h|618617|\n",
      "|   d|649961|\n",
      "|   c|617237|\n",
      "|   i|740429|\n",
      "|   b|729907|\n",
      "|   a|646829|\n",
      "+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "static.groupby(\"User\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|  Device|  count|\n",
      "+--------+-------+\n",
      "|nexus4_1|3091811|\n",
      "|nexus4_2|3149180|\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "static.groupby(\"Device\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "| Model|  count|\n",
      "+------+-------+\n",
      "|nexus4|6240991|\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "static.groupby(\"Model\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'false'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.streaming.schemaInference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'200'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.shuffle.partitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.streaming.schemaInference\", \"true\")\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'8'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.shuffle.partitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'true'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.streaming.schemaInference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "#streaming = spark.readStream.schema(dataSchema).option(\"maxFilesPerTrigger\", 1).json(path)\n",
    "streaming = spark.readStream.option(\"maxFilesPerTrigger\", 1).json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "activityCounts = streaming.groupBy(\"gt\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "activityQuery = activityCounts.writeStream.queryName(\"activity_counts\")\\\n",
    "  .format(\"memory\").outputMode(\"complete\")\\\n",
    "  .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| gt|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n",
      "+----------+-----+\n",
      "|        gt|count|\n",
      "+----------+-----+\n",
      "|      bike|10796|\n",
      "|      null|10449|\n",
      "|  stairsup|10452|\n",
      "|     stand|11384|\n",
      "|       sit|12309|\n",
      "|      walk|13256|\n",
      "|stairsdown| 9365|\n",
      "+----------+-----+\n",
      "\n",
      "+----------+-----+\n",
      "|        gt|count|\n",
      "+----------+-----+\n",
      "|      bike|21593|\n",
      "|      null|20896|\n",
      "|  stairsup|20905|\n",
      "|     stand|22769|\n",
      "|       sit|24619|\n",
      "|      walk|26512|\n",
      "|stairsdown|18729|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "from time import sleep\n",
    "for x in range(3):\n",
    "    spark.sql(\"SELECT * FROM activity_counts\").show()\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|        gt|  count|\n",
      "+----------+-------+\n",
      "|      bike| 863710|\n",
      "|      null| 835725|\n",
      "|  stairsup| 836598|\n",
      "|     stand| 910783|\n",
      "|       sit| 984714|\n",
      "|      walk|1060402|\n",
      "|stairsdown| 749059|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "static.groupby(\"gt\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "from pyspark.sql.functions import expr\n",
    "simpleTransform = streaming.withColumn(\"stairs\", expr(\"gt like '%stairs%'\"))\\\n",
    "  .where(\"stairs\")\\\n",
    "  .where(\"gt is not null\")\\\n",
    "  .select(\"gt\", \"model\", \"arrival_time\", \"creation_time\")\\\n",
    "  .writeStream\\\n",
    "  .queryName(\"simple_transform\")\\\n",
    "  .format(\"memory\")\\\n",
    "  .outputMode(\"append\")\\\n",
    "  .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------------+-------------+\n",
      "| gt|model|arrival_time|creation_time|\n",
      "+---+-----+------------+-------------+\n",
      "+---+-----+------------+-------------+\n",
      "\n",
      "+--------+------+-------------+-------------------+\n",
      "|      gt| model| arrival_time|      creation_time|\n",
      "+--------+------+-------------+-------------------+\n",
      "|stairsup|nexus4|1424687983719|1424687981726802718|\n",
      "|stairsup|nexus4|1424687984000|1424687982009853255|\n",
      "|stairsup|nexus4|1424687984404|1424687982411977009|\n",
      "|stairsup|nexus4|1424687984805|1424687982814351277|\n",
      "|stairsup|nexus4|1424687985210|1424687983217500861|\n",
      "+--------+------+-------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+------+-------------+-------------------+\n",
      "|      gt| model| arrival_time|      creation_time|\n",
      "+--------+------+-------------+-------------------+\n",
      "|stairsup|nexus4|1424687983719|1424687981726802718|\n",
      "|stairsup|nexus4|1424687984000|1424687982009853255|\n",
      "|stairsup|nexus4|1424687984404|1424687982411977009|\n",
      "|stairsup|nexus4|1424687984805|1424687982814351277|\n",
      "|stairsup|nexus4|1424687985210|1424687983217500861|\n",
      "+--------+------+-------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in range(3):\n",
    "    spark.sql(\"SELECT * FROM simple_transform\").show(5)\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pyspark.sql.streaming.StreamingQuery at 0x6dede9d30c10>,\n",
       " <pyspark.sql.streaming.StreamingQuery at 0x6dede9d307d0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.streams.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "deviceModelStats = streaming.cube(\"gt\", \"model\").avg()\\\n",
    "  .drop(\"avg(Arrival_time)\")\\\n",
    "  .drop(\"avg(Creation_Time)\")\\\n",
    "  .drop(\"avg(Index)\")\\\n",
    "  .writeStream.queryName(\"device_counts\").format(\"memory\")\\\n",
    "  .outputMode(\"complete\")\\\n",
    "  .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+------+------+\n",
      "| gt|model|avg(x)|avg(y)|avg(z)|\n",
      "+---+-----+------+------+------+\n",
      "+---+-----+------+------+------+\n",
      "\n",
      "+---+-----+------+------+------+\n",
      "| gt|model|avg(x)|avg(y)|avg(z)|\n",
      "+---+-----+------+------+------+\n",
      "+---+-----+------+------+------+\n",
      "\n",
      "+--------+------+--------------------+--------------------+--------------------+\n",
      "|      gt| model|              avg(x)|              avg(y)|              avg(z)|\n",
      "+--------+------+--------------------+--------------------+--------------------+\n",
      "|    null|nexus4|0.002921030154575...|-0.00836616384160438|-0.00897552622204...|\n",
      "|    walk|  null|0.001970352086338262|7.489666845956908E-5|-0.00149828380428...|\n",
      "|stairsup|  null|-0.02623301318863...|-0.01385931765291...| -0.0939500972801954|\n",
      "|stairsup|nexus4|-0.02623301318863...|-0.01385931765291...| -0.0939500972801954|\n",
      "|    bike|nexus4| 0.02351254447093368|-0.01304747996973...|-0.08360475809007037|\n",
      "+--------+------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in range(3):\n",
    "    spark.sql(\"SELECT * FROM device_counts\").show(5)\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "historicalAgg = static.groupBy(\"gt\", \"model\").avg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deviceModelStats = streaming.drop(\"Arrival_Time\", \"Creation_Time\", \"Index\")\\\n",
    "  .cube(\"gt\", \"model\").avg()\\\n",
    "  .join(historicalAgg, [\"gt\", \"model\"])\\\n",
    "  .writeStream.queryName(\"device_counts1\").format(\"memory\")\\\n",
    "  .outputMode(\"complete\")\\\n",
    "  .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+------+------+-----------------+------------------+----------+------+------+------+\n",
      "| gt|model|avg(x)|avg(y)|avg(z)|avg(Arrival_Time)|avg(Creation_Time)|avg(Index)|avg(x)|avg(y)|avg(z)|\n",
      "+---+-----+------+------+------+-----------------+------------------+----------+------+------+------+\n",
      "+---+-----+------+------+------+-----------------+------------------+----------+------+------+------+\n",
      "\n",
      "+---+-----+------+------+------+-----------------+------------------+----------+------+------+------+\n",
      "| gt|model|avg(x)|avg(y)|avg(z)|avg(Arrival_Time)|avg(Creation_Time)|avg(Index)|avg(x)|avg(y)|avg(z)|\n",
      "+---+-----+------+------+------+-----------------+------------------+----------+------+------+------+\n",
      "+---+-----+------+------+------+-----------------+------------------+----------+------+------+------+\n",
      "\n",
      "+--------+------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "|      gt| model|              avg(x)|              avg(y)|              avg(z)|   avg(Arrival_Time)|  avg(Creation_Time)|        avg(Index)|              avg(x)|              avg(y)|              avg(z)|\n",
      "+--------+------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "|stairsup|nexus4|-0.02623301318863...|-0.01385931765291...| -0.0939500972801954|1.424745996101163E12|1.424746915892737...|227912.96550673083|-0.02479965287771...|-0.00800392344379...|-0.10034088415060395|\n",
      "|    bike|nexus4| 0.02351254447093368|-0.01304747996973...|-0.08360475809007037|1.424751134339985...|1.424752127369589...| 326459.6867328154|0.022688759550866845|-0.00877912156368...|-0.08251001663412344|\n",
      "|    null|nexus4|-0.00302501221506...|-0.00410754501410...|0.005961452067049...|1.424749002876339E12|1.424749919482126...| 219276.9663669269|-0.00847688860109...|-7.30455258739188...|0.003090601491419932|\n",
      "|     sit|nexus4|-4.92132825379804...|3.757376157445776E-4|-4.42863346250722...|1.424741207868231...|1.424742112220356...| 74577.84690275553|-5.49433244039557...|2.791446281700041E-4|-2.33994461689905...|\n",
      "|    walk|nexus4|0.001970352086338262|7.489666845956904E-5|-0.00149828380428...|1.424746420641789...|1.424747351060674...|149760.09974990616|-0.00390116006094...|0.001052508689953...|-6.95435553042997...|\n",
      "+--------+------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in range(3):\n",
    "    spark.sql(\"SELECT * FROM device_counts1\").show(5)\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pyspark.sql.streaming.StreamingQuery at 0x6dede9bbd390>,\n",
       " <pyspark.sql.streaming.StreamingQuery at 0x6dede9d6bd50>,\n",
       " <pyspark.sql.streaming.StreamingQuery at 0x6dede9d6bcd0>,\n",
       " <pyspark.sql.streaming.StreamingQuery at 0x6dede9d6bd90>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.streams.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # COMMAND ----------\n",
    "\n",
    "# # Subscribe to 1 topic\n",
    "# df1 = spark.readStream.format(\"kafka\")\\\n",
    "#   .option(\"kafka.bootstrap.servers\", \"host1:port1,host2:port2\")\\\n",
    "#   .option(\"subscribe\", \"topic1\")\\\n",
    "#   .load()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Subscribe to multiple topics\n",
    "# df2 = spark.readStream.format(\"kafka\")\\\n",
    "#   .option(\"kafka.bootstrap.servers\", \"host1:port1,host2:port2\")\\\n",
    "#   .option(\"subscribe\", \"topic1,topic2\")\\\n",
    "#   .load()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Subscribe to a pattern\n",
    "# df3 = spark.readStream.format(\"kafka\")\\\n",
    "#   .option(\"kafka.bootstrap.servers\", \"host1:port1,host2:port2\")\\\n",
    "#   .option(\"subscribePattern\", \"topic.*\")\\\n",
    "#   .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # COMMAND ----------\n",
    "\n",
    "# df1.selectExpr(\"topic\", \"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\\\n",
    "#   .writeStream\\\n",
    "#   .format(\"kafka\")\\\n",
    "#   .option(\"kafka.bootstrap.servers\", \"host1:port1,host2:port2\")\\\n",
    "#   .option(\"checkpointLocation\", \"/to/HDFS-compatible/dir\")\\\n",
    "#   .start()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df1.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\\\n",
    "#   .writeStream\\\n",
    "#   .format(\"kafka\")\\\n",
    "#   .option(\"kafka.bootstrap.servers\", \"host1:port1,host2:port2\")\\\n",
    "#   .option(\"checkpointLocation\", \"/to/HDFS-compatible/dir\")\\\n",
    "#   .option(\"topic\", \"topic1\")\\\n",
    "#   .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# run ----- nc -lk 9999 on terminal\n",
    "socketDF = spark.readStream.format(\"socket\")\\\n",
    "  .option(\"host\", \"localhost\").option(\"port\", 9999).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviceModelStats = socketDF\\\n",
    "  .writeStream.queryName(\"socket\").format(\"memory\")\\\n",
    "  .outputMode(\"append\")\\\n",
    "  .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "+-----+\n",
      "\n",
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "+-----+\n",
      "\n",
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "|   kk|\n",
      "+-----+\n",
      "\n",
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "|   kk|\n",
      "|   ll|\n",
      "|  123|\n",
      "|  567|\n",
      "+-----+\n",
      "\n",
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "|   kk|\n",
      "|   ll|\n",
      "|  123|\n",
      "|  567|\n",
      "|  901|\n",
      "+-----+\n",
      "\n",
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "|   kk|\n",
      "|   ll|\n",
      "|  123|\n",
      "|  567|\n",
      "|  901|\n",
      "+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "|   kk|\n",
      "|   ll|\n",
      "|  123|\n",
      "|  567|\n",
      "|  901|\n",
      "+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "|   kk|\n",
      "|   ll|\n",
      "|  123|\n",
      "|  567|\n",
      "|  901|\n",
      "+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "|   kk|\n",
      "|   ll|\n",
      "|  123|\n",
      "|  567|\n",
      "|  901|\n",
      "+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "|   kk|\n",
      "|   ll|\n",
      "|  123|\n",
      "|  567|\n",
      "|  901|\n",
      "+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    spark.sql(\"SELECT * FROM socket\").show(5)\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pyspark.sql.streaming.StreamingQuery at 0x6dede9d6ba10>,\n",
       " <pyspark.sql.streaming.StreamingQuery at 0x6dede9d6b7d0>,\n",
       " <pyspark.sql.streaming.StreamingQuery at 0x6dede9d6b850>,\n",
       " <pyspark.sql.streaming.StreamingQuery at 0x6dede9d6bad0>,\n",
       " <pyspark.sql.streaming.StreamingQuery at 0x6dede9d6bc90>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.streams.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # COMMAND ----------\n",
    "\n",
    "# activityCounts.writeStream.trigger(processingTime='5 seconds')\\\n",
    "#   .format(\"console\").outputMode(\"complete\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "# activityCounts.writeStream.trigger(once=True)\\\n",
    "#   .format(\"console\").outputMode(\"complete\").start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark2.7_home",
   "language": "python",
   "name": "pyspark2.7_home"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
