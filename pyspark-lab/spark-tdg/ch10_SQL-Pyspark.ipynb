{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/hdp/current/spark2-client'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/hdp/current/spark2-client')\n",
    "#findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"yarn\").appName(\"ch10SQLPyspark\").enableHiveSupport().getOrCreate()\n",
    "#spark = SparkSession.builder.master(\"local[*]\").appName(\"ch08Joins\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://rm01.itversity.com:19288/proxy/application_1533622723243_17801\n"
     ]
    }
   ],
   "source": [
    "for x in sc._conf.getAll():\n",
    "    if '/proxy/' in x[1]:\n",
    "        print(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data_dir = \"D:/Learn/GitRepos/Spark-The-Definitive-Guide/data\"\n",
    "data_dir = \"/user/kranthidr/dataSets/spark-guide\"\n",
    "data_path = data_dir + \"/flight-data/json/2015-summary.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.read.json(data_path).createOrReplaceTempView(\"some_sql_view\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "|DEST_COUNTRY_NAME|sum(count)|\n",
      "+-----------------+----------+\n",
      "|         Anguilla|        41|\n",
      "|           Russia|       176|\n",
      "|         Paraguay|        60|\n",
      "|          Senegal|        40|\n",
      "|           Sweden|       118|\n",
      "|         Kiribati|        26|\n",
      "|           Guyana|        64|\n",
      "|      Philippines|       134|\n",
      "|         Djibouti|         1|\n",
      "|         Malaysia|         2|\n",
      "+-----------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT DEST_COUNTRY_NAME, sum(count) FROM some_sql_view GROUP BY DEST_COUNTRY_NAME\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|   DEST_COUNTRY_NAME|sum(count)|\n",
      "+--------------------+----------+\n",
      "|             Senegal|        40|\n",
      "|              Sweden|       118|\n",
      "|               Spain|       420|\n",
      "|    Saint Barthelemy|        39|\n",
      "|Saint Kitts and N...|       139|\n",
      "|         South Korea|      1048|\n",
      "|        Sint Maarten|       325|\n",
      "|        Saudi Arabia|        83|\n",
      "|         Switzerland|       294|\n",
      "|         Saint Lucia|       123|\n",
      "+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT DEST_COUNTRY_NAME, sum(count) FROM some_sql_view GROUP BY DEST_COUNTRY_NAME\")\\\n",
    ".where(\"DEST_COUNTRY_NAME like 'S%'\")\\\n",
    ".where(\"`sum(count)` > 10\").show(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE DATABASE IF NOT EXISTS Kranthidr_db\n",
    "LOCATION '/user/kranthidr/Kranthidr_db'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "USE Kranthidr_db\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS flights (DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count LONG)\n",
    "USING JSON OPTIONS (path '/user/kranthidr/dataSets/spark-guide/flight-data/json/2015-summary.json')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "|    United States|          Singapore|    1|\n",
      "|    United States|            Grenada|   62|\n",
      "|       Costa Rica|      United States|  588|\n",
      "|          Senegal|      United States|   40|\n",
      "|          Moldova|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select * from flights limit 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE flights_csv (\n",
    "  DEST_COUNTRY_NAME STRING,\n",
    "  ORIGIN_COUNTRY_NAME STRING COMMENT \"remember, the US will be most prevalent\",\n",
    "  count LONG)\n",
    "USING csv OPTIONS (header true, path '/user/kranthidr/dataSets/spark-guide/flight-data/csv/2015-summary.csv')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "|    United States|          Singapore|    1|\n",
      "|    United States|            Grenada|   62|\n",
      "|       Costa Rica|      United States|  588|\n",
      "|          Senegal|      United States|   40|\n",
      "|          Moldova|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select * from flights_csv limit 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|        databaseName|\n",
      "+--------------------+\n",
      "|   000000_abhi_cards|\n",
      "|            00_cards|\n",
      "|              00_db1|\n",
      "|           05121990a|\n",
      "|        0_ganesh1146|\n",
      "|          0_practice|\n",
      "|            0_subrat|\n",
      "|          10bq1a0410|\n",
      "|               10feb|\n",
      "|          1pakr12345|\n",
      "|                1ssm|\n",
      "|23singhabhishek_s...|\n",
      "|             24thmay|\n",
      "|                2jun|\n",
      "|               30may|\n",
      "|               31may|\n",
      "|              5avril|\n",
      "|                5jun|\n",
      "|             5junraj|\n",
      "|         5junrajnish|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "show databases\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+-----------+\n",
      "|    database|          tableName|isTemporary|\n",
      "+------------+-------------------+-----------+\n",
      "|kranthidr_db|            flights|      false|\n",
      "|kranthidr_db|        flights_csv|      false|\n",
      "|kranthidr_db|flights_from_select|      false|\n",
      "|kranthidr_db|       hive_flights|      false|\n",
      "|kranthidr_db|partitioned_flights|      false|\n",
      "|            |      some_sql_view|       true|\n",
      "+------------+-------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "show tables\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS flights_from_select\n",
    "  AS SELECT * FROM flights\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM flights_from_select\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE partitioned_flights USING parquet PARTITIONED BY (DEST_COUNTRY_NAME)\n",
    "AS SELECT DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME, count FROM flights LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/user/kranthidr/dataSets/spark-guide/flight-data-hive/'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir+\"/flight-data-hive/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE EXTERNAL TABLE hive_flights (\n",
    "  DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count LONG)\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LOCATION '/user/kranthidr/dataSets/spark-guide/flight-data-hive/'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE EXTERNAL TABLE hive_flights_2\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\n",
    "LOCATION '/user/kranthidr/dataSets/spark-guide/flight-data-hive/' AS SELECT * FROM flights\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+-----------+\n",
      "|    database|          tableName|isTemporary|\n",
      "+------------+-------------------+-----------+\n",
      "|kranthidr_db|            flights|      false|\n",
      "|kranthidr_db|        flights_csv|      false|\n",
      "|kranthidr_db|flights_from_select|      false|\n",
      "|kranthidr_db|       hive_flights|      false|\n",
      "|kranthidr_db|     hive_flights_2|      false|\n",
      "|kranthidr_db|partitioned_flights|      false|\n",
      "|            |      some_sql_view|       true|\n",
      "+------------+-------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "show tables\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "INSERT INTO flights_from_select\n",
    "  SELECT DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME, count FROM flights LIMIT 20\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "INSERT INTO partitioned_flights\n",
    "  PARTITION (DEST_COUNTRY_NAME=\"UNITED STATES\")\n",
    "  SELECT count, ORIGIN_COUNTRY_NAME FROM flights\n",
    "  WHERE DEST_COUNTRY_NAME='UNITED STATES' LIMIT 12\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------------------+\n",
      "|           col_name|data_type|             comment|\n",
      "+-------------------+---------+--------------------+\n",
      "|  DEST_COUNTRY_NAME|   string|                null|\n",
      "|ORIGIN_COUNTRY_NAME|   string|remember, the US ...|\n",
      "|              count|   bigint|                null|\n",
      "+-------------------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "DESCRIBE TABLE flights_csv\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|partition                      |\n",
      "+-------------------------------+\n",
      "|DEST_COUNTRY_NAME=Egypt        |\n",
      "|DEST_COUNTRY_NAME=United States|\n",
      "+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SHOW PARTITIONS partitioned_flights\n",
    "\"\"\").show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "REFRESH table partitioned_flights\n",
    "\"\"\").show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "MSCK REPAIR TABLE partitioned_flights\n",
    "\"\"\").show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "DROP TABLE flights_csv\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "DROP TABLE IF EXISTS flights_csv\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CACHE TABLE flights\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "UNCACHE TABLE FLIGHTS\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE VIEW IF NOT EXISTS just_usa_view AS\n",
    "  SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TEMP VIEW just_usa_view_temp AS\n",
    "  SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE GLOBAL TEMP VIEW just_usa_global_view_temp AS\n",
    "  SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+-----------+\n",
      "|    database|          tableName|isTemporary|\n",
      "+------------+-------------------+-----------+\n",
      "|kranthidr_db|            flights|      false|\n",
      "|kranthidr_db|flights_from_select|      false|\n",
      "|kranthidr_db|       hive_flights|      false|\n",
      "|kranthidr_db|     hive_flights_2|      false|\n",
      "|kranthidr_db|      just_usa_view|      false|\n",
      "|kranthidr_db|partitioned_flights|      false|\n",
      "|            | just_usa_view_temp|       true|\n",
      "|            |      some_sql_view|       true|\n",
      "+------------+-------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SHOW TABLES\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW just_usa_view_temp AS\n",
    "  SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-----+\n",
      "|DEST_COUNTRY_NAME| ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+--------------------+-----+\n",
      "|    United States|             Romania|   15|\n",
      "|    United States|             Croatia|    1|\n",
      "|    United States|             Ireland|  344|\n",
      "|    United States|               India|   62|\n",
      "|    United States|           Singapore|    1|\n",
      "|    United States|             Grenada|   62|\n",
      "|    United States|        Sint Maarten|  325|\n",
      "|    United States|    Marshall Islands|   39|\n",
      "|    United States|            Paraguay|    6|\n",
      "|    United States|           Gibraltar|    1|\n",
      "|    United States|Federated States ...|   69|\n",
      "|    United States|              Russia|  161|\n",
      "|    United States|         Netherlands|  660|\n",
      "|    United States|             Senegal|   42|\n",
      "|    United States|              Angola|   13|\n",
      "|    United States|            Anguilla|   38|\n",
      "|    United States|             Ecuador|  300|\n",
      "|    United States|              Cyprus|    1|\n",
      "|    United States|            Portugal|  134|\n",
      "|    United States|          Costa Rica|  608|\n",
      "+-----------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM just_usa_view_temp\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(plan=u'== Physical Plan ==\\n*(1) Project [DEST_COUNTRY_NAME#52, ORIGIN_COUNTRY_NAME#53, count#54L]\\n+- *(1) Filter (isnotnull(dest_country_name#52) && (dest_country_name#52 = United States))\\n   +- *(1) FileScan json kranthidr_db.flights[DEST_COUNTRY_NAME#52,ORIGIN_COUNTRY_NAME#53,count#54L] Batched: false, Format: JSON, Location: InMemoryFileIndex[hdfs://nn01.itversity.com:8020/user/kranthidr/dataSets/spark-guide/flight-data/..., PartitionFilters: [], PushedFilters: [IsNotNull(DEST_COUNTRY_NAME), EqualTo(DEST_COUNTRY_NAME,United States)], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:bigint>')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "EXPLAIN SELECT * FROM just_usa_view\n",
    "\"\"\").take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(plan=u'== Physical Plan ==\\n*(1) Project [DEST_COUNTRY_NAME#52, ORIGIN_COUNTRY_NAME#53, count#54L]\\n+- *(1) Filter (isnotnull(dest_country_name#52) && (dest_country_name#52 = United States))\\n   +- *(1) FileScan json kranthidr_db.flights[DEST_COUNTRY_NAME#52,ORIGIN_COUNTRY_NAME#53,count#54L] Batched: false, Format: JSON, Location: InMemoryFileIndex[hdfs://nn01.itversity.com:8020/user/kranthidr/dataSets/spark-guide/flight-data/..., PartitionFilters: [], PushedFilters: [IsNotNull(DEST_COUNTRY_NAME), EqualTo(DEST_COUNTRY_NAME,United States)], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:bigint>')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "EXPLAIN SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\"\"\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "DROP VIEW IF EXISTS just_usa_view\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|        databaseName|\n",
      "+--------------------+\n",
      "|    kr_arun_problem6|\n",
      "|     kr_sqoop_import|\n",
      "|        kranthidr_db|\n",
      "|       kranthikarnam|\n",
      "|              kranti|\n",
      "|               krish|\n",
      "|            krish_db|\n",
      "| krish_retail_db_txt|\n",
      "|              krishm|\n",
      "|           krishmani|\n",
      "|             krishna|\n",
      "|          krishna324|\n",
      "|krishna324_daily_...|\n",
      "|      krishna324_orc|\n",
      "|krishna324_retail...|\n",
      "|          krishna533|\n",
      "|krishna533_sqoop_...|\n",
      "| krishna_201711_demo|\n",
      "| krishna_arun_201801|\n",
      "| krishna_arun_201802|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SHOW DATABASES 'kr*'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7010"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SHOW DATABASES\n",
    "\"\"\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM default.flights\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|current_database()|\n",
      "+------------------+\n",
      "|      kranthidr_db|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT current_database()\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"\"\"\n",
    "# DROP DATABASE IF EXISTS kranthidr_db\n",
    "# \"\"\").show()\n",
    "\n",
    "# AnalysisException: u'org.apache.hadoop.hive.ql.metadata.HiveException: \n",
    "#     InvalidOperationException(message:Database kranthidr_db is not empty. One or more tables exist.);'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SELECT [ALL|DISTINCT] named_expression[, named_expression, ...]\n",
    "#     FROM relation[, relation, ...]\n",
    "#     [lateral_view[, lateral_view, ...]]\n",
    "#     [WHERE boolean_expression]\n",
    "#     [aggregation [HAVING boolean_expression]]\n",
    "#     [ORDER BY sort_expressions]\n",
    "#     [CLUSTER BY expressions]\n",
    "#     [DISTRIBUTE BY expressions]\n",
    "#     [SORT BY sort_expressions]\n",
    "#     [WINDOW named_window[, WINDOW named_window, ...]]\n",
    "#     [LIMIT num_rows]\n",
    "\n",
    "# named_expression:\n",
    "#     : expression [AS alias]\n",
    "\n",
    "# relation:\n",
    "#     | join_relation\n",
    "#     | (table_name|query|relation) [sample] [AS alias]\n",
    "#     : VALUES (expressions)[, (expressions), ...]\n",
    "#           [AS (column_name[, column_name, ...])]\n",
    "\n",
    "# expressions:\n",
    "#     : expression[, expression, ...]\n",
    "\n",
    "# sort_expressions:\n",
    "#     : expression [ASC|DESC][, expression [ASC|DESC], ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------+\n",
      "|CASE WHEN (DEST_COUNTRY_NAME = UNITED STATES) THEN 1 WHEN (DEST_COUNTRY_NAME = Egypt) THEN 0 ELSE -1 END|\n",
      "+--------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                      -1|\n",
      "|                                                                                                      -1|\n",
      "|                                                                                                      -1|\n",
      "|                                                                                                      -1|\n",
      "|                                                                                                       0|\n",
      "+--------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "  CASE WHEN DEST_COUNTRY_NAME = 'UNITED STATES' THEN 1\n",
    "       WHEN DEST_COUNTRY_NAME = 'Egypt' THEN 0\n",
    "       ELSE -1 END\n",
    "FROM partitioned_flights\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE VIEW IF NOT EXISTS nested_data AS\n",
    "  SELECT (DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME) as country, count FROM flights\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----+\n",
      "|country                 |count|\n",
      "+------------------------+-----+\n",
      "|[United States, Romania]|15   |\n",
      "|[United States, Croatia]|1    |\n",
      "|[United States, Ireland]|344  |\n",
      "+------------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM nested_data\n",
    "\"\"\").show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|DEST_COUNTRY_NAME|count|\n",
      "+-----------------+-----+\n",
      "|United States    |15   |\n",
      "|United States    |1    |\n",
      "|United States    |344  |\n",
      "|Egypt            |15   |\n",
      "|United States    |62   |\n",
      "+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT country.DEST_COUNTRY_NAME, count FROM nested_data\n",
    "\"\"\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |15   |\n",
      "|United States    |Croatia            |1    |\n",
      "|United States    |Ireland            |344  |\n",
      "|Egypt            |United States      |15   |\n",
      "|United States    |India              |62   |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT country.*, count FROM nested_data\n",
    "\"\"\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+---------------+\n",
      "|new_name|flight_counts|origin_set     |\n",
      "+--------+-------------+---------------+\n",
      "|Anguilla|[41]         |[United States]|\n",
      "|Paraguay|[60]         |[United States]|\n",
      "|Russia  |[176]        |[United States]|\n",
      "|Senegal |[40]         |[United States]|\n",
      "|Sweden  |[118]        |[United States]|\n",
      "+--------+-------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT DEST_COUNTRY_NAME as new_name, collect_list(count) as flight_counts,\n",
    "  collect_set(ORIGIN_COUNTRY_NAME) as origin_set\n",
    "FROM flights GROUP BY DEST_COUNTRY_NAME\n",
    "\"\"\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------+\n",
      "|DEST_COUNTRY_NAME|array(1, 2, 3)|\n",
      "+-----------------+--------------+\n",
      "|United States    |[1, 2, 3]     |\n",
      "|United States    |[1, 2, 3]     |\n",
      "|United States    |[1, 2, 3]     |\n",
      "|Egypt            |[1, 2, 3]     |\n",
      "|United States    |[1, 2, 3]     |\n",
      "+-----------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, ARRAY(1, 2, 3) FROM flights\n",
    "\"\"\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------------+\n",
      "|new_name|collect_list(count)[0]|\n",
      "+--------+----------------------+\n",
      "|Anguilla|41                    |\n",
      "|Paraguay|60                    |\n",
      "|Russia  |176                   |\n",
      "|Senegal |40                    |\n",
      "|Sweden  |118                   |\n",
      "+--------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT DEST_COUNTRY_NAME as new_name, collect_list(count)[0]\n",
    "FROM flights GROUP BY DEST_COUNTRY_NAME\n",
    "\"\"\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW flights_agg AS\n",
    "  SELECT DEST_COUNTRY_NAME, collect_list(count) as collected_counts\n",
    "  FROM flights GROUP BY DEST_COUNTRY_NAME\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+\n",
      "|col|DEST_COUNTRY_NAME|\n",
      "+---+-----------------+\n",
      "|41 |Anguilla         |\n",
      "|60 |Paraguay         |\n",
      "|176|Russia           |\n",
      "|40 |Senegal          |\n",
      "|118|Sweden           |\n",
      "+---+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT explode(collected_counts), DEST_COUNTRY_NAME FROM flights_agg\n",
    "\"\"\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            function|\n",
      "+--------------------+\n",
      "|                   !|\n",
      "|                   %|\n",
      "|                   &|\n",
      "|                   *|\n",
      "|                   +|\n",
      "|                   -|\n",
      "|                   /|\n",
      "|                   <|\n",
      "|                  <=|\n",
      "|                 <=>|\n",
      "|                   =|\n",
      "|                  ==|\n",
      "|                   >|\n",
      "|                  >=|\n",
      "|                   ^|\n",
      "|                 abs|\n",
      "|                acos|\n",
      "|          add_months|\n",
      "|                 and|\n",
      "|approx_count_dist...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SHOW FUNCTIONS\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            function|\n",
      "+--------------------+\n",
      "|                   !|\n",
      "|                   %|\n",
      "|                   &|\n",
      "|                   *|\n",
      "|                   +|\n",
      "|                   -|\n",
      "|                   /|\n",
      "|                   <|\n",
      "|                  <=|\n",
      "|                 <=>|\n",
      "|                   =|\n",
      "|                  ==|\n",
      "|                   >|\n",
      "|                  >=|\n",
      "|                   ^|\n",
      "|                 abs|\n",
      "|                acos|\n",
      "|          add_months|\n",
      "|                 and|\n",
      "|approx_count_dist...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SHOW SYSTEM FUNCTIONS\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|function|\n",
      "+--------+\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SHOW USER FUNCTIONS\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|          function|\n",
      "+------------------+\n",
      "|            second|\n",
      "|         sentences|\n",
      "|               sha|\n",
      "|              sha1|\n",
      "|              sha2|\n",
      "|         shiftleft|\n",
      "|        shiftright|\n",
      "|shiftrightunsigned|\n",
      "|              sign|\n",
      "|            signum|\n",
      "|               sin|\n",
      "|              sinh|\n",
      "|              size|\n",
      "|          skewness|\n",
      "|          smallint|\n",
      "|        sort_array|\n",
      "|           soundex|\n",
      "|             space|\n",
      "|spark_partition_id|\n",
      "|             split|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SHOW FUNCTIONS \"s*\"\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|    function|\n",
      "+------------+\n",
      "|collect_list|\n",
      "| collect_set|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SHOW FUNCTIONS LIKE \"collect*\"\n",
    "\"\"\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"\"\"\n",
    "# SELECT count, power3(count) FROM flights\n",
    "# \"\"\").show()\n",
    "# AnalysisException: u\"Undefined function: 'power3'. \n",
    "#     This function is neither a registered temporary function nor a permanent function registered in the database 'default'.; \n",
    "#     line 2 pos 14\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|current_database()|\n",
      "+------------------+\n",
      "|      kranthidr_db|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select current_database()\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|dest_country_name|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|           Canada|\n",
      "|           Mexico|\n",
      "|   United Kingdom|\n",
      "|            Japan|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT dest_country_name FROM flights\n",
    "GROUP BY dest_country_name ORDER BY sum(count) DESC LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|               Egypt|      United States|   15|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|               Italy|      United States|  382|\n",
      "|            Pakistan|      United States|   12|\n",
      "|             Iceland|      United States|  181|\n",
      "|    Marshall Islands|      United States|   42|\n",
      "|          Luxembourg|      United States|  155|\n",
      "|            Honduras|      United States|  362|\n",
      "|         The Bahamas|      United States|  955|\n",
      "|         El Salvador|      United States|  561|\n",
      "|               Samoa|      United States|   25|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM flights\n",
    "WHERE origin_country_name IN (SELECT dest_country_name FROM flights\n",
    "      GROUP BY dest_country_name ORDER BY sum(count) DESC LIMIT 5)\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|   DEST_COUNTRY_NAME| ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+--------------------+-----+\n",
      "|       United States|             Romania|   15|\n",
      "|       United States|             Croatia|    1|\n",
      "|       United States|             Ireland|  344|\n",
      "|               Egypt|       United States|   15|\n",
      "|       United States|               India|   62|\n",
      "|       United States|           Singapore|    1|\n",
      "|       United States|             Grenada|   62|\n",
      "|          Costa Rica|       United States|  588|\n",
      "|             Senegal|       United States|   40|\n",
      "|       United States|        Sint Maarten|  325|\n",
      "|       United States|    Marshall Islands|   39|\n",
      "|              Guyana|       United States|   64|\n",
      "|               Malta|       United States|    1|\n",
      "|            Anguilla|       United States|   41|\n",
      "|             Bolivia|       United States|   30|\n",
      "|       United States|            Paraguay|    6|\n",
      "|Turks and Caicos ...|       United States|  230|\n",
      "|               Italy|       United States|  382|\n",
      "|       United States|Federated States ...|   69|\n",
      "|       United States|              Russia|  161|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM flights f1\n",
    "WHERE EXISTS (SELECT 1 FROM flights f2\n",
    "            WHERE f1.dest_country_name = f2.origin_country_name)\n",
    "AND EXISTS (SELECT 1 FROM flights f2\n",
    "            WHERE f2.dest_country_name = f1.origin_country_name)\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+-------+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|maximum|\n",
      "+--------------------+-------------------+-----+-------+\n",
      "|       United States|            Romania|   15| 370002|\n",
      "|       United States|            Croatia|    1| 370002|\n",
      "|       United States|            Ireland|  344| 370002|\n",
      "|               Egypt|      United States|   15| 370002|\n",
      "|       United States|              India|   62| 370002|\n",
      "|       United States|          Singapore|    1| 370002|\n",
      "|       United States|            Grenada|   62| 370002|\n",
      "|          Costa Rica|      United States|  588| 370002|\n",
      "|             Senegal|      United States|   40| 370002|\n",
      "|             Moldova|      United States|    1| 370002|\n",
      "|       United States|       Sint Maarten|  325| 370002|\n",
      "|       United States|   Marshall Islands|   39| 370002|\n",
      "|              Guyana|      United States|   64| 370002|\n",
      "|               Malta|      United States|    1| 370002|\n",
      "|            Anguilla|      United States|   41| 370002|\n",
      "|             Bolivia|      United States|   30| 370002|\n",
      "|       United States|           Paraguay|    6| 370002|\n",
      "|             Algeria|      United States|    4| 370002|\n",
      "|Turks and Caicos ...|      United States|  230| 370002|\n",
      "|       United States|          Gibraltar|    1| 370002|\n",
      "+--------------------+-------------------+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT *, (SELECT max(count) FROM flights) AS maximum FROM flights\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                 key|value|\n",
      "+--------------------+-----+\n",
      "|spark.sql.shuffle...|   20|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SET spark.sql.shuffle.partitions=20\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark2.7_home",
   "language": "python",
   "name": "pyspark2.7_home"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
