{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/hdp/current/spark2-client'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/hdp/current/spark2-client')\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"yarn\").appName(\"ch06DifferentTypesOfData\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://gw02.itversity.com:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0.2.6.5.0-292</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ch06DifferentTypesOfData</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x66abc40a3050>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://rm01.itversity.com:19288/proxy/application_1533622723243_12327\n"
     ]
    }
   ],
   "source": [
    "for x in sc._conf.getAll():\n",
    "    if '/proxy/' in x[1]:\n",
    "        print(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .option(\"inferSchema\", \"true\")\\\n",
    "  .load(\"/user/kranthidr/dataSets/spark-guide/retail-data/by-day/2010-12-01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER |6       |2010-12-01 08:26:00|2.55     |17850.0   |United Kingdom|\n",
      "|536365   |71053    |WHITE METAL LANTERN                |6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|\n",
      "|536365   |84406B   |CREAM CUPID HEARTS COAT HANGER     |8       |2010-12-01 08:26:00|2.75     |17850.0   |United Kingdom|\n",
      "|536365   |84029G   |KNITTED UNION FLAG HOT WATER BOTTLE|6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|\n",
      "|536365   |84029E   |RED WOOLLY HOTTIE WHITE HEART.     |6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|\n",
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n",
      "|  5|five|5.0|\n",
      "+---+----+---+\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "+---+----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import lit\n",
    "df.select(lit(5), lit(\"five\"), lit(5.0)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------+\n",
      "|InvoiceNo|Description                  |\n",
      "+---------+-----------------------------+\n",
      "|536366   |HAND WARMER UNION JACK       |\n",
      "|536366   |HAND WARMER RED POLKA DOT    |\n",
      "|536367   |ASSORTED COLOUR BIRD ORNAMENT|\n",
      "|536367   |POPPY'S PLAYHOUSE BEDROOM    |\n",
      "|536367   |POPPY'S PLAYHOUSE KITCHEN    |\n",
      "+---------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.where(col(\"InvoiceNo\") != 536365)\\\n",
    "  .select(\"InvoiceNo\", \"Description\")\\\n",
    "  .show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------+\n",
      "|InvoiceNo|Description                  |\n",
      "+---------+-----------------------------+\n",
      "|536366   |HAND WARMER UNION JACK       |\n",
      "|536366   |HAND WARMER RED POLKA DOT    |\n",
      "|536367   |ASSORTED COLOUR BIRD ORNAMENT|\n",
      "|536367   |POPPY'S PLAYHOUSE BEDROOM    |\n",
      "|536367   |POPPY'S PLAYHOUSE KITCHEN    |\n",
      "+---------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(\"InvoiceNo != 536365\")\\\n",
    "  .select(\"InvoiceNo\", \"Description\")\\\n",
    "  .show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------+\n",
      "|InvoiceNo|Description                  |\n",
      "+---------+-----------------------------+\n",
      "|536366   |HAND WARMER UNION JACK       |\n",
      "|536366   |HAND WARMER RED POLKA DOT    |\n",
      "|536367   |ASSORTED COLOUR BIRD ORNAMENT|\n",
      "|536367   |POPPY'S PLAYHOUSE BEDROOM    |\n",
      "|536367   |POPPY'S PLAYHOUSE KITCHEN    |\n",
      "+---------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(\"InvoiceNo <> 536365\")\\\n",
    "  .select(\"InvoiceNo\", \"Description\")\\\n",
    "  .show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------------+\n",
      "|InvoiceNo|Description                        |\n",
      "+---------+-----------------------------------+\n",
      "|536365   |WHITE HANGING HEART T-LIGHT HOLDER |\n",
      "|536365   |WHITE METAL LANTERN                |\n",
      "|536365   |CREAM CUPID HEARTS COAT HANGER     |\n",
      "|536365   |KNITTED UNION FLAG HOT WATER BOTTLE|\n",
      "|536365   |RED WOOLLY HOTTIE WHITE HEART.     |\n",
      "+---------+-----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Both = and == will work.........\n",
    "df.where(\"InvoiceNo == 536365\")\\\n",
    "  .select(\"InvoiceNo\", \"Description\")\\\n",
    "  .show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description   |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|536544   |DOT      |DOTCOM POSTAGE|1       |2010-12-01 14:32:00|569.77   |null      |United Kingdom|\n",
      "|536592   |DOT      |DOTCOM POSTAGE|1       |2010-12-01 17:06:00|607.49   |null      |United Kingdom|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import instr\n",
    "priceFilter = col(\"UnitPrice\") > 600\n",
    "descripFilter = instr(df.Description, \"POSTAGE\") >= 1\n",
    "\n",
    "df.where(df.StockCode.isin(\"DOT\")).where(priceFilter | descripFilter).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description   |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|536370   |POST     |POSTAGE       |3       |2010-12-01 08:45:00|18.0     |12583.0   |France        |\n",
      "|536403   |POST     |POSTAGE       |1       |2010-12-01 11:27:00|15.0     |12791.0   |Netherlands   |\n",
      "|536527   |POST     |POSTAGE       |1       |2010-12-01 13:04:00|18.0     |12662.0   |Germany       |\n",
      "|536544   |DOT      |DOTCOM POSTAGE|1       |2010-12-01 14:32:00|569.77   |null      |United Kingdom|\n",
      "|536592   |DOT      |DOTCOM POSTAGE|1       |2010-12-01 17:06:00|607.49   |null      |United Kingdom|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(descripFilter).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-------------------+---------+----------+-----------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate        |UnitPrice|CustomerID|Country    |\n",
      "+---------+---------+-----------+--------+-------------------+---------+----------+-----------+\n",
      "|536370   |POST     |POSTAGE    |3       |2010-12-01 08:45:00|18.0     |12583.0   |France     |\n",
      "|536403   |POST     |POSTAGE    |1       |2010-12-01 11:27:00|15.0     |12791.0   |Netherlands|\n",
      "|536527   |POST     |POSTAGE    |1       |2010-12-01 13:04:00|18.0     |12662.0   |Germany    |\n",
      "+---------+---------+-----------+--------+-------------------+---------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.Description.isin(\"POSTAGE\")).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description   |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|536370   |POST     |POSTAGE       |3       |2010-12-01 08:45:00|18.0     |12583.0   |France        |\n",
      "|536403   |POST     |POSTAGE       |1       |2010-12-01 11:27:00|15.0     |12791.0   |Netherlands   |\n",
      "|536527   |POST     |POSTAGE       |1       |2010-12-01 13:04:00|18.0     |12662.0   |Germany       |\n",
      "|536544   |DOT      |DOTCOM POSTAGE|1       |2010-12-01 14:32:00|569.77   |null      |United Kingdom|\n",
      "|536592   |DOT      |DOTCOM POSTAGE|1       |2010-12-01 17:06:00|607.49   |null      |United Kingdom|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(priceFilter | descripFilter).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description   |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|536544   |DOT      |DOTCOM POSTAGE|1       |2010-12-01 14:32:00|569.77   |null      |United Kingdom|\n",
      "|536592   |DOT      |DOTCOM POSTAGE|1       |2010-12-01 17:06:00|607.49   |null      |United Kingdom|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.StockCode.isin(\"DOT\")).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+---------+-----------+\n",
      "|StockCode|Description   |unitPrice|isExpensive|\n",
      "+---------+--------------+---------+-----------+\n",
      "|DOT      |DOTCOM POSTAGE|569.77   |true       |\n",
      "|DOT      |DOTCOM POSTAGE|607.49   |true       |\n",
      "+---------+--------------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import instr\n",
    "DOTCodeFilter = col(\"StockCode\") == \"DOT\"\n",
    "priceFilter = col(\"UnitPrice\") > 600\n",
    "descripFilter = instr(col(\"Description\"), \"POSTAGE\") >= 1\n",
    "df.withColumn(\"isExpensive\", DOTCodeFilter & (priceFilter | descripFilter))\\\n",
    "  .where(\"isExpensive\")\\\n",
    "  .select(\"StockCode\",\"Description\",\"unitPrice\", \"isExpensive\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------------+---------+-----------+\n",
      "|StockCode|Description                        |unitPrice|isExpensive|\n",
      "+---------+-----------------------------------+---------+-----------+\n",
      "|85123A   |WHITE HANGING HEART T-LIGHT HOLDER |2.55     |false      |\n",
      "|71053    |WHITE METAL LANTERN                |3.39     |false      |\n",
      "|84406B   |CREAM CUPID HEARTS COAT HANGER     |2.75     |false      |\n",
      "|84029G   |KNITTED UNION FLAG HOT WATER BOTTLE|3.39     |false      |\n",
      "|84029E   |RED WOOLLY HOTTIE WHITE HEART.     |3.39     |false      |\n",
      "+---------+-----------------------------------+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"isExpensive\", DOTCodeFilter & (priceFilter | descripFilter))\\\n",
    "  .select(\"StockCode\",\"Description\",\"unitPrice\", \"isExpensive\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+---------+-----------+\n",
      "|StockCode|Description   |unitPrice|isExpensive|\n",
      "+---------+--------------+---------+-----------+\n",
      "|DOT      |DOTCOM POSTAGE|569.77   |true       |\n",
      "|DOT      |DOTCOM POSTAGE|607.49   |true       |\n",
      "+---------+--------------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import expr\n",
    "df.withColumn(\"isExpensive\", expr(\"NOT UnitPrice <= 250\"))\\\n",
    "  .where(\"isExpensive\")\\\n",
    "  .select(\"StockCode\",\"Description\",\"unitPrice\", \"isExpensive\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description        |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+-------------------+--------+-------------------+---------+----------+--------------+\n",
      "|536365   |71053    |WHITE METAL LANTERN|6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|\n",
      "|536373   |71053    |WHITE METAL LANTERN|6       |2010-12-01 09:02:00|3.39     |17850.0   |United Kingdom|\n",
      "|536375   |71053    |WHITE METAL LANTERN|6       |2010-12-01 09:32:00|3.39     |17850.0   |United Kingdom|\n",
      "|536396   |71053    |WHITE METAL LANTERN|6       |2010-12-01 10:51:00|3.39     |17850.0   |United Kingdom|\n",
      "|536406   |71053    |WHITE METAL LANTERN|8       |2010-12-01 11:33:00|3.39     |17850.0   |United Kingdom|\n",
      "+---------+---------+-------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(col(\"Description\").eqNullSafe(\"WHITE METAL LANTERN\")).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(col(\"Description\") != \"WHITE METAL LANTERN\").where(col(\"Description\").isNull()).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+-----------+--------+-------------------+---------+----------+--------------+\n",
      "|536414   |22139    |null       |56      |2010-12-01 11:52:00|0.0      |null      |United Kingdom|\n",
      "|536545   |21134    |null       |1       |2010-12-01 14:32:00|0.0      |null      |United Kingdom|\n",
      "|536546   |22145    |null       |1       |2010-12-01 14:33:00|0.0      |null      |United Kingdom|\n",
      "|536547   |37509    |null       |1       |2010-12-01 14:33:00|0.0      |null      |United Kingdom|\n",
      "|536549   |85226A   |null       |1       |2010-12-01 14:34:00|0.0      |null      |United Kingdom|\n",
      "+---------+---------+-----------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(col(\"Description\").isNull()).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+---------+----------+-------+\n",
      "|        0|        0|         10|       0|        0|      1140|      0|\n",
      "+---------+---------+-----------+--------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "#df.select([count(when(isnan(c), c)).alias(c) for c in df.columns]).show() # not work due to Date Column\n",
    "df.select([count(when(col(c).isNull() |isnan(c), c)).alias(c)\\\n",
    "           for c in [x for x in df.columns if x != \"InvoiceDate\"]]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+---------+----------+-------+\n",
      "|        0|        0|          0|       0|        0|         0|      0|\n",
      "+---------+---------+-----------+--------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([count(when(isnan(c), c)).alias(c)\\\n",
    "           for c in [x for x in df.columns if x != \"InvoiceDate\"]]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|        0|        0|         10|       0|          0|        0|      1140|      0|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([count(when(col(c).isNull(), c)).alias(c)\\\n",
    "           for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|        0|        0|         10|       0|          0|        0|      1140|      0|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([count(when(col(c).isNull(), 1)).alias(c)\\\n",
    "           for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------+\n",
      "|count(CASE WHEN isnan(Description) THEN 1 END)|\n",
      "+----------------------------------------------+\n",
      "|                                             0|\n",
      "+----------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(count(when(isnan(\"Description\"), 1))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------+\n",
      "|count(CASE WHEN isnan(Description) THEN 1 ELSE 0 END)|\n",
      "+-----------------------------------------------------+\n",
      "|                                                 3108|\n",
      "+-----------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(count(when(isnan(\"Description\"), 1).otherwise(0))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|nanCount|count|\n",
      "+--------+-----+\n",
      "|       0| 3108|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(when(isnan(\"Description\"), 1).otherwise(0).alias(\"nanCount\")).groupBy(\"nanCount\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------+\n",
      "|CASE WHEN isnan(Description) THEN 1 ELSE 0 END|\n",
      "+----------------------------------------------+\n",
      "|                                             0|\n",
      "|                                             0|\n",
      "|                                             0|\n",
      "|                                             0|\n",
      "|                                             0|\n",
      "+----------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(when(isnan(\"Description\"), 1).otherwise(0)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3108\n",
      "3098\n",
      "10\n",
      "3108\n",
      "6\n",
      "6\n",
      "3092\n"
     ]
    }
   ],
   "source": [
    "print(df.select(col(\"Description\")).count())\n",
    "print(df.where(col(\"Description\").isNotNull()).count())\n",
    "print(df.where(col(\"Description\").isNull()).count())\n",
    "print(df.select(when(isnan(\"Description\"), 1)).count())\n",
    "\n",
    "print(df.where(col(\"Description\").eqNullSafe(\"WHITE METAL LANTERN\")).count())\n",
    "print(df.where(col(\"Description\") == \"WHITE METAL LANTERN\").count())\n",
    "print(df.where(col(\"Description\") != \"WHITE METAL LANTERN\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CustomerId|      realQuantity|\n",
      "+----------+------------------+\n",
      "|   17850.0|239.08999999999997|\n",
      "|   17850.0|          418.7156|\n",
      "+----------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import expr, pow\n",
    "\n",
    "fabricatedQuantity = pow(col(\"Quantity\") * col(\"UnitPrice\"), 2) + 5\n",
    "df.select(expr(\"CustomerId\"), fabricatedQuantity.alias(\"realQuantity\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CustomerId|      realQuantity|\n",
      "+----------+------------------+\n",
      "|   17850.0|239.08999999999997|\n",
      "|   17850.0|          418.7156|\n",
      "+----------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "df.selectExpr(\n",
    "  \"CustomerId\",\n",
    "  \"(POWER((Quantity * UnitPrice), 2.0) + 5) as realQuantity\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|round(2.5, 0)|bround(2.5, 0)|\n",
      "+-------------+--------------+\n",
      "|          3.0|           2.0|\n",
      "|          3.0|           2.0|\n",
      "+-------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import lit, round, bround\n",
    "\n",
    "df.select(round(lit(\"2.5\")), bround(lit(\"2.5\"))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04112314436835551"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import corr\n",
    "df.stat.corr(\"Quantity\", \"UnitPrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|corr(Quantity, UnitPrice)|\n",
      "+-------------------------+\n",
      "|     -0.04112314436835551|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(corr(\"Quantity\", \"UnitPrice\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- summary: string (nullable = true)\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- UnitPrice: string (nullable = true)\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "df.describe().printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['summary',\n",
       " 'InvoiceNo',\n",
       " 'StockCode',\n",
       " 'Description',\n",
       " 'Quantity',\n",
       " 'UnitPrice',\n",
       " 'CustomerID',\n",
       " 'Country']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+--------------------+------------------+\n",
      "|summary|        InvoiceNo|         StockCode|         Description|          Quantity|\n",
      "+-------+-----------------+------------------+--------------------+------------------+\n",
      "|  count|             3108|              3108|                3098|              3108|\n",
      "|   mean| 536516.684944841|27834.304044117645|                null| 8.627413127413128|\n",
      "| stddev|72.89447869788873|17407.897548583845|                null|26.371821677029203|\n",
      "|    min|           536365|             10002| 4 PURPLE FLOCK D...|               -24|\n",
      "|    max|          C536548|              POST|ZINC WILLIE WINKI...|               600|\n",
      "+-------+-----------------+------------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().select('summary',\n",
    " 'InvoiceNo',\n",
    " 'StockCode',\n",
    " 'Description',\n",
    " 'Quantity').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+--------------+\n",
      "|summary|         UnitPrice|        CustomerID|       Country|\n",
      "+-------+------------------+------------------+--------------+\n",
      "|  count|              3108|              1968|          3108|\n",
      "|   mean| 4.151946589446603|15661.388719512195|          null|\n",
      "| stddev|15.638659854603892|1854.4496996893627|          null|\n",
      "|    min|               0.0|           12431.0|     Australia|\n",
      "|    max|            607.49|           18229.0|United Kingdom|\n",
      "+-------+------------------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().select('summary',\n",
    " 'UnitPrice',\n",
    " 'CustomerID',\n",
    " 'Country').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import count, mean, stddev_pop, min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.51]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "colName = \"UnitPrice\"\n",
    "quantileProbs = [0.5]\n",
    "relError = 0.05\n",
    "df.stat.approxQuantile(\"UnitPrice\", quantileProbs, relError) # 2.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- StockCode_Quantity: string (nullable = true)\n",
      " |-- -1: long (nullable = true)\n",
      " |-- -10: long (nullable = true)\n",
      " |-- -12: long (nullable = true)\n",
      " |-- -2: long (nullable = true)\n",
      " |-- -24: long (nullable = true)\n",
      " |-- -3: long (nullable = true)\n",
      " |-- -4: long (nullable = true)\n",
      " |-- -5: long (nullable = true)\n",
      " |-- -6: long (nullable = true)\n",
      " |-- -7: long (nullable = true)\n",
      " |-- 1: long (nullable = true)\n",
      " |-- 10: long (nullable = true)\n",
      " |-- 100: long (nullable = true)\n",
      " |-- 11: long (nullable = true)\n",
      " |-- 12: long (nullable = true)\n",
      " |-- 120: long (nullable = true)\n",
      " |-- 128: long (nullable = true)\n",
      " |-- 13: long (nullable = true)\n",
      " |-- 14: long (nullable = true)\n",
      " |-- 144: long (nullable = true)\n",
      " |-- 15: long (nullable = true)\n",
      " |-- 16: long (nullable = true)\n",
      " |-- 17: long (nullable = true)\n",
      " |-- 18: long (nullable = true)\n",
      " |-- 19: long (nullable = true)\n",
      " |-- 192: long (nullable = true)\n",
      " |-- 2: long (nullable = true)\n",
      " |-- 20: long (nullable = true)\n",
      " |-- 200: long (nullable = true)\n",
      " |-- 21: long (nullable = true)\n",
      " |-- 216: long (nullable = true)\n",
      " |-- 22: long (nullable = true)\n",
      " |-- 23: long (nullable = true)\n",
      " |-- 24: long (nullable = true)\n",
      " |-- 25: long (nullable = true)\n",
      " |-- 252: long (nullable = true)\n",
      " |-- 27: long (nullable = true)\n",
      " |-- 28: long (nullable = true)\n",
      " |-- 288: long (nullable = true)\n",
      " |-- 3: long (nullable = true)\n",
      " |-- 30: long (nullable = true)\n",
      " |-- 32: long (nullable = true)\n",
      " |-- 33: long (nullable = true)\n",
      " |-- 34: long (nullable = true)\n",
      " |-- 36: long (nullable = true)\n",
      " |-- 384: long (nullable = true)\n",
      " |-- 4: long (nullable = true)\n",
      " |-- 40: long (nullable = true)\n",
      " |-- 432: long (nullable = true)\n",
      " |-- 47: long (nullable = true)\n",
      " |-- 48: long (nullable = true)\n",
      " |-- 480: long (nullable = true)\n",
      " |-- 5: long (nullable = true)\n",
      " |-- 50: long (nullable = true)\n",
      " |-- 56: long (nullable = true)\n",
      " |-- 6: long (nullable = true)\n",
      " |-- 60: long (nullable = true)\n",
      " |-- 600: long (nullable = true)\n",
      " |-- 64: long (nullable = true)\n",
      " |-- 7: long (nullable = true)\n",
      " |-- 70: long (nullable = true)\n",
      " |-- 72: long (nullable = true)\n",
      " |-- 8: long (nullable = true)\n",
      " |-- 80: long (nullable = true)\n",
      " |-- 9: long (nullable = true)\n",
      " |-- 96: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.stat.crosstab(\"StockCode\", \"Quantity\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(StockCode_Quantity=u'22578', -1=0, -10=0, -12=0, -2=0, -24=0, -3=0, -4=0, -5=0, -6=0, -7=0, 1=0, 10=0, 100=0, 11=0, 12=0, 120=0, 128=0, 13=0, 14=0, 144=0, 15=0, 16=0, 17=0, 18=0, 19=0, 192=0, 2=0, 20=0, 200=0, 21=0, 216=0, 22=0, 23=0, 24=1, 25=0, 252=0, 27=0, 28=0, 288=0, 3=0, 30=0, 32=0, 33=0, 34=0, 36=0, 384=0, 4=0, 40=0, 432=0, 47=0, 48=0, 480=0, 5=0, 50=0, 56=0, 6=0, 60=0, 600=0, 64=0, 7=0, 70=0, 72=0, 8=0, 80=0, 9=0, 96=0),\n",
       " Row(StockCode_Quantity=u'21327', -1=0, -10=0, -12=0, -2=0, -24=0, -3=0, -4=0, -5=0, -6=0, -7=0, 1=2, 10=0, 100=0, 11=0, 12=0, 120=0, 128=0, 13=0, 14=0, 144=0, 15=0, 16=0, 17=0, 18=0, 19=0, 192=0, 2=0, 20=0, 200=0, 21=0, 216=0, 22=0, 23=0, 24=0, 25=0, 252=0, 27=0, 28=0, 288=0, 3=0, 30=0, 32=0, 33=0, 34=0, 36=0, 384=0, 4=0, 40=0, 432=0, 47=0, 48=0, 480=0, 5=0, 50=0, 56=0, 6=0, 60=0, 600=0, 64=0, 7=0, 70=0, 72=0, 8=0, 80=0, 9=0, 96=0),\n",
       " Row(StockCode_Quantity=u'22064', -1=0, -10=0, -12=0, -2=0, -24=0, -3=0, -4=0, -5=0, -6=0, -7=0, 1=1, 10=0, 100=0, 11=0, 12=1, 120=0, 128=0, 13=0, 14=0, 144=0, 15=0, 16=0, 17=0, 18=0, 19=0, 192=0, 2=1, 20=0, 200=0, 21=0, 216=0, 22=0, 23=0, 24=0, 25=0, 252=0, 27=0, 28=0, 288=0, 3=0, 30=0, 32=0, 33=0, 34=0, 36=0, 384=0, 4=0, 40=0, 432=0, 47=0, 48=0, 480=0, 5=0, 50=0, 56=0, 6=0, 60=0, 600=0, 64=0, 7=0, 70=0, 72=0, 8=0, 80=0, 9=0, 96=0)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "df.stat.crosstab(\"StockCode\", \"Quantity\").take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- StockCode_freqItems: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- Quantity_freqItems: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(StockCode_freqItems=[u'90214E', u'20728', u'20755', u'21703', u'22113', u'22524', u'22041', u'72803A', u'72798C', u'90181B', u'21756', u'22694', u'90206C', u'20970', u'21624', u'90209C', u'84744', u'82494L', u'22952', u'20682', u'22583', u'21705', u'20679', u'22220', u'90177E', u'90214A', u'22448', u'90214S', u'22121', u'22802', u'84970L', u'72818', u'90192', u'90200C', u'22910', u'21380', u'90211A', u'21137', u'35271S', u'84926A', u'20765', u'22384', u'21524', u'22165', u'22366', u'21221', u'21704', u'22519', u'85035C', u'21967', u'22114', u'22909', u'22900', u'22447', u'21577', u'21877', u'20726', u'85034A', u'DOT', u'84658', u'21472', u'22804', u'22222', u'72802C', u'21739', u'22467', u'90214H', u'22785', u'22446', u'22197', u'20665', u'21733', u'22731', u'21709', u'22086', u'40001', u'85123A'], Quantity_freqItems=[200, 128, 23, 32, 50, 600, 8, 17, 80, -1, -10, 11, 56, 47, 20, -7, 2, 5, 480, -4, 14, 432, 100, 64, 40, 13, 4, -5, 22, 16, -2, 7, 70, 384, 25, 34, 10, 1, 288, 216, 28, 252, 19, 120, 192, 60, 96, 72, 144, 36, 27, 9, 18, 48, 21, 12, 3, -6, -24, 30, 15, 33, 6, 24, -12, -3])]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "df.stat.freqItems([\"StockCode\", \"Quantity\"]).printSchema()\n",
    "df.stat.freqItems([\"StockCode\", \"Quantity\"]).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "df = df.withColumn(\"index\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+-----+\n",
      "|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |index|\n",
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+-----+\n",
      "|536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER |6       |2010-12-01 08:26:00|2.55     |17850.0   |United Kingdom|0    |\n",
      "|536365   |71053    |WHITE METAL LANTERN                |6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|1    |\n",
      "|536365   |84406B   |CREAM CUPID HEARTS COAT HANGER     |8       |2010-12-01 08:26:00|2.75     |17850.0   |United Kingdom|2    |\n",
      "|536365   |84029G   |KNITTED UNION FLAG HOT WATER BOTTLE|6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|3    |\n",
      "|536365   |84029E   |RED WOOLLY HOTTIE WHITE HEART.     |6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|4    |\n",
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3108"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+-----+\n",
      "|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |index|\n",
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+-----+\n",
      "|536597   |21739    |COSY SLIPPER SHOES SMALL GREEN     |1       |2010-12-01 17:35:00|2.95     |18011.0   |United Kingdom|3096 |\n",
      "|536597   |85034A   |3 GARDENIA MORRIS BOXED CANDLES    |1       |2010-12-01 17:35:00|4.25     |18011.0   |United Kingdom|3097 |\n",
      "|536597   |72818    |CHRISTMAS DECOUPAGE CANDLE         |4       |2010-12-01 17:35:00|0.85     |18011.0   |United Kingdom|3098 |\n",
      "|536597   |72798C   |SET/4 GARDEN ROSE DINNER CANDLE    |1       |2010-12-01 17:35:00|1.65     |18011.0   |United Kingdom|3099 |\n",
      "|536597   |22197    |SMALL POPCORN HOLDER               |6       |2010-12-01 17:35:00|0.85     |18011.0   |United Kingdom|3100 |\n",
      "|536597   |20726    |LUNCH BAG WOODLAND                 |1       |2010-12-01 17:35:00|1.65     |18011.0   |United Kingdom|3101 |\n",
      "|536597   |84744    |S/6 SEW ON CROCHET FLOWERS         |1       |2010-12-01 17:35:00|1.25     |18011.0   |United Kingdom|3102 |\n",
      "|536597   |35271S   |GOLD PRINT PAPER BAG               |14      |2010-12-01 17:35:00|0.19     |18011.0   |United Kingdom|3103 |\n",
      "|536597   |21380    |WOODEN HAPPY BIRTHDAY GARLAND      |1       |2010-12-01 17:35:00|2.95     |18011.0   |United Kingdom|3104 |\n",
      "|536597   |22909    |SET OF 20 VINTAGE CHRISTMAS NAPKINS|1       |2010-12-01 17:35:00|0.85     |18011.0   |United Kingdom|3105 |\n",
      "|536597   |21221    |SET/4 BADGES CUTE CREATURES        |5       |2010-12-01 17:35:00|1.25     |18011.0   |United Kingdom|3106 |\n",
      "|536597   |20755    |BLUE PAISLEY POCKET BOOK           |6       |2010-12-01 17:35:00|0.85     |18011.0   |United Kingdom|3107 |\n",
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"index > 3095\").show(30,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+\n",
      "|initcap(Description)               |\n",
      "+-----------------------------------+\n",
      "|White Hanging Heart T-light Holder |\n",
      "|White Metal Lantern                |\n",
      "|Cream Cupid Hearts Coat Hanger     |\n",
      "|Knitted Union Flag Hot Water Bottle|\n",
      "+-----------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import initcap\n",
    "df.select(initcap(col(\"Description\"))).show(4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+----------------------------------+----------------------------------+\n",
      "|Description                       |lower(Description)                |upper(lower(Description))         |\n",
      "+----------------------------------+----------------------------------+----------------------------------+\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|white hanging heart t-light holder|WHITE HANGING HEART T-LIGHT HOLDER|\n",
      "|WHITE METAL LANTERN               |white metal lantern               |WHITE METAL LANTERN               |\n",
      "|CREAM CUPID HEARTS COAT HANGER    |cream cupid hearts coat hanger    |CREAM CUPID HEARTS COAT HANGER    |\n",
      "+----------------------------------+----------------------------------+----------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import lower, upper\n",
    "df.select(col(\"Description\"),\n",
    "    lower(col(\"Description\")),\n",
    "    upper(lower(col(\"Description\")))).show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----+---+----------+---+----------+\n",
      "|ltrim    |rtrim    |trim |lp3|lp10      |rp3|rp10      |\n",
      "+---------+---------+-----+---+----------+---+----------+\n",
      "|HELLO    |    HELLO|HELLO|HEL|     HELLO|HEL|HELLO     |\n",
      "|HELLO    |    HELLO|HELLO|HEL|     HELLO|HEL|HELLO     |\n",
      "|HELLO    |    HELLO|HELLO|HEL|     HELLO|HEL|HELLO     |\n",
      "|HELLO    |    HELLO|HELLO|HEL|     HELLO|HEL|HELLO     |\n",
      "+---------+---------+-----+---+----------+---+----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import lit, ltrim, rtrim, rpad, lpad, trim\n",
    "df.select(\n",
    "    ltrim(lit(\"    HELLO    \")).alias(\"ltrim\"),\n",
    "    rtrim(lit(\"    HELLO    \")).alias(\"rtrim\"),\n",
    "    trim(lit(\"    HELLO    \")).alias(\"trim\"),\n",
    "    lpad(lit(\"HELLO\"), 3, \" \").alias(\"lp3\"),\n",
    "    lpad(lit(\"HELLO\"), 10, \" \").alias(\"lp10\"),\n",
    "    rpad(lit(\"HELLO\"), 3, \" \").alias(\"rp3\"),\n",
    "    rpad(lit(\"HELLO\"), 10, \" \").alias(\"rp10\")\n",
    ").show(4, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "regex_string = \"BLACK|WHITE|RED|GREEN|BLUE\"\n",
    "df.select(\n",
    "  regexp_replace(col(\"Description\"), regex_string, \"COLOR\").alias(\"color_clean\"),\n",
    "  col(\"Description\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import translate\n",
    "df.select(translate(col(\"Description\"), \"LEET\", \"1337\"),col(\"Description\"))\\\n",
    "  .show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import regexp_extract\n",
    "extract_str = \"(BLACK|WHITE|RED|GREEN|BLUE)\"\n",
    "df.select(\n",
    "     regexp_extract(col(\"Description\"), extract_str, 1).alias(\"color_clean\"),\n",
    "     col(\"Description\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import instr\n",
    "containsBlack = instr(col(\"Description\"), \"BLACK\") >= 1\n",
    "containsWhite = instr(col(\"Description\"), \"WHITE\") >= 1\n",
    "df.withColumn(\"hasSimpleColor\", containsBlack | containsWhite)\\\n",
    "  .where(\"hasSimpleColor\")\\\n",
    "  .select(\"Description\").show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import expr, locate\n",
    "simpleColors = [\"black\", \"white\", \"red\", \"green\", \"blue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color_locator(column, color_string):\n",
    "  return locate(color_string.upper(), column)\\\n",
    "          .cast(\"boolean\")\\\n",
    "          .alias(\"is_\" + color_string)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selectedColumns = [color_locator(df.Description, c) for c in simpleColors]\n",
    "selectedColumns.append(expr(\"*\")) # has to a be Column type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.select(*selectedColumns).where(expr(\"is_white OR is_red\"))\\\n",
    "  .select(\"Description\").show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import current_date, current_timestamp\n",
    "dateDF = spark.range(10)\\\n",
    "  .withColumn(\"today\", current_date())\\\n",
    "  .withColumn(\"now\", current_timestamp())\n",
    "dateDF.createOrReplaceTempView(\"dateTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import date_add, date_sub\n",
    "dateDF.select(date_sub(col(\"today\"), 5), date_add(col(\"today\"), 5)).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import datediff, months_between, to_date\n",
    "dateDF.withColumn(\"week_ago\", date_sub(col(\"today\"), 7))\\\n",
    "  .select(datediff(col(\"week_ago\"), col(\"today\"))).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dateDF.select(\n",
    "    to_date(lit(\"2016-01-01\")).alias(\"start\"),\n",
    "    to_date(lit(\"2017-05-22\")).alias(\"end\"))\\\n",
    "  .select(months_between(col(\"start\"), col(\"end\"))).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import to_date, lit\n",
    "spark.range(5).withColumn(\"date\", lit(\"2017-01-01\"))\\\n",
    "  .select(to_date(col(\"date\"))).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import to_date\n",
    "dateFormat = \"yyyy-dd-MM\"\n",
    "cleanDateDF = spark.range(1).select(\n",
    "    to_date(lit(\"2017-12-11\"), dateFormat).alias(\"date\"),\n",
    "    to_date(lit(\"2017-20-12\"), dateFormat).alias(\"date2\"))\n",
    "cleanDateDF.createOrReplaceTempView(\"dateTable2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "cleanDateDF.select(to_timestamp(col(\"date\"), dateFormat)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import coalesce\n",
    "df.select(coalesce(col(\"Description\"), col(\"CustomerId\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "df.na.drop(\"all\", subset=[\"StockCode\", \"InvoiceNo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "df.na.fill(\"all\", subset=[\"StockCode\", \"InvoiceNo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "fill_cols_vals = {\"StockCode\": 5, \"Description\" : \"No Value\"}\n",
    "df.na.fill(fill_cols_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "df.na.replace([\"\"], [\"UNKNOWN\"], \"Description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import struct\n",
    "complexDF = df.select(struct(\"Description\", \"InvoiceNo\").alias(\"complex\"))\n",
    "complexDF.createOrReplaceTempView(\"complexDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import split\n",
    "df.select(split(col(\"Description\"), \" \")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "df.select(split(col(\"Description\"), \" \").alias(\"array_col\"))\\\n",
    "  .selectExpr(\"array_col[0]\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import size\n",
    "df.select(size(split(col(\"Description\"), \" \"))).show(2) # shows 5 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import array_contains\n",
    "df.select(array_contains(split(col(\"Description\"), \" \"), \"WHITE\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import split, explode\n",
    "\n",
    "df.withColumn(\"splitted\", split(col(\"Description\"), \" \"))\\\n",
    "  .withColumn(\"exploded\", explode(col(\"splitted\")))\\\n",
    "  .select(\"Description\", \"InvoiceNo\", \"exploded\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import create_map\n",
    "df.select(create_map(col(\"Description\"), col(\"InvoiceNo\")).alias(\"complex_map\"))\\\n",
    "  .show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "df.select(map(col(\"Description\"), col(\"InvoiceNo\")).alias(\"complex_map\"))\\\n",
    "  .selectExpr(\"complex_map['WHITE METAL LANTERN']\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "df.select(map(col(\"Description\"), col(\"InvoiceNo\")).alias(\"complex_map\"))\\\n",
    "  .selectExpr(\"explode(complex_map)\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "jsonDF = spark.range(1).selectExpr(\"\"\"\n",
    "  '{\"myJSONKey\" : {\"myJSONValue\" : [1, 2, 3]}}' as jsonString\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import get_json_object, json_tuple\n",
    "\n",
    "jsonDF.select(\n",
    "    get_json_object(col(\"jsonString\"), \"$.myJSONKey.myJSONValue[1]\") as \"column\",\n",
    "    json_tuple(col(\"jsonString\"), \"myJSONKey\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import to_json\n",
    "df.selectExpr(\"(InvoiceNo, Description) as myStruct\")\\\n",
    "  .select(to_json(col(\"myStruct\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import from_json\n",
    "from pyspark.sql.types import *\n",
    "parseSchema = StructType((\n",
    "  StructField(\"InvoiceNo\",StringType(),True),\n",
    "  StructField(\"Description\",StringType(),True)))\n",
    "df.selectExpr(\"(InvoiceNo, Description) as myStruct\")\\\n",
    "  .select(to_json(col(\"myStruct\")).alias(\"newJSON\"))\\\n",
    "  .select(from_json(col(\"newJSON\"), parseSchema), col(\"newJSON\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "udfExampleDF = spark.range(5).toDF(\"num\")\n",
    "def power3(double_value):\n",
    "  return double_value ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "power3(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "power3udf = udf(power3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "udfExampleDF.select(power3udf(col(\"num\"))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "udfExampleDF.selectExpr(\"power3(num)\").show(2)\n",
    "# registered in Scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "spark.udf.register(\"power3py\", power3, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "udfExampleDF.selectExpr(\"power3py(num)\").show(2)\n",
    "# registered via Python\n",
    "\n",
    "\n",
    "# COMMAND ----------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark2.7_home",
   "language": "python",
   "name": "pyspark2.7_home"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
