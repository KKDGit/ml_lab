{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/hdp/current/spark2-client'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/hdp/current/spark2-client')\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"yarn\").appName(\"ch03SparkToolSet-Streaming3\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'http://gw02.itversity.com:4043'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "sc._jsc.sc().uiWebUrl().get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://rm01.itversity.com:19288/proxy/application_1533622723243_12037\n",
      "rm01.itversity.com\n",
      "http://rm01.itversity.com:19288/proxy/application_1533622723243_12037\n",
      "http://gw02.itversity.com:4043\n"
     ]
    }
   ],
   "source": [
    "for x in sc._conf.getAll():\n",
    "    if 'PROXY' in x[0]:\n",
    "        print(x[1])\n",
    "print(spark.conf.get('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES'))\n",
    "print(spark.conf.get('spark.driver.appUIAddress'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "staticDataFrame = spark.read.format(\"csv\")\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .option(\"inferSchema\", \"true\")\\\n",
    "  .load(\"/user/kranthidr/dataSets/spark-guide/data/retail-data/by-day/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "staticDataFrame.createOrReplaceTempView(\"retail_data\")\n",
    "staticSchema = staticDataFrame.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "staticDataFrame.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                    |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+-------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|580538   |23084    |RABBIT NIGHT LIGHT             |48      |2011-12-05 08:38:00|1.79     |14075.0   |United Kingdom|\n",
      "|580538   |23077    |DOUGHNUT LIP GLOSS             |20      |2011-12-05 08:38:00|1.25     |14075.0   |United Kingdom|\n",
      "|580538   |22906    |12 MESSAGE CARDS WITH ENVELOPES|24      |2011-12-05 08:38:00|1.65     |14075.0   |United Kingdom|\n",
      "|580538   |21914    |BLUE HARMONICA IN BOX          |24      |2011-12-05 08:38:00|1.25     |14075.0   |United Kingdom|\n",
      "|580538   |22467    |GUMBALL COAT RACK              |6       |2011-12-05 08:38:00|2.55     |14075.0   |United Kingdom|\n",
      "+---------+---------+-------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "staticDataFrame.show(truncate=False, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'2.3.0.2.6.5.0-292'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "from pyspark.sql.functions import window, column, desc, col\n",
    "t1 = staticDataFrame\\\n",
    "  .selectExpr(\"CustomerId\", \"(UnitPrice * Quantity) as total_cost\", \"InvoiceDate\")\\\n",
    "  .groupBy(col(\"CustomerId\"), window(col(\"InvoiceDate\"), \"1 day\"))\\\n",
    "  .sum(\"total_cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------------------------------+-----------------+\n",
      "|CustomerId|window                                    |sum(total_cost)  |\n",
      "+----------+------------------------------------------+-----------------+\n",
      "|16057.0   |[2011-12-04 19:00:00, 2011-12-05 19:00:00]|-37.6            |\n",
      "|14126.0   |[2011-11-28 19:00:00, 2011-11-29 19:00:00]|643.6300000000001|\n",
      "|13500.0   |[2011-11-15 19:00:00, 2011-11-16 19:00:00]|497.9700000000001|\n",
      "|17160.0   |[2011-11-07 19:00:00, 2011-11-08 19:00:00]|516.8499999999999|\n",
      "|15608.0   |[2011-11-10 19:00:00, 2011-11-11 19:00:00]|122.4            |\n",
      "+----------+------------------------------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " t1.show(n=5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------+----------+-------------------+\n",
      "|CustomerId|UnitPrice|Quantity|total_cost|        InvoiceDate|\n",
      "+----------+---------+--------+----------+-------------------+\n",
      "|   16057.0|    12.75|      -1|    -12.75|2011-12-05 16:36:00|\n",
      "|   16057.0|     9.95|      -2|     -19.9|2011-12-05 16:36:00|\n",
      "|   16057.0|     4.95|      -1|     -4.95|2011-12-05 16:36:00|\n",
      "+----------+---------+--------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "staticDataFrame\\\n",
    "  .selectExpr(\"CustomerId\", \"UnitPrice\", \"Quantity\", \"(UnitPrice * Quantity) as total_cost\", \"InvoiceDate\")\\\n",
    "  .where(col(\"CustomerId\") == '16057.0').where(col(\"InvoiceDate\") >= '2011-12-04 19:00:00')\\\n",
    ".where(col(\"InvoiceDate\") <= '2011-12-05 19:00:00').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(CustomerId=16813.0, window=Row(start=datetime.datetime(2011, 11, 30, 19, 0), end=datetime.datetime(2011, 12, 1, 19, 0)), sum(total_cost)=148.54000000000002)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[CustomerId#16, window#132], functions=[sum(total_cost#122)])\n",
      "+- Exchange hashpartitioning(CustomerId#16, window#132, 200)\n",
      "   +- *(1) HashAggregate(keys=[CustomerId#16, window#132], functions=[partial_sum(total_cost#122)])\n",
      "      +- *(1) Project [named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(InvoiceDate#14, TimestampType, LongType) - 0) as double) / 8.64E10)) as double) = (cast((precisetimestampconversion(InvoiceDate#14, TimestampType, LongType) - 0) as double) / 8.64E10)) THEN (CEIL((cast((precisetimestampconversion(InvoiceDate#14, TimestampType, LongType) - 0) as double) / 8.64E10)) + 1) ELSE CEIL((cast((precisetimestampconversion(InvoiceDate#14, TimestampType, LongType) - 0) as double) / 8.64E10)) END + 0) - 1) * 86400000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(InvoiceDate#14, TimestampType, LongType) - 0) as double) / 8.64E10)) as double) = (cast((precisetimestampconversion(InvoiceDate#14, TimestampType, LongType) - 0) as double) / 8.64E10)) THEN (CEIL((cast((precisetimestampconversion(InvoiceDate#14, TimestampType, LongType) - 0) as double) / 8.64E10)) + 1) ELSE CEIL((cast((precisetimestampconversion(InvoiceDate#14, TimestampType, LongType) - 0) as double) / 8.64E10)) END + 0) - 1) * 86400000000) + 86400000000), LongType, TimestampType)) AS window#132, CustomerId#16, (UnitPrice#15 * cast(Quantity#13 as double)) AS total_cost#122]\n",
      "         +- *(1) Filter isnotnull(InvoiceDate#14)\n",
      "            +- *(1) FileScan csv [Quantity#13,InvoiceDate#14,UnitPrice#15,CustomerID#16] Batched: false, Format: CSV, Location: InMemoryFileIndex[hdfs://nn01.itversity.com:8020/user/kranthidr/dataSets/spark-guide/data/retail-..., PartitionFilters: [], PushedFilters: [IsNotNull(InvoiceDate)], ReadSchema: struct<Quantity:int,InvoiceDate:timestamp,UnitPrice:double,CustomerID:double>\n"
     ]
    }
   ],
   "source": [
    "t1.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CustomerId: double (nullable = true)\n",
      " |-- window: struct (nullable = false)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- sum(total_cost): double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "streamingDataFrame = spark.readStream\\\n",
    "    .schema(staticSchema)\\\n",
    "    .option(\"maxFilesPerTrigger\", 1)\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .load(\"/user/kranthidr/dataSets/spark-guide/data/retail-data/by-day/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "org.apache.spark.sql.AnalysisException: Queries with streaming sources must be executed with writeStream.start();;\n",
      "FileSource[/user/kranthidr/dataSets/spark-guide/data/retail-data/by-day/*.csv]\n"
     ]
    }
   ],
   "source": [
    "streamingDataFrame.explain() # note the Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "purchaseByCustomerPerHour = streamingDataFrame\\\n",
    "  .selectExpr(\n",
    "    \"CustomerId\",\n",
    "    \"(UnitPrice * Quantity) as total_cost\",\n",
    "    \"InvoiceDate\")\\\n",
    "  .groupBy(\n",
    "    col(\"CustomerId\"), window(col(\"InvoiceDate\"), \"1 day\"))\\\n",
    "  .sum(\"total_cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x71d6ea29f990>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "purchaseByCustomerPerHour.writeStream\\\n",
    "    .format(\"memory\")\\\n",
    "    .queryName(\"customer_purchases\")\\\n",
    "    .outputMode(\"complete\")\\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---------------+\n",
      "|CustomerId|window|sum(total_cost)|\n",
      "+----------+------+---------------+\n",
      "+----------+------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "  SELECT *\n",
    "  FROM customer_purchases\n",
    "  ORDER BY `sum(total_cost)` DESC\n",
    "  \"\"\")\\\n",
    "  .show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------------------+\n",
      "|CustomerId|              window|   sum(total_cost)|\n",
      "+----------+--------------------+------------------+\n",
      "|   15605.0|[2010-11-30 19:00...|194.85000000000002|\n",
      "|   14142.0|[2010-11-30 19:00...|311.81000000000006|\n",
      "|   17968.0|[2010-11-30 19:00...|277.34999999999997|\n",
      "|   17069.0|[2010-11-30 19:00...|            277.05|\n",
      "|   15100.0|[2010-11-30 19:00...|             350.4|\n",
      "|   15525.0|[2010-11-30 19:00...| 313.9299999999999|\n",
      "|   17643.0|[2010-11-30 19:00...|101.55000000000001|\n",
      "|   16928.0|[2010-11-30 19:00...|            116.25|\n",
      "|   16552.0|[2010-11-30 19:00...|             95.29|\n",
      "|   12838.0|[2010-11-30 19:00...|390.78999999999985|\n",
      "|   13767.0|[2010-11-30 19:00...| 507.8800000000001|\n",
      "|   16456.0|[2010-11-30 19:00...|             787.4|\n",
      "|   16098.0|[2010-11-30 19:00...|430.59999999999997|\n",
      "|   15235.0|[2010-11-30 19:00...|              79.5|\n",
      "|   14307.0|[2010-11-30 19:00...| 783.1099999999999|\n",
      "|   14606.0|[2010-11-30 19:00...|            198.32|\n",
      "|   14688.0|[2010-11-30 19:00...|            444.98|\n",
      "|   12431.0|[2010-11-30 19:00...|            358.25|\n",
      "|   14696.0|[2010-11-30 19:00...|294.61999999999995|\n",
      "|   17873.0|[2010-11-30 19:00...|215.14999999999998|\n",
      "+----------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  SELECT *\n",
    "  FROM customer_purchases\n",
    "  ORDER BY `window` DESC\n",
    "  \"\"\")\\\n",
    "  .show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# purchaseByCustomerPerHour.writeStream\\\n",
    "#     .format(\"console\")\\\n",
    "#     .queryName(\"customer_purchases_2\")\\\n",
    "#     .outputMode(\"complete\")\\\n",
    "#     .start()\n",
    "\n",
    "#check on Console"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark2.7_home",
   "language": "python",
   "name": "pyspark2.7_home"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
