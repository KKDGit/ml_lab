{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@5207476f\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ul>\n",
       "<li><a href=\"Some(http://gw02.itversity.com:4042)\" target=\"new_tab\">Spark UI: application_1533622723243_13396</a></li>\n",
       "</ul>"
      ],
      "text/plain": [
       "Spark application_1533622723243_13396: Some(http://gw02.itversity.com:4042)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession.builder()\n",
    "                        .master(\"yarn\")\n",
    "                        .appName(\"ch06_wiki_LSA-nsc\")\n",
    "                        .config(\"spark.jars\",\"ch06-lsa-2.0.0-jar-with-dependencies.jar\")\n",
    "                        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|  id|\n",
      "+----+\n",
      "|2675|\n",
      "|2019|\n",
      "|3284|\n",
      "| 381|\n",
      "|2596|\n",
      "|3292|\n",
      "|3382|\n",
      "| 235|\n",
      "|3338|\n",
      "|2265|\n",
      "|2975|\n",
      "|2164|\n",
      "|1834|\n",
      "|4941|\n",
      "|3129|\n",
      "|4126|\n",
      "|2847|\n",
      "|3740|\n",
      "|3426|\n",
      "|2458|\n",
      "+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.range(10000).repartition(10).toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:26: error: object umd is not a member of package edu\n",
       "       import edu.umd.cloud9.collection.XMLInputFormat\n",
       "                  ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import edu.umd.cloud9.collection.XMLInputFormat\n",
    "\n",
    "import org.apache.hadoop.conf.Configuration\n",
    "import org.apache.hadoop.io._ //{LongWritable, Text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import edu.umd.cloud9.collection.wikipedia._//WikipediaPage\n",
    "import edu.umd.cloud9.collection.wikipedia.language._//EnglishWikipediaPage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def wikiXmlToPlainText(pageXml: String): Option[(String, String)] = {\n",
    "    val page = new EnglishWikipediaPage()\n",
    "\n",
    "    // Wikipedia has updated their dumps slightly since Cloud9 was written, so this hacky replacement is sometimes\n",
    "    // required to get parsing to work.\n",
    "    val hackedPageXml = pageXml.replaceFirst(\n",
    "      \"<text xml:space=\\\"preserve\\\" bytes=\\\"\\\\d+\\\">\", \"<text xml:space=\\\"preserve\\\">\")\n",
    "\n",
    "    WikipediaPage.readPage(page, hackedPageXml)\n",
    "    if (page.isEmpty || !page.isArticle || page.isRedirect || page.isDisambiguation ||\n",
    "        page.getTitle.contains(\"(disambiguation)\")) {\n",
    "      None\n",
    "    } else {\n",
    "      Some((page.getTitle, page.getContent))\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val path = \"/user/kranthidr/dataSets/wikidump-02-sept-2018.xml\"\n",
    "@transient val conf = new Configuration()\n",
    "\n",
    "    conf.set(XMLInputFormat.START_TAG_KEY, \"<page>\")\n",
    "    conf.set(XMLInputFormat.END_TAG_KEY, \"</page>\")\n",
    "\n",
    "    val kvs = spark.sparkContext.newAPIHadoopFile(path, \n",
    "                                                  classOf[XMLInputFormat], \n",
    "                                                  classOf[LongWritable],\n",
    "                                                  classOf[Text], \n",
    "                                                  conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    val rawXmls = kvs.map(_._2.toString).toDS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawXmls.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  val docTexts =  rawXmls.filter(_ != null).flatMap(wikiXmlToPlainText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docTexts.take(1).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// docTexts.show(1, false) \n",
    "//Not Good print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docTexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawXmls.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docTexts.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scala.collection.JavaConverters._\n",
    "import scala.collection.mutable.ArrayBuffer\n",
    "\n",
    "import edu.stanford.nlp.ling.CoreAnnotations._ //{LemmaAnnotation, SentencesAnnotation, TokensAnnotation}\n",
    "import edu.stanford.nlp.pipeline._ //{Annotation, StanfordCoreNLP}\n",
    "\n",
    "import java.util.Properties\n",
    "\n",
    "import org.apache.spark.ml.feature._ //{CountVectorizer, IDF}\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql._ //{DataFrame, Dataset, SparkSession}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def createNLPPipeline(): StanfordCoreNLP = {\n",
    "    val props = new Properties()\n",
    "    props.put(\"annotators\", \"tokenize, ssplit, pos, lemma\")\n",
    "    new StanfordCoreNLP(props)\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def isOnlyLetters(str: String): Boolean = {\n",
    "    str.forall(c => Character.isLetter(c))\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def plainTextToLemmas(text: String, stopWords: Set[String], pipeline: StanfordCoreNLP)\n",
    "    : Seq[String] = {\n",
    "    val doc = new Annotation(text)\n",
    "    pipeline.annotate(doc)\n",
    "    val lemmas = new ArrayBuffer[String]()\n",
    "    val sentences = doc.get(classOf[SentencesAnnotation])\n",
    "    for (sentence <- sentences.asScala;\n",
    "         token <- sentence.get(classOf[TokensAnnotation]).asScala) {\n",
    "      val lemma = token.get(classOf[LemmaAnnotation])\n",
    "      if (lemma.length > 2 && !stopWords.contains(lemma) && isOnlyLetters(lemma)) {\n",
    "        lemmas += lemma.toLowerCase\n",
    "      }\n",
    "    }\n",
    "    lemmas\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stopWords = Set(down, it's, ourselves, that's, for, further, she'll, any, there's, this, haven't, in, ought, myself, have, your, off, once, i'll, are, is, his, why, too, why's, am, than, isn't, didn't, himself, but, you're, below, what, would, i'd, if, you'll, own, they'll, up, we're, they'd, so, our, do, all, him, had, nor, before, it, a, she's, as, hadn't, because, has, she, yours, or, above, yourself, herself, she'd, such, they, each, can't, don't, i, until, that, out, he's, cannot, to, we've, hers, you, did, let's, most, here, these, hasn't, was, there, when's, shan't, doing, at, through, been, over, i've, on, being, same, how, whom, my, after, who, itself, me, them, by, then, couldn't, he, should, few, wasn't, again, while, their, not, with, ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Set(down, it's, ourselves, that's, for, further, she'll, any, there's, this, haven't, in, ought, myself, have, your, off, once, i'll, are, is, his, why, too, why's, am, than, isn't, didn't, himself, but, you're, below, what, would, i'd, if, you'll, own, they'll, up, we're, they'd, so, our, do, all, him, had, nor, before, it, a, she's, as, hadn't, because, has, she, yours, or, above, yourself, herself, she'd, such, they, each, can't, don't, i, until, that, out, he's, cannot, to, we've, hers, you, did, let's, most, here, these, hasn't, was, there, when's, shan't, doing, at, through, been, over, i've, on, being, same, how, whom, my, after, who, itself, me, them, by, then, couldn't, he, should, few, wasn't, again, while, their, not, with, from, you've, they've, what's, wouldn't, both, could, its, under, which, you'd, an, be, here's, into, where, he'll, her, themselves, were, more, we'd, where's, they're, who's, between, aren't, ours, about, doesn't, how's, against, during, no, very, we, having, mustn't, some, does, when, shouldn't, yourselves, he'd, other, of, weren't, and, won't, theirs, i'm, we'll, the, those, only)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val stopWords = scala.io.Source.fromFile(\"./stopwords.txt\").getLines().toSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bStopWords = Broadcast(0)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Broadcast(0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val bStopWords = spark.sparkContext.broadcast(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Set(down, it's, ourselves, that's, for, further, she'll, any, there's, this, haven't, in, ought, myself, have, your, off, once, i'll, are, is, his, why, too, why's, am, than, isn't, didn't, himself, but, you're, below, what, would, i'd, if, you'll, own, they'll, up, we're, they'd, so, our, do, all, him, had, nor, before, it, a, she's, as, hadn't, because, has, she, yours, or, above, yourself, herself, she'd, such, they, each, can't, don't, i, until, that, out, he's, cannot, to, we've, hers, you, did, let's, most, here, these, hasn't, was, there, when's, shan't, doing, at, through, been, over, i've, on, being, same, how, whom, my, after, who, itself, me, them, by, then, couldn't, he, should, few, wasn't, again, while, their, not, with, from, you've, they've, what's, wouldn't, both, could, its, under, which, you'd, an, be, here's, into, where, he'll, her, themselves, were, more, we'd, where's, they're, who's, between, aren't, ours, about, doesn't, how's, against, during, no, very, we, having, mustn't, some, does, when, shouldn't, yourselves, he'd, other, of, weren't, and, won't, theirs, i'm, we'll, the, those, only)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bStopWords.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val terms: Dataset[(String, Seq[String])] = \n",
    "docTexts.mapPartitions { iter =>\n",
    "      val pipeline = createNLPPipeline()\n",
    "      iter.map { case (title, contents) => (title, plainTextToLemmas(contents, bStopWords.value, pipeline)) }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scala_nsc - Scala",
   "language": "scala",
   "name": "scala_nsc_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
