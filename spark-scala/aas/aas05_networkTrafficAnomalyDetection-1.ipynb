{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ul>\n",
       "<li><a href=\"Some(http://gw02.itversity.com:4053)\" target=\"new_tab\">Spark UI: application_1533622723243_5727</a></li>\n",
       "</ul>"
      ],
      "text/plain": [
       "Spark application_1533622723243_5727: Some(http://gw02.itversity.com:4053)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types will be printed.\n"
     ]
    }
   ],
   "source": [
    "%showtypes on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// val spark2 = spark\n",
    "// import spark2.implicits._\n",
    "// import org.apache.spark.sql.SQLImplicits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.DataFrame\n",
    "import util.Random\n",
    "\n",
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.clustering.{KMeans, KMeansModel}\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.ml.feature.StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dataWithoutHeader = [_c0: int, _c1: string ... 40 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[_c0: int, _c1: string ... 40 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataWithoutHeader = spark\n",
    "                        .read\n",
    "                        .option(\"inferSchema\",true)\n",
    "                        .option(\"header\",false)\n",
    "                        .csv(\"hdfs:///user/kranthidr/dataSets/KDDCup1999DataSet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class org.apache.spark.sql.Dataset\n"
     ]
    }
   ],
   "source": [
    "println(dataWithoutHeader.getClass())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: integer (nullable = true)\n",
      " |-- _c5: integer (nullable = true)\n",
      " |-- _c6: integer (nullable = true)\n",
      " |-- _c7: integer (nullable = true)\n",
      " |-- _c8: integer (nullable = true)\n",
      " |-- _c9: integer (nullable = true)\n",
      " |-- _c10: integer (nullable = true)\n",
      " |-- _c11: integer (nullable = true)\n",
      " |-- _c12: integer (nullable = true)\n",
      " |-- _c13: integer (nullable = true)\n",
      " |-- _c14: integer (nullable = true)\n",
      " |-- _c15: integer (nullable = true)\n",
      " |-- _c16: integer (nullable = true)\n",
      " |-- _c17: integer (nullable = true)\n",
      " |-- _c18: integer (nullable = true)\n",
      " |-- _c19: integer (nullable = true)\n",
      " |-- _c20: integer (nullable = true)\n",
      " |-- _c21: integer (nullable = true)\n",
      " |-- _c22: integer (nullable = true)\n",
      " |-- _c23: integer (nullable = true)\n",
      " |-- _c24: double (nullable = true)\n",
      " |-- _c25: double (nullable = true)\n",
      " |-- _c26: double (nullable = true)\n",
      " |-- _c27: double (nullable = true)\n",
      " |-- _c28: double (nullable = true)\n",
      " |-- _c29: double (nullable = true)\n",
      " |-- _c30: double (nullable = true)\n",
      " |-- _c31: integer (nullable = true)\n",
      " |-- _c32: integer (nullable = true)\n",
      " |-- _c33: double (nullable = true)\n",
      " |-- _c34: double (nullable = true)\n",
      " |-- _c35: double (nullable = true)\n",
      " |-- _c36: double (nullable = true)\n",
      " |-- _c37: double (nullable = true)\n",
      " |-- _c38: double (nullable = true)\n",
      " |-- _c39: double (nullable = true)\n",
      " |-- _c40: double (nullable = true)\n",
      " |-- _c41: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataWithoutHeader.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><td>0</td><td>tcp</td><td>http</td><td>SF</td><td>215</td><td>45076</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>normal.</td></tr>\n",
       "<tr><td>0</td><td>tcp</td><td>http</td><td>SF</td><td>162</td><td>4528</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>2</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1</td><td>1</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>normal.</td></tr>\n",
       "<tr><td>0</td><td>tcp</td><td>http</td><td>SF</td><td>236</td><td>1228</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>2</td><td>2</td><td>1.0</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>normal.</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "+-----+-----+------+-----+-----+-------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+---------+\n",
       "| 0   | tcp | http | SF  | 215 | 45076 | 0   | 0   | 0   | 0   | 0   | 1   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 1   | 1   | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0   | 0   | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | normal. |\n",
       "| 0   | tcp | http | SF  | 162 | 4528  | 0   | 0   | 0   | 0   | 0   | 1   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 2   | 2   | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1   | 1   | 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | normal. |\n",
       "| 0   | tcp | http | SF  | 236 | 1228  | 0   | 0   | 0   | 0   | 0   | 1   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 1   | 1   | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 2   | 2   | 1.0 | 0.0 | 0.5 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | normal. |\n",
       "+-----+-----+------+-----+-----+-------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+---------+"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataWithoutHeader.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataDF = [duration: int, protocol_type: string ... 40 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[duration: int, protocol_type: string ... 40 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataDF = dataWithoutHeader.toDF(\n",
    "        \"duration\", \"protocol_type\", \"service\", \"flag\",\n",
    "        \"src_bytes\", \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\",\n",
    "        \"hot\", \"num_failed_logins\", \"logged_in\", \"num_compromised\",\n",
    "        \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\",\n",
    "        \"num_shells\", \"num_access_files\", \"num_outbound_cmds\",\n",
    "        \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\",\n",
    "        \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\",\n",
    "        \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\",\n",
    "        \"dst_host_count\", \"dst_host_srv_count\",\n",
    "        \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\",\n",
    "        \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\",\n",
    "        \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
    "        \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\",\n",
    "        \"label\").cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- protocol_type: string (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- src_bytes: integer (nullable = true)\n",
      " |-- dst_bytes: integer (nullable = true)\n",
      " |-- land: integer (nullable = true)\n",
      " |-- wrong_fragment: integer (nullable = true)\n",
      " |-- urgent: integer (nullable = true)\n",
      " |-- hot: integer (nullable = true)\n",
      " |-- num_failed_logins: integer (nullable = true)\n",
      " |-- logged_in: integer (nullable = true)\n",
      " |-- num_compromised: integer (nullable = true)\n",
      " |-- root_shell: integer (nullable = true)\n",
      " |-- su_attempted: integer (nullable = true)\n",
      " |-- num_root: integer (nullable = true)\n",
      " |-- num_file_creations: integer (nullable = true)\n",
      " |-- num_shells: integer (nullable = true)\n",
      " |-- num_access_files: integer (nullable = true)\n",
      " |-- num_outbound_cmds: integer (nullable = true)\n",
      " |-- is_host_login: integer (nullable = true)\n",
      " |-- is_guest_login: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- srv_count: integer (nullable = true)\n",
      " |-- serror_rate: double (nullable = true)\n",
      " |-- srv_serror_rate: double (nullable = true)\n",
      " |-- rerror_rate: double (nullable = true)\n",
      " |-- srv_rerror_rate: double (nullable = true)\n",
      " |-- same_srv_rate: double (nullable = true)\n",
      " |-- diff_srv_rate: double (nullable = true)\n",
      " |-- srv_diff_host_rate: double (nullable = true)\n",
      " |-- dst_host_count: integer (nullable = true)\n",
      " |-- dst_host_srv_count: integer (nullable = true)\n",
      " |-- dst_host_same_srv_rate: double (nullable = true)\n",
      " |-- dst_host_diff_srv_rate: double (nullable = true)\n",
      " |-- dst_host_same_src_port_rate: double (nullable = true)\n",
      " |-- dst_host_srv_diff_host_rate: double (nullable = true)\n",
      " |-- dst_host_serror_rate: double (nullable = true)\n",
      " |-- dst_host_srv_serror_rate: double (nullable = true)\n",
      " |-- dst_host_rerror_rate: double (nullable = true)\n",
      " |-- dst_host_srv_rerror_rate: double (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numericOnly = [duration: int, src_bytes: int ... 37 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[duration: int, src_bytes: int ... 37 more fields]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val numericOnly = dataDF.drop(\"protocol_type\", \"service\", \"flag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class org.apache.spark.sql.Dataset\n",
      "class org.apache.spark.sql.Dataset\n"
     ]
    }
   ],
   "source": [
    "println(numericOnly.getClass())\n",
    "println(dataDF.getClass())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clusterScore1: (data: org.apache.spark.sql.DataFrame, k: Int)Double\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clusterScore1(data: DataFrame, k: Int) = {\n",
    "    \n",
    "    val assembler = new VectorAssembler().setInputCols(data.columns.filter(_!=\"label\")).setOutputCol(\"featureVector\")\n",
    "    \n",
    "    val kmeans = new KMeans().\n",
    "        setSeed(Random.nextLong()).\n",
    "        setK(k).\n",
    "        setMaxIter(40).\n",
    "        setTol(1.0e-5).\n",
    "        setPredictionCol(\"cluster\").\n",
    "        setFeaturesCol(\"featureVector\")\n",
    "    \n",
    "    val pipeline = new Pipeline().setStages(Array(assembler, kmeans))\n",
    "    \n",
    "    val pipelineModel = pipeline.fit(data)\n",
    "    \n",
    "    val kmeansModel = pipelineModel.stages.last.asInstanceOf[KMeansModel]\n",
    "    \n",
    "    kmeansModel.computeCost(pipelineModel.transform(data))/ data.count()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k_kScore1 = Vector((30,3.635840221511652E7), (60,6641447.521341801), (90,1.0923617558041153E7), (120,1.5906840622696329E7), (150,3879801.228146184), (180,6210733.632874885), (210,7032526.219276081))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Vector((30,3.635840221511652E7), (60,6641447.521341801), (90,1.0923617558041153E7), (120,1.5906840622696329E7), (150,3879801.228146184), (180,6210733.632874885), (210,7032526.219276081))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val k_kScore1 = (30 to 210 by 30).map(k => (k, clusterScore1(numericOnly, k))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clusterScore2: (data: org.apache.spark.sql.DataFrame, k: Int)Double\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clusterScore2(data: DataFrame, k: Int) = {\n",
    "    \n",
    "    val assembler = new VectorAssembler().setInputCols(data.columns.filter(_!=\"label\")).setOutputCol(\"featureVector\")\n",
    "    \n",
    "    val scalar = new StandardScaler().setInputCol(\"featureVector\").setOutputCol(\"scaledFeatureVector\").\n",
    "        setWithStd(true).\n",
    "        setWithMean(false)\n",
    "    \n",
    "     val kmeans = new KMeans().\n",
    "        setSeed(Random.nextLong()).\n",
    "        setK(k).\n",
    "        setMaxIter(40).\n",
    "        setTol(1.0e-5).\n",
    "        setFeaturesCol(\"scaledFeatureVector\").\n",
    "        setPredictionCol(\"cluster\")\n",
    "   \n",
    "    val pipeline = new Pipeline().setStages(Array(assembler, scalar, kmeans))\n",
    "    \n",
    "    val pipelineModel = pipeline.fit(data)\n",
    "    \n",
    "    val kmeansModel = pipelineModel.stages.last.asInstanceOf[KMeansModel]\n",
    "    \n",
    "    kmeansModel.computeCost(pipelineModel.transform(data))/ data.count()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k_kScore2 = Vector((30,3.343485325379386), (60,1.1720012949665948), (90,0.7832049859676018), (120,0.5264366623855883), (150,0.3967492031349398), (180,0.33590317357634714), (210,0.2871852397233478))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Vector((30,3.343485325379386), (60,1.1720012949665948), (90,0.7832049859676018), (120,0.5264366623855883), (150,0.3967492031349398), (180,0.33590317357634714), (210,0.2871852397233478))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val k_kScore2 = (30 to 210 by 30).map(k => (k, clusterScore2(numericOnly, k))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "warning: there was one deprecation warning; re-run with -deprecation for details\n",
       "oneHotPipeline: (inputCol: String)(org.apache.spark.ml.Pipeline, String)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer}\n",
    "\n",
    "def oneHotPipeline(inputCol: String):(Pipeline, String) = {\n",
    "    val indexer = new StringIndexer().setInputCol(inputCol).setOutputCol(inputCol + \"_indexed\")\n",
    "    val encoder = new OneHotEncoder().setInputCol(inputCol + \"_indexed\").setOutputCol(inputCol + \"_vec\")\n",
    "    val pipeline = new Pipeline().setStages(Array(indexer, encoder))\n",
    "    (pipeline, inputCol +\"_vec\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clusterScore3: (data: org.apache.spark.sql.DataFrame, k: Int)Double\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clusterScore3(data: DataFrame, k: Int) = {\n",
    "    \n",
    "    val (protoTypeEncoder, protoTypeVecCol) = oneHotPipeline(\"protocol_type\")\n",
    "    val (serviceEncoder, serviceVecCol) = oneHotPipeline(\"service\")\n",
    "    val (flagEncoder, flagVecCol) = oneHotPipeline(\"flag\")\n",
    "\n",
    "    // Original columns, without label / string columns, but with new vector encoded cols\n",
    "    val assembleCols = Set(data.columns: _*) --\n",
    "      Seq(\"label\", \"protocol_type\", \"service\", \"flag\")--\n",
    "      Seq(\"protocol_type_indexed\", \"service_indexed\", \"flag_indexed\") ++\n",
    "      Seq(protoTypeVecCol, serviceVecCol, flagVecCol)\n",
    "    \n",
    "    val assembler = new VectorAssembler().\n",
    "      setInputCols(assembleCols.toArray).\n",
    "      setOutputCol(\"featureVector\")\n",
    "    \n",
    "    val scalar = new StandardScaler().setInputCol(\"featureVector\").setOutputCol(\"scaledFeatureVector\").\n",
    "        setWithStd(true).\n",
    "        setWithMean(false)\n",
    "    \n",
    "     val kmeans = new KMeans().\n",
    "        setSeed(Random.nextLong()).\n",
    "        setK(k).\n",
    "        setMaxIter(40).\n",
    "        setTol(1.0e-5).\n",
    "        setPredictionCol(\"cluster\").\n",
    "        setFeaturesCol(\"scaledFeatureVector\")\n",
    "   \n",
    "    val pipeline = new Pipeline().setStages(\n",
    "      Array(protoTypeEncoder, serviceEncoder, flagEncoder, assembler, scalar, kmeans))\n",
    "    \n",
    "    val pipelineModel = pipeline.fit(data)\n",
    "    \n",
    "    val kmeansModel = pipelineModel.stages.last.asInstanceOf[KMeansModel]\n",
    "    \n",
    "    kmeansModel.computeCost(pipelineModel.transform(data))/ data.count()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k_kScore3 = Vector((30,66.49785730673229), (60,37.65366216663372), (90,15.693068031156018), (120,3.4786749206863736), (150,2.476913465083039), (180,1.5727684090945262), (210,1.3239785307094756))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Vector((30,66.49785730673229), (60,37.65366216663372), (90,15.693068031156018), (120,3.4786749206863736), (150,2.476913465083039), (180,1.5727684090945262), (210,1.3239785307094756))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val k_kScore3 = (30 to 210 by 30).map(k => (k, clusterScore3(dataDF, k))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking co.theasi:plotly_2.11:0.2.0 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree-tmp-dir451726423047915545/toree_add_deps/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree-tmp-dir451726423047915545/toree_add_deps/https/repo1.maven.org/maven2/org/json4s/json4s-scalap_2.11/3.3.0/json4s-scalap_2.11-3.3.0.jar\n",
      "-> New file at /tmp/toree-tmp-dir451726423047915545/toree_add_deps/https/repo1.maven.org/maven2/org/json4s/json4s-core_2.11/3.3.0/json4s-core_2.11-3.3.0.jar\n",
      "-> New file at /tmp/toree-tmp-dir451726423047915545/toree_add_deps/https/repo1.maven.org/maven2/co/theasi/plotly_2.11/0.2.0/plotly_2.11-0.2.0.jar\n",
      "-> New file at /tmp/toree-tmp-dir451726423047915545/toree_add_deps/https/repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar\n",
      "-> New file at /tmp/toree-tmp-dir451726423047915545/toree_add_deps/https/repo1.maven.org/maven2/org/scalaj/scalaj-http_2.11/2.2.1/scalaj-http_2.11-2.2.1.jar\n",
      "-> New file at /tmp/toree-tmp-dir451726423047915545/toree_add_deps/https/repo1.maven.org/maven2/org/json4s/json4s-ast_2.11/3.3.0/json4s-ast_2.11-3.3.0.jar\n",
      "-> New file at /tmp/toree-tmp-dir451726423047915545/toree_add_deps/https/repo1.maven.org/maven2/org/json4s/json4s-native_2.11/3.3.0/json4s-native_2.11-3.3.0.jar\n",
      "-> New file at /tmp/toree-tmp-dir451726423047915545/toree_add_deps/https/repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.pom\n",
      "-> New file at /tmp/toree-tmp-dir451726423047915545/toree_add_deps/https/repo1.maven.org/maven2/org/json4s/json4s-ast_2.11/3.3.0/json4s-ast_2.11-3.3.0.pom\n",
      "-> New file at /tmp/toree-tmp-dir451726423047915545/toree_add_deps/https/repo1.maven.org/maven2/org/scalaj/scalaj-http_2.11/2.2.1/scalaj-http_2.11-2.2.1.pom\n",
      "-> New file at /tmp/toree-tmp-dir451726423047915545/toree_add_deps/https/repo1.maven.org/maven2/org/json4s/json4s-native_2.11/3.3.0/json4s-native_2.11-3.3.0.pom\n",
      "-> New file at /tmp/toree-tmp-dir451726423047915545/toree_add_deps/https/repo1.maven.org/maven2/org/json4s/json4s-core_2.11/3.3.0/json4s-core_2.11-3.3.0.pom\n",
      "-> New file at /tmp/toree-tmp-dir451726423047915545/toree_add_deps/https/repo1.maven.org/maven2/org/json4s/json4s-scalap_2.11/3.3.0/json4s-scalap_2.11-3.3.0.pom\n",
      "-> New file at /tmp/toree-tmp-dir451726423047915545/toree_add_deps/https/repo1.maven.org/maven2/co/theasi/plotly_2.11/0.2.0/plotly_2.11-0.2.0.pom\n"
     ]
    }
   ],
   "source": [
    "%AddDeps co.theasi plotly_2.11 0.2.0 --transitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//%addjar http://central.maven.org/maven2/co/theasi/plotly_2.11/0.2.0/plotly_2.11-0.2.0.jar -- NOT WORKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import co.theasi.plotly._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xs1 = Vector(30, 60, 90, 120, 150, 180, 210)\n",
       "ys1 = Vector(3.635840221511652E7, 6641447.521341801, 1.0923617558041153E7, 1.5906840622696329E7, 3879801.228146184, 6210733.632874885, 7032526.219276081)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Vector(3.635840221511652E7, 6641447.521341801, 1.0923617558041153E7, 1.5906840622696329E7, 3879801.228146184, 6210733.632874885, 7032526.219276081)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val xs1 =  k_kScore1.map(_._1)\n",
    "val ys1 =  k_kScore1.map(_._2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot = CartesianPlot(Vector(Scatter(Vector(PInt(30), PInt(60), PInt(90), PInt(120), PInt(150), PInt(180), PInt(210)),Vector(PDouble(3.635840221511652E7), PDouble(6641447.521341801), PDouble(1.0923617558041153E7), PDouble(1.5906840622696329E7), PDouble(3879801.228146184), PDouble(6210733.632874885), PDouble(7032526.219276081)),ScatterOptions(None,List(),None,MarkerOptions(None,None,None,None,None)))),CartesianPlotOptions(Axis(AxisOptions(None,None,None,None,None,None,None,Font(None,None,None),Font(None,None,None),None,None,None,None)),Axis(AxisOptions(None,None,None,None,None,None,None,Font(None,None,None),Font(None,None,None),None,None,None,None))))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PlotFile(kranthidr:28,ch05_traffic_anamoly1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val plot = Plot().withScatter(xs1, ys1)\n",
    "\n",
    "draw(plot, \"ch05_traffic_anamoly1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xs2 = Vector(30, 60, 90, 120, 150, 180, 210)\n",
       "ys2 = Vector(3.343485325379386, 1.1720012949665948, 0.7832049859676018, 0.5264366623855883, 0.3967492031349398, 0.33590317357634714, 0.2871852397233478)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Vector(3.343485325379386, 1.1720012949665948, 0.7832049859676018, 0.5264366623855883, 0.3967492031349398, 0.33590317357634714, 0.2871852397233478)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val xs2 =  k_kScore2.map(_._1)\n",
    "val ys2 =  k_kScore2.map(_._2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot = CartesianPlot(Vector(Scatter(Vector(PInt(30), PInt(60), PInt(90), PInt(120), PInt(150), PInt(180), PInt(210)),Vector(PDouble(3.343485325379386), PDouble(1.1720012949665948), PDouble(0.7832049859676018), PDouble(0.5264366623855883), PDouble(0.3967492031349398), PDouble(0.33590317357634714), PDouble(0.2871852397233478)),ScatterOptions(None,List(),None,MarkerOptions(None,None,None,None,None)))),CartesianPlotOptions(Axis(AxisOptions(None,None,None,None,None,None,None,Font(None,None,None),Font(None,None,None),None,None,None,None)),Axis(AxisOptions(None,None,None,None,None,None,None,Font(None,None,None),Font(None,None,None),None,None,None,None))))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PlotFile(kranthidr:30,ch05_traffic_anamoly2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val plot = Plot().withScatter(xs2, ys2)\n",
    "\n",
    "draw(plot, \"ch05_traffic_anamoly2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xs3 = Vector(30, 60, 90, 120, 150, 180, 210)\n",
       "ys3 = Vector(66.49785730673229, 37.65366216663372, 15.693068031156018, 3.4786749206863736, 2.476913465083039, 1.5727684090945262, 1.3239785307094756)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Vector(66.49785730673229, 37.65366216663372, 15.693068031156018, 3.4786749206863736, 2.476913465083039, 1.5727684090945262, 1.3239785307094756)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val xs3 =  k_kScore3.map(_._1)\n",
    "val ys3 =  k_kScore3.map(_._2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot = CartesianPlot(Vector(Scatter(Vector(PInt(30), PInt(60), PInt(90), PInt(120), PInt(150), PInt(180), PInt(210)),Vector(PDouble(66.49785730673229), PDouble(37.65366216663372), PDouble(15.693068031156018), PDouble(3.4786749206863736), PDouble(2.476913465083039), PDouble(1.5727684090945262), PDouble(1.3239785307094756)),ScatterOptions(None,List(),None,MarkerOptions(None,None,None,None,None)))),CartesianPlotOptions(Axis(AxisOptions(None,None,None,None,None,None,None,Font(None,None,None),Font(None,None,None),None,None,None,None)),Axis(AxisOptions(None,None,None,None,None,None,None,Font(None,None,None),Font(None,None,None),None,None,None,None))))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PlotFile(kranthidr:32,ch05_traffic_anamoly3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val plot = Plot().withScatter(xs3, ys3)\n",
    "\n",
    "draw(plot, \"ch05_traffic_anamoly3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark - Scala",
   "language": "scala",
   "name": "spark_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
