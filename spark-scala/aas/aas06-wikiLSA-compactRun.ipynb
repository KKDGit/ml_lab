{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ul>\n",
       "<li><a href=\"Some(http://gw02.itversity.com:4041)\" target=\"new_tab\">Spark UI: application_1540458187951_69601</a></li>\n",
       "</ul>"
      ],
      "text/plain": [
       "Spark application_1540458187951_69601: Some(http://gw02.itversity.com:4041)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://rm01.itversity.com:19288/proxy/application_1540458187951_69601\n"
     ]
    }
   ],
   "source": [
    "spark.sparkContext.getConf.getAll.foreach(x=>if(x._2.contains(\"/proxy/\")){println(x._2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scala.collection.JavaConversions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "os_name = Linux\n",
       "hdfs_home = /user/kranthidr\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/user/kranthidr"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val os_name = System.getProperty(\"os.name\")\n",
    "val hdfs_home = \"/user/\" + System.getProperty(\"user.home\").split(\"/\")(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path = /user/kranthidr/dataSets/wikidump-02-sept-2018.xml\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/user/kranthidr/dataSets/wikidump-02-sept-2018.xml"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val path = hdfs_home+\"/dataSets/wikidump-02-sept-2018.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.cloudera.datascience.lsa._\n",
    "import com.cloudera.datascience.lsa.AssembleDocumentTermMatrix\n",
    "import com.cloudera.datascience.lsa.LSAQueryEngine\n",
    "import com.cloudera.datascience.lsa.RunLSA._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import breeze.linalg.{DenseMatrix=>BDenseMatrix, SparseVector=>BSparseVector}\n",
       "import org.apache.spark.mllib.linalg.{Matrices, Matrix, SingularValueDecomposition, Vectors, Vector=>MLLibVector}\n",
       "import org.apache.spark.ml.linalg.{Vector=>MLVector}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import breeze.linalg.{DenseMatrix => BDenseMatrix, SparseVector => BSparseVector}\n",
    "\n",
    "import org.apache.spark.mllib.linalg.{Matrices, Matrix, SingularValueDecomposition, Vectors, Vector => MLLibVector}\n",
    "import org.apache.spark.ml.linalg.{Vector => MLVector}\n",
    "import org.apache.spark.mllib.linalg.distributed.RowMatrix\n",
    "import org.apache.spark.serializer.KryoSerializer\n",
    "import org.apache.spark.sql.{Dataset, SparkSession}\n",
    "\n",
    "import scala.collection.Map\n",
    "import scala.collection.mutable.ArrayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val k =  100\n",
    "val numTerms = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val assembleMatrix = new AssembleDocumentTermMatrix(spark)\n",
    "import assembleMatrix._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val docTexts: Dataset[(String, String)] = parseWikipediaDump(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docTexts.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val docTexts1 = docTexts.sample(false, 0.001) //50 Docs we get approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docTexts1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val (docTermMatrix, termIds, docIds, termIdfs) = documentTermMatrix(docTexts1, \"stopwords.txt\", numTerms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docTexts.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docTermMatrix.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " val vecRdd = docTermMatrix.select(\"tfidfVec\").rdd.map { row =>\n",
    "      Vectors.fromML(row.getAs[MLVector](\"tfidfVec\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docTermMatrix.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecRdd.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    val mat = new RowMatrix(vecRdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    val svd = mat.computeSVD(k, computeU=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    println(\"Singular values: \" + svd.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    val topConceptTerms = topTermsInTopConcepts(svd, 10, 10, termIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    val topConceptDocs = topDocsInTopConcepts(svd, 10, 10, docIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for ((terms, docs) <- topConceptTerms.zip(topConceptDocs)) {\n",
    "      println(\"Concept terms: \" + terms.map(_._1).mkString(\", \"))\n",
    "      println(\"Concept docs: \" + docs.map(_._1).mkString(\", \"))\n",
    "      println()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    val queryEngine = new LSAQueryEngine(svd, termIds, docIds, termIdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    queryEngine.printTopTermsForTerm(\"algorithm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    queryEngine.printTopTermsForTerm(\"kempegowda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    queryEngine.printTopTermsForTerm(\"malleshwaram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    queryEngine.printTopDocsForTerm(\"fir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    queryEngine.printTopDocsForTerm(\"graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    queryEngine.printTopDocsForDoc(\"BAR domain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    queryEngine.printTopDocsForDoc(\"List of BMTC routes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    queryEngine.printTopDocsForDoc(\"ATP-binding cassette transporter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    queryEngine.printTopDocsForTermQuery(Seq(\"nagar\", \"circle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "0609 - Scala",
   "language": "scala",
   "name": "0609_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
