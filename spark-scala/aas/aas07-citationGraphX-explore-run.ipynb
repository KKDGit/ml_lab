{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ul>\n",
       "<li><a href=\"Some(http://gw02.itversity.com:4056)\" target=\"new_tab\">Spark UI: application_1533622723243_21384</a></li>\n",
       "</ul>"
      ],
      "text/plain": [
       "Spark application_1533622723243_21384: Some(http://gw02.itversity.com:4056)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://rm01.itversity.com:19288/proxy/application_1533622723243_21384\n"
     ]
    }
   ],
   "source": [
    "spark.sparkContext.getConf.getAll.foreach(x=>if(x._2.contains(\"/proxy/\")){println(x._2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scala.collection.JavaConversions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "os_name = Linux\n",
       "hdfs_home = /user/kranthidr\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/user/kranthidr"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val os_name = System.getProperty(\"os.name\")\n",
    "val hdfs_home = \"/user/\" + System.getProperty(\"user.home\").split(\"/\")(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path = /user/kranthidr/dataSets/medline_2016\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/user/kranthidr/dataSets/medline_2016"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val path = hdfs_home+\"/dataSets/medline_2016\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import com.cloudera.datascience.graph.RunGraph._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import edu.umd.cloud9.collection.XMLInputFormat\n",
    "\n",
    "import java.nio.charset.StandardCharsets\n",
    "import java.security.MessageDigest\n",
    "\n",
    "import org.apache.hadoop.io.{Text, LongWritable}\n",
    "import org.apache.hadoop.conf.Configuration\n",
    "\n",
    "import org.apache.spark.graphx._\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql.{Dataset, SparkSession, Row}\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "import scala.xml._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medlineRaw = [value: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[value: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val medlineRaw: Dataset[String] = loadMedline(spark, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medline = [value: array<string>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[value: array<string>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val medline: Dataset[Seq[String]] = medlineRaw.map(majorTopics).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "medline.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medline.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------+\n",
      "|value                                                                      |\n",
      "+---------------------------------------------------------------------------+\n",
      "|[Intellectual Disability, Maternal-Fetal Exchange, Pregnancy Complications]|\n",
      "+---------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "medline.show(1, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topics = [topic: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[topic: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val topics = medline.flatMap(mesh => mesh).toDF(\"topic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    topics.createOrReplaceTempView(\"topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topicDist = [topic: string, cnt: bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[topic: string, cnt: bigint]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val topicDist = spark.sql(\"SELECT topic, COUNT(*) cnt FROM topics GROUP BY topic ORDER BY cnt DESC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|               topic| cnt|\n",
      "+--------------------+----+\n",
      "|            Research|1649|\n",
      "|             Disease|1349|\n",
      "|           Neoplasms|1123|\n",
      "|        Tuberculosis|1066|\n",
      "|       Public Policy| 816|\n",
      "|       Jurisprudence| 796|\n",
      "|          Demography| 763|\n",
      "| Population Dynamics| 753|\n",
      "|           Economics| 690|\n",
      "|            Medicine| 682|\n",
      "|Socioeconomic Fac...| 655|\n",
      "|            Politics| 631|\n",
      "|               Blood| 631|\n",
      "|Emigration and Im...| 601|\n",
      "|       Social Change| 577|\n",
      "|          Physicians| 560|\n",
      "|            Mutation| 542|\n",
      "|   Abortion, Induced| 503|\n",
      "|          Anesthesia| 483|\n",
      "|       Public Health| 479|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    topicDist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    topicDist.createOrReplaceTempView(\"topic_dist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "|cnt|dist|\n",
      "+---+----+\n",
      "|  1|3106|\n",
      "|  2|1699|\n",
      "|  3|1207|\n",
      "|  4| 902|\n",
      "|  5| 680|\n",
      "|  6| 571|\n",
      "|  7| 490|\n",
      "|  8| 380|\n",
      "|  9| 356|\n",
      "| 10| 296|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    spark.sql(\"SELECT cnt, COUNT(*) dist FROM topic_dist GROUP BY cnt ORDER BY dist DESC LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topicPairs = [pairs: array<string>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[pairs: array<string>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val topicPairs = medline.flatMap(_.sorted.combinations(2)).toDF(\"pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    topicPairs.createOrReplaceTempView(\"topic_pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cooccurs = [pairs: array<string>, cnt: bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[pairs: array<string>, cnt: bigint]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val cooccurs = spark.sql(\"SELECT pairs, COUNT(*) cnt FROM topic_pairs GROUP BY pairs\")\n",
    "    cooccurs.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    cooccurs.createOrReplaceTempView(\"cooccurs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique co-occurrence pairs: 213745\n"
     ]
    }
   ],
   "source": [
    "    println(\"Number of unique co-occurrence pairs: \" + cooccurs.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|               pairs|cnt|\n",
      "+--------------------+---+\n",
      "|[Demography, Popu...|288|\n",
      "|[Government Regul...|254|\n",
      "|[Emigration and I...|230|\n",
      "|[Acquired Immunod...|220|\n",
      "|[Antibiotics, Ant...|205|\n",
      "|[Analgesia, Anest...|183|\n",
      "|[Economics, Popul...|181|\n",
      "|[Analgesia, Anest...|179|\n",
      "|[Anesthesia, Anes...|177|\n",
      "|[Population Dynam...|174|\n",
      "+--------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    spark.sql(\"SELECT pairs, cnt FROM cooccurs ORDER BY cnt DESC LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vertices = [hash: bigint, topic: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[hash: bigint, topic: string]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val vertices = topics.map { case Row(topic: String) => (hashId(topic), topic) }.toDF(\"hash\", \"topic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "edges = [srcId: bigint, dstId: bigint ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[srcId: bigint, dstId: bigint ... 1 more field]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val edges = cooccurs.map { case Row(topics: Seq[_], cnt: Long) =>\n",
    "       val ids = topics.map(_.toString).map(hashId).sorted\n",
    "       Edge(ids(0), ids(1), cnt)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vertexRDD = MapPartitionsRDD[90] at map at <console>:61\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[90] at map at <console>:61"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val vertexRDD = vertices.rdd.map{ case Row(hash: Long, topic: String) => (hash, topic) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topicGraph = org.apache.spark.graphx.impl.GraphImpl@6f0e2189\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@6f0e2189"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val topicGraph = Graph(vertexRDD, edges.rdd)\n",
    "    topicGraph.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "connectedComponentGraph = org.apache.spark.graphx.impl.GraphImpl@40468bb4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@40468bb4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val connectedComponentGraph = topicGraph.connectedComponents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "componentDF = [vid: bigint, cid: bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[vid: bigint, cid: bigint]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val componentDF = connectedComponentGraph.vertices.toDF(\"vid\", \"cid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "componentCounts = [cid: bigint, count: bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[cid: bigint, count: bigint]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val componentCounts = componentDF.groupBy(\"cid\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                 cid|count|\n",
      "+--------------------+-----+\n",
      "|-9218306090261648869|13610|\n",
      "|-8193948242717911820|    5|\n",
      "|-2062883918534425492|    4|\n",
      "|-7016546051037489808|    3|\n",
      "| 2742772755763603550|    3|\n",
      "|-7685954109876710390|    3|\n",
      "| -784187332742198415|    3|\n",
      "| 1765411469112156596|    3|\n",
      "|-8679136035911620397|    3|\n",
      "|-3299226677350014771|    2|\n",
      "|-5179176761971077378|    2|\n",
      "|-2317423407077322989|    2|\n",
      "|-9211944049288765106|    2|\n",
      "|-5295884525273097033|    2|\n",
      "|-3191983795676547449|    2|\n",
      "| 2026738476704047088|    2|\n",
      "|-1390944942283085161|    2|\n",
      "| -697775734067750523|    2|\n",
      "|-5362458719777034637|    2|\n",
      "|-3467839743215210439|    2|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    componentCounts.orderBy(desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topicComponentDF = [topic: string, cid: bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[topic: string, cid: bigint]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val topicComponentDF = topicGraph.vertices.innerJoin(\n",
    "      connectedComponentGraph.vertices) {\n",
    "      (topicId, name, componentId) => (name, componentId.toLong)\n",
    "    }.values.toDF(\"topic\", \"cid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               topic|                 cid|\n",
      "+--------------------+--------------------+\n",
      "|          Serotyping|-2062883918534425492|\n",
      "|Campylobacter jejuni|-2062883918534425492|\n",
      "|Campylobacter Inf...|-2062883918534425492|\n",
      "|  Campylobacter coli|-2062883918534425492|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    topicComponentDF.where(\"cid = -2062883918534425492\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|               topic|cnt|\n",
      "+--------------------+---+\n",
      "|Campylobacter jejuni|  3|\n",
      "|Campylobacter Inf...|  2|\n",
      "| Campylobacter fetus|  1|\n",
      "|  Campylobacter coli|  1|\n",
      "|       Campylobacter|  1|\n",
      "+--------------------+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "campy = [topic: string, cnt: bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[topic: string, cnt: bigint]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val campy = spark.sql(\"SELECT * FROM topic_dist WHERE topic LIKE '%ampylobacter%'\")\n",
    "    campy.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "degrees = VertexRDDImpl[277] at RDD at VertexRDD.scala:57\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VertexRDDImpl[277] at RDD at VertexRDD.scala:57"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val degrees: VertexRDD[Int] = topicGraph.degrees.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+\n",
      "|              topic|degree|\n",
      "+-------------------+------+\n",
      "|           Research|  2596|\n",
      "|            Disease|  1746|\n",
      "|          Neoplasms|  1202|\n",
      "|              Blood|   914|\n",
      "|       Pharmacology|   882|\n",
      "|       Tuberculosis|   815|\n",
      "|         Toxicology|   694|\n",
      "|       Drug Therapy|   678|\n",
      "|      Jurisprudence|   661|\n",
      "|Biomedical Research|   633|\n",
      "|         Physicians|   625|\n",
      "|      Public Policy|   601|\n",
      "|           Medicine|   590|\n",
      "|         Metabolism|   578|\n",
      "|      Social Change|   570|\n",
      "|Wounds and Injuries|   570|\n",
      "|              Brain|   569|\n",
      "|          Hospitals|   557|\n",
      "|              Urine|   551|\n",
      "|          Economics|   548|\n",
      "+-------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    degrees.map(_._2).stats()\n",
    "    degrees.innerJoin(topicGraph.vertices) {\n",
    "      (topicId, degree, name) => (name, degree.toInt)\n",
    "    }.values.toDF(\"topic\", \"degree\").orderBy(desc(\"degree\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T = 240000\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "240000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val T = medline.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topicDistRdd = MapPartitionsRDD[313] at rdd at <console>:51\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[313] at rdd at <console>:51"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val topicDistRdd = topicDist.map { case Row(topic: String, cnt: Long) => (hashId(topic), cnt) }.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topicDistGraph = org.apache.spark.graphx.impl.GraphImpl@58580eaa\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@58580eaa"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val topicDistGraph = Graph(topicDistRdd, topicGraph.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chiSquaredGraph = org.apache.spark.graphx.impl.GraphImpl@422d0e99\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@422d0e99"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val chiSquaredGraph = topicDistGraph.mapTriplets(triplet =>\n",
    "      chiSq(triplet.attr, triplet.srcAttr, triplet.dstAttr, T)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count: 213745, mean: 877.956648, stdev: 5094.935171, max: 198668.408387, min: 0.000000)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    chiSquaredGraph.edges.map(x => x.attr).stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interesting = org.apache.spark.graphx.impl.GraphImpl@56f7fba8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@56f7fba8"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val interesting = chiSquaredGraph.subgraph(triplet => triplet.attr > 19.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interestingComponentGraph = org.apache.spark.graphx.impl.GraphImpl@b06bc78\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@b06bc78"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val interestingComponentGraph = interesting.connectedComponents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "icDF = [vid: bigint, cid: bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[vid: bigint, cid: bigint]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val icDF = interestingComponentGraph.vertices.toDF(\"vid\", \"cid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "icCountDF = [cid: bigint, count: bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[cid: bigint, count: bigint]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val icCountDF = icDF.groupBy(\"cid\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    icCountDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                 cid|count|\n",
      "+--------------------+-----+\n",
      "|-9218306090261648869|13610|\n",
      "|-8193948242717911820|    5|\n",
      "|-2062883918534425492|    4|\n",
      "|-7016546051037489808|    3|\n",
      "| 2742772755763603550|    3|\n",
      "|-7685954109876710390|    3|\n",
      "| -784187332742198415|    3|\n",
      "| 1765411469112156596|    3|\n",
      "|-8679136035911620397|    3|\n",
      "|-3299226677350014771|    2|\n",
      "|-1390944942283085161|    2|\n",
      "| 2026738476704047088|    2|\n",
      "|-9211944049288765106|    2|\n",
      "|-5295884525273097033|    2|\n",
      "|-3191983795676547449|    2|\n",
      "|-1046815223728304871|    2|\n",
      "| -697775734067750523|    2|\n",
      "|-5179176761971077378|    2|\n",
      "|-5362458719777034637|    2|\n",
      "|-3467839743215210439|    2|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    icCountDF.orderBy(desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interestingDegrees = VertexRDDImpl[514] at RDD at VertexRDD.scala:57\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VertexRDDImpl[514] at RDD at VertexRDD.scala:57"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val interestingDegrees = interesting.degrees.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count: 13721, mean: 20.490489, stdev: 29.864223, max: 863.000000, min: 1.000000)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    interestingDegrees.map(_._2).stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               topic|              degree|\n",
      "+--------------------+--------------------+\n",
      "| 7245808948765301120|[von Willebrand D...|\n",
      "| 5099251899234384801|[src-Family Kinas...|\n",
      "|-1530704564905827748|[src Homology Dom...|\n",
      "| 2507157745758004630|[rho GTP-Binding ...|\n",
      "|-7862235140823909271|       [ras-GRF1, 1]|\n",
      "| 2059861029745035294|   [ras Proteins, 6]|\n",
      "| 5955929388309042993|[rab GTP-Binding ...|\n",
      "| 7816430327900570785|    [rRNA Operon, 2]|\n",
      "| 7239719559500007147|[para-Aminobenzoa...|\n",
      "| 1284163606049864457|[p38 Mitogen-Acti...|\n",
      "|-1087266232809183895|[p-Methoxy-N-meth...|\n",
      "|-8705584836746698588|[p-Dimethylaminoa...|\n",
      "|-5100017000906699736|[p-Aminohippuric ...|\n",
      "|-4066692375147750810|[p-Aminoazobenzen...|\n",
      "|-1046658263400552818|[ortho-Aminobenzo...|\n",
      "|-4311340282177857587|[omega-Conotoxins...|\n",
      "| 6603518327358446980|[gamma-Globulins,...|\n",
      "|-2996202821866347894|[gamma-Aminobutyr...|\n",
      "|-6978724293355107821|[cis-trans-Isomer...|\n",
      "|  172595453653541184|[cdc25 Phosphatas...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    interestingDegrees.innerJoin(topicGraph.vertices) {\n",
    "      (topicId, degree, name) => (name, degree)\n",
    "    }.toDF(\"topic\", \"degree\").orderBy(desc(\"degree\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avgCC = 0.306246256051886\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.306246256051886"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val avgCC = avgClusteringCoef(interesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paths = MapPartitionsRDD[741] at distinct at RunGraph.scala:142\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(count: 3170622, mean: 3.607923, stdev: 0.776411, max: 8.000000, min: 1.000000)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val paths = samplePathLengths(interesting)\n",
    "    paths.map(_._3).filter(_ > 0).stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,255)\n",
      "(1,4834)\n",
      "(2,168905)\n",
      "(3,1259106)\n",
      "(4,1394555)\n",
      "(5,319149)\n",
      "(6,23106)\n",
      "(7,940)\n",
      "(8,27)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hist = Map(0 -> 255, 5 -> 319149, 1 -> 4834, 6 -> 23106, 2 -> 168905, 7 -> 940, 3 -> 1259106, 8 -> 27, 4 -> 1394555)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map(0 -> 255, 5 -> 319149, 1 -> 4834, 6 -> 23106, 2 -> 168905, 7 -> 940, 3 -> 1259106, 8 -> 27, 4 -> 1394555)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val hist = paths.map(_._3).countByValue()\n",
    "    hist.toSeq.sorted.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "0708 - Scala",
   "language": "scala",
   "name": "0708_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
