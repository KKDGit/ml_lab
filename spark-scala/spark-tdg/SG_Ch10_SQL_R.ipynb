{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ul>\n",
       "<li><a href=\"Some(http://gw02.itversity.com:4041)\" target=\"new_tab\">Spark UI: application_1540458187951_76633</a></li>\n",
       "</ul>"
      ],
      "text/plain": [
       "Spark application_1540458187951_76633: Some(http://gw02.itversity.com:4041)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "http://rm01.itversity.com:19288/proxy/application_1540458187951_76633"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.getConf.getAll.filter(_._2.contains(\"/proxy/\"))(0)._2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getType: (o: Any)String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getType(o: Any) = o.getClass.getCanonicalName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "os_name = Linux\n",
       "hdfs_home = /user/kranthidr\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/user/kranthidr"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val os_name = System.getProperty(\"os.name\")\n",
    "val hdfs_home = \"/user/\" + System.getenv(\"HOME\").split(\"/\")(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_dir = /user/kranthidr/dataSets/spark-guide\n",
       "data_path = /user/kranthidr/dataSets/spark-guide/flight-data/json/2015-summary.json\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/user/kranthidr/dataSets/spark-guide/flight-data/json/2015-summary.json"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data_dir = \"/user/kranthidr/dataSets/spark-guide\"\n",
    "val data_path = data_dir + \"/flight-data/json/2015-summary.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.read.json(data_path).createOrReplaceTempView(\"some_sql_view\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "|DEST_COUNTRY_NAME|sum(count)|\n",
      "+-----------------+----------+\n",
      "|         Anguilla|        41|\n",
      "|           Russia|       176|\n",
      "|         Paraguay|        60|\n",
      "|          Senegal|        40|\n",
      "|           Sweden|       118|\n",
      "|         Kiribati|        26|\n",
      "|           Guyana|        64|\n",
      "|      Philippines|       134|\n",
      "|         Djibouti|         1|\n",
      "|         Malaysia|         2|\n",
      "+-----------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT DEST_COUNTRY_NAME, sum(count) FROM some_sql_view GROUP BY DEST_COUNTRY_NAME\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|   DEST_COUNTRY_NAME|sum(count)|\n",
      "+--------------------+----------+\n",
      "|             Senegal|        40|\n",
      "|              Sweden|       118|\n",
      "|               Spain|       420|\n",
      "|    Saint Barthelemy|        39|\n",
      "|Saint Kitts and N...|       139|\n",
      "|         South Korea|      1048|\n",
      "|        Sint Maarten|       325|\n",
      "|        Saudi Arabia|        83|\n",
      "|         Switzerland|       294|\n",
      "|         Saint Lucia|       123|\n",
      "+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT DEST_COUNTRY_NAME, sum(count) FROM some_sql_view GROUP BY DEST_COUNTRY_NAME\")\n",
    ".where(\"DEST_COUNTRY_NAME like 'S%'\")\n",
    ".where(\"`sum(count)` > 10\").show(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE DATABASE IF NOT EXISTS Kranthidr_db\n",
    "LOCATION '/user/kranthidr/Kranthidr_db'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "USE Kranthidr_db\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS flights (DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count LONG)\n",
    "USING JSON OPTIONS (path '/user/kranthidr/dataSets/spark-guide/flight-data/json/2015-summary.json')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "|    United States|          Singapore|    1|\n",
      "|    United States|            Grenada|   62|\n",
      "|       Costa Rica|      United States|  588|\n",
      "|          Senegal|      United States|   40|\n",
      "|          Moldova|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select * from flights limit 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE flights_csv (\n",
    "  DEST_COUNTRY_NAME STRING,\n",
    "  ORIGIN_COUNTRY_NAME STRING COMMENT \"remember, the US will be most prevalent\",\n",
    "  count LONG)\n",
    "USING csv OPTIONS (header true, path '/user/kranthidr/dataSets/spark-guide/flight-data/csv/2015-summary.csv')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "|    United States|          Singapore|    1|\n",
      "|    United States|            Grenada|   62|\n",
      "|       Costa Rica|      United States|  588|\n",
      "|          Senegal|      United States|   40|\n",
      "|          Moldova|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select * from flights_csv limit 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|databaseName|\n",
      "+------------+\n",
      "|     default|\n",
      "|kranthidr_db|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "show databases\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+-----------+\n",
      "|    database|    tableName|isTemporary|\n",
      "+------------+-------------+-----------+\n",
      "|kranthidr_db|      flights|      false|\n",
      "|kranthidr_db|  flights_csv|      false|\n",
      "|            |some_sql_view|       true|\n",
      "+------------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "show tables\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// spark.sql(\"\"\"\n",
    "// CREATE TABLE IF NOT EXISTS flights_from_select\n",
    "//   AS SELECT * FROM flights\n",
    "// \"\"\").show()\n",
    "\n",
    "// Name: org.apache.spark.sql.AnalysisException\n",
    "// Message: Hive support is required to CREATE Hive TABLE (AS SELECT);;\n",
    "\n",
    "\n",
    "\n",
    "// spark.sql(\"\"\"\n",
    "// SELECT * FROM flights_from_select\n",
    "// \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE partitioned_flights USING parquet PARTITIONED BY (DEST_COUNTRY_NAME)\n",
    "AS SELECT DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME, count FROM flights LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/user/kranthidr/dataSets/spark-guide/flight-data-hive/"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir+\"/flight-data-hive/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// spark.sql(\"\"\"\n",
    "// CREATE EXTERNAL TABLE hive_flights (\n",
    "//   DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count LONG)\n",
    "// ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LOCATION '/user/kranthidr/dataSets/spark-guide/flight-data-hive/'\n",
    "// \"\"\").show()\n",
    "\n",
    "// Name: org.apache.spark.sql.AnalysisException\n",
    "// Message: Hive support is required to CREATE Hive TABLE (AS SELECT);;\n",
    "// 'CreateTable `hive_flights`, org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, ErrorIfExists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// spark.sql(\"\"\"\n",
    "// CREATE EXTERNAL TABLE hive_flights_2\n",
    "// ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\n",
    "// LOCATION '/user/kranthidr/dataSets/spark-guide/flight-data-hive/' AS SELECT * FROM flights\n",
    "// \"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+-----------+\n",
      "|    database|          tableName|isTemporary|\n",
      "+------------+-------------------+-----------+\n",
      "|kranthidr_db|            flights|      false|\n",
      "|kranthidr_db|        flights_csv|      false|\n",
      "|kranthidr_db|partitioned_flights|      false|\n",
      "|            |      some_sql_view|       true|\n",
      "+------------+-------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "show tables\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// spark.sql(\"\"\"\n",
    "// INSERT INTO flights_from_select\n",
    "//   SELECT DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME, count FROM flights LIMIT 20\n",
    "// \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "INSERT INTO partitioned_flights\n",
    "  PARTITION (DEST_COUNTRY_NAME=\"UNITED STATES\")\n",
    "  SELECT count, ORIGIN_COUNTRY_NAME FROM flights\n",
    "  WHERE DEST_COUNTRY_NAME='UNITED STATES' LIMIT 12\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------------------+\n",
      "|           col_name|data_type|             comment|\n",
      "+-------------------+---------+--------------------+\n",
      "|  DEST_COUNTRY_NAME|   string|                null|\n",
      "|ORIGIN_COUNTRY_NAME|   string|remember, the US ...|\n",
      "|              count|   bigint|                null|\n",
      "+-------------------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "DESCRIBE TABLE flights_csv\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|partition                      |\n",
      "+-------------------------------+\n",
      "|DEST_COUNTRY_NAME=Egypt        |\n",
      "|DEST_COUNTRY_NAME=United States|\n",
      "+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SHOW PARTITIONS partitioned_flights\n",
    "\"\"\").show(20, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "REFRESH table partitioned_flights\n",
    "\"\"\").show(20, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "MSCK REPAIR TABLE partitioned_flights\n",
    "\"\"\").show(20, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "DROP TABLE flights_csv\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "DROP TABLE IF EXISTS flights_csv\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CACHE TABLE flights\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "UNCACHE TABLE FLIGHTS\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE VIEW IF NOT EXISTS just_usa_view AS\n",
    "  SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TEMP VIEW just_usa_view_temp AS\n",
    "  SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE GLOBAL TEMP VIEW just_usa_global_view_temp AS\n",
    "  SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+-----------+\n",
      "|    database|          tableName|isTemporary|\n",
      "+------------+-------------------+-----------+\n",
      "|kranthidr_db|            flights|      false|\n",
      "|kranthidr_db|      just_usa_view|      false|\n",
      "|kranthidr_db|partitioned_flights|      false|\n",
      "|            | just_usa_view_temp|       true|\n",
      "|            |      some_sql_view|       true|\n",
      "+------------+-------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SHOW TABLES\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW just_usa_view_temp AS\n",
    "  SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-----+\n",
      "|DEST_COUNTRY_NAME| ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+--------------------+-----+\n",
      "|    United States|             Romania|   15|\n",
      "|    United States|             Croatia|    1|\n",
      "|    United States|             Ireland|  344|\n",
      "|    United States|               India|   62|\n",
      "|    United States|           Singapore|    1|\n",
      "|    United States|             Grenada|   62|\n",
      "|    United States|        Sint Maarten|  325|\n",
      "|    United States|    Marshall Islands|   39|\n",
      "|    United States|            Paraguay|    6|\n",
      "|    United States|           Gibraltar|    1|\n",
      "|    United States|Federated States ...|   69|\n",
      "|    United States|              Russia|  161|\n",
      "|    United States|         Netherlands|  660|\n",
      "|    United States|             Senegal|   42|\n",
      "|    United States|              Angola|   13|\n",
      "|    United States|            Anguilla|   38|\n",
      "|    United States|             Ecuador|  300|\n",
      "|    United States|              Cyprus|    1|\n",
      "|    United States|            Portugal|  134|\n",
      "|    United States|          Costa Rica|  608|\n",
      "+-----------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM just_usa_view_temp\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([== Physical Plan ==\n",
       "*(1) Project [DEST_COUNTRY_NAME#52, ORIGIN_COUNTRY_NAME#53, count#54L]\n",
       "+- *(1) Filter (isnotnull(dest_country_name#52) && (dest_country_name#52 = United States))\n",
       "   +- *(1) FileScan json kranthidr_db.flights[DEST_COUNTRY_NAME#52,ORIGIN_COUNTRY_NAME#53,count#54L] Batched: false, Format: JSON, Location: InMemoryFileIndex[hdfs://nn01.itversity.com:8020/user/kranthidr/dataSets/spark-guide/flight-data/..., PartitionFilters: [], PushedFilters: [IsNotNull(DEST_COUNTRY_NAME), EqualTo(DEST_COUNTRY_NAME,United States)], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:bigint>])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><td>== Physical Plan ==\n",
       "*(1) Project [DEST_COUNTRY_NAME#52, ORIGIN_COUNTRY_NAME#53, count#54L]\n",
       "+- *(1) Filter (isnotnull(dest_country_name#52) && (dest_country_name#52 = United States))\n",
       "   +- *(1) FileScan json kranthidr_db.flights[DEST_COUNTRY_NAME#52,ORIGIN_COUNTRY_NAME#53,count#54L] Batched: false, Format: JSON, Location: InMemoryFileIndex[hdfs://nn01.itversity.com:8020/user/kranthidr/dataSets/spark-guide/flight-data/..., PartitionFilters: [], PushedFilters: [IsNotNull(DEST_COUNTRY_NAME), EqualTo(DEST_COUNTRY_NAME,United States)], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:bigint></td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
       "| == Physical Plan ==\n",
       "*(1) Project [DEST_COUNTRY_NAME#52, ORIGIN_COUNTRY_NAME#53, count#54L]\n",
       "+- *(1) Filter (isnotnull(dest_country_name#52) && (dest_country_name#52 = United States))\n",
       "   +- *(1) FileScan json kranthidr_db.flights[DEST_COUNTRY_NAME#52,ORIGIN_COUNTRY_NAME#53,count#54L] Batched: false, Format: JSON, Location: InMemoryFileIndex[hdfs://nn01.itversity.com:8020/user/kranthidr/dataSets/spark-guide/flight-data/..., PartitionFilters: [], PushedFilters: [IsNotNull(DEST_COUNTRY_NAME), EqualTo(DEST_COUNTRY_NAME,United States)], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:bigint> |\n",
       "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "EXPLAIN SELECT * FROM just_usa_view\n",
    "\"\"\").take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[== Physical Plan ==\n",
       "*(1) Project [DEST_COUNTRY_NAME#52, ORIGIN_COUNTRY_NAME#53, count#54L]\n",
       "+- *(1) Filter (isnotnull(dest_country_name#52) && (dest_country_name#52 = United States))\n",
       "   +- *(1) FileScan json kranthidr_db.flights[DEST_COUNTRY_NAME#52,ORIGIN_COUNTRY_NAME#53,count#54L] Batched: false, Format: JSON, Location: InMemoryFileIndex[hdfs://nn01.itversity.com:8020/user/kranthidr/dataSets/spark-guide/flight-data/..., PartitionFilters: [], PushedFilters: [IsNotNull(DEST_COUNTRY_NAME), EqualTo(DEST_COUNTRY_NAME,United States)], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:bigint>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "EXPLAIN SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\"\"\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "DROP VIEW IF EXISTS just_usa_view\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|databaseName|\n",
      "+------------+\n",
      "|kranthidr_db|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SHOW DATABASES 'kr*'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SHOW DATABASES\n",
    "\"\"\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// spark.sql(\"\"\"\n",
    "// SELECT * FROM default.flights\n",
    "// \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|current_database()|\n",
      "+------------------+\n",
      "|      kranthidr_db|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT current_database()\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// # spark.sql(\"\"\"\n",
    "// # DROP DATABASE IF EXISTS kranthidr_db\n",
    "// # \"\"\").show()\n",
    "\n",
    "// # AnalysisException: u'org.apache.hadoop.hive.ql.metadata.HiveException: \n",
    "// #     InvalidOperationException(message:Database kranthidr_db is not empty. One or more tables exist.);'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// # SELECT [ALL|DISTINCT] named_expression[, named_expression, ...]\n",
    "// #     FROM relation[, relation, ...]\n",
    "// #     [lateral_view[, lateral_view, ...]]\n",
    "// #     [WHERE boolean_expression]\n",
    "// #     [aggregation [HAVING boolean_expression]]\n",
    "// #     [ORDER BY sort_expressions]\n",
    "// #     [CLUSTER BY expressions]\n",
    "// #     [DISTRIBUTE BY expressions]\n",
    "// #     [SORT BY sort_expressions]\n",
    "// #     [WINDOW named_window[, WINDOW named_window, ...]]\n",
    "// #     [LIMIT num_rows]\n",
    "\n",
    "// # named_expression:\n",
    "// #     : expression [AS alias]\n",
    "\n",
    "// # relation:\n",
    "// #     | join_relation\n",
    "// #     | (table_name|query|relation) [sample] [AS alias]\n",
    "// #     : VALUES (expressions)[, (expressions), ...]\n",
    "// #           [AS (column_name[, column_name, ...])]\n",
    "\n",
    "// # expressions:\n",
    "// #     : expression[, expression, ...]\n",
    "\n",
    "// # sort_expressions:\n",
    "// #     : expression [ASC|DESC][, expression [ASC|DESC], ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------+\n",
      "|CASE WHEN (DEST_COUNTRY_NAME = UNITED STATES) THEN 1 WHEN (DEST_COUNTRY_NAME = Egypt) THEN 0 ELSE -1 END|\n",
      "+--------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                      -1|\n",
      "|                                                                                                      -1|\n",
      "|                                                                                                      -1|\n",
      "|                                                                                                      -1|\n",
      "|                                                                                                       0|\n",
      "+--------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "  CASE WHEN DEST_COUNTRY_NAME = 'UNITED STATES' THEN 1\n",
    "       WHEN DEST_COUNTRY_NAME = 'Egypt' THEN 0\n",
    "       ELSE -1 END\n",
    "FROM partitioned_flights\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE VIEW IF NOT EXISTS nested_data AS\n",
    "  SELECT (DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME) as country, count FROM flights\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----+\n",
      "|country                 |count|\n",
      "+------------------------+-----+\n",
      "|[United States, Romania]|15   |\n",
      "|[United States, Croatia]|1    |\n",
      "|[United States, Ireland]|344  |\n",
      "+------------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM nested_data\n",
    "\"\"\").show(3, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|DEST_COUNTRY_NAME|count|\n",
      "+-----------------+-----+\n",
      "|United States    |15   |\n",
      "|United States    |1    |\n",
      "|United States    |344  |\n",
      "|Egypt            |15   |\n",
      "|United States    |62   |\n",
      "+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT country.DEST_COUNTRY_NAME, count FROM nested_data\n",
    "\"\"\").show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |15   |\n",
      "|United States    |Croatia            |1    |\n",
      "|United States    |Ireland            |344  |\n",
      "|Egypt            |United States      |15   |\n",
      "|United States    |India              |62   |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT country.*, count FROM nested_data\n",
    "\"\"\").show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+---------------+\n",
      "|new_name|flight_counts|origin_set     |\n",
      "+--------+-------------+---------------+\n",
      "|Anguilla|[41]         |[United States]|\n",
      "|Paraguay|[60]         |[United States]|\n",
      "|Russia  |[176]        |[United States]|\n",
      "|Senegal |[40]         |[United States]|\n",
      "|Sweden  |[118]        |[United States]|\n",
      "+--------+-------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT DEST_COUNTRY_NAME as new_name, collect_list(count) as flight_counts,\n",
    "  collect_set(ORIGIN_COUNTRY_NAME) as origin_set\n",
    "FROM flights GROUP BY DEST_COUNTRY_NAME\n",
    "\"\"\").show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------+\n",
      "|DEST_COUNTRY_NAME|array(1, 2, 3)|\n",
      "+-----------------+--------------+\n",
      "|United States    |[1, 2, 3]     |\n",
      "|United States    |[1, 2, 3]     |\n",
      "|United States    |[1, 2, 3]     |\n",
      "|Egypt            |[1, 2, 3]     |\n",
      "|United States    |[1, 2, 3]     |\n",
      "+-----------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, ARRAY(1, 2, 3) FROM flights\n",
    "\"\"\").show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------------+\n",
      "|new_name|collect_list(count)[0]|\n",
      "+--------+----------------------+\n",
      "|Anguilla|41                    |\n",
      "|Paraguay|60                    |\n",
      "|Russia  |176                   |\n",
      "|Senegal |40                    |\n",
      "|Sweden  |118                   |\n",
      "+--------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT DEST_COUNTRY_NAME as new_name, collect_list(count)[0]\n",
    "FROM flights GROUP BY DEST_COUNTRY_NAME\n",
    "\"\"\").show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW flights_agg AS\n",
    "  SELECT DEST_COUNTRY_NAME, collect_list(count) as collected_counts\n",
    "  FROM flights GROUP BY DEST_COUNTRY_NAME\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+\n",
      "|col|DEST_COUNTRY_NAME|\n",
      "+---+-----------------+\n",
      "|41 |Anguilla         |\n",
      "|60 |Paraguay         |\n",
      "|176|Russia           |\n",
      "|40 |Senegal          |\n",
      "|118|Sweden           |\n",
      "+---+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT explode(collected_counts), DEST_COUNTRY_NAME FROM flights_agg\n",
    "\"\"\").show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            function|\n",
      "+--------------------+\n",
      "|                   !|\n",
      "|                   %|\n",
      "|                   &|\n",
      "|                   *|\n",
      "|                   +|\n",
      "|                   -|\n",
      "|                   /|\n",
      "|                   <|\n",
      "|                  <=|\n",
      "|                 <=>|\n",
      "|                   =|\n",
      "|                  ==|\n",
      "|                   >|\n",
      "|                  >=|\n",
      "|                   ^|\n",
      "|                 abs|\n",
      "|                acos|\n",
      "|          add_months|\n",
      "|                 and|\n",
      "|approx_count_dist...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SHOW FUNCTIONS\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            function|\n",
      "+--------------------+\n",
      "|                   !|\n",
      "|                   %|\n",
      "|                   &|\n",
      "|                   *|\n",
      "|                   +|\n",
      "|                   -|\n",
      "|                   /|\n",
      "|                   <|\n",
      "|                  <=|\n",
      "|                 <=>|\n",
      "|                   =|\n",
      "|                  ==|\n",
      "|                   >|\n",
      "|                  >=|\n",
      "|                   ^|\n",
      "|                 abs|\n",
      "|                acos|\n",
      "|          add_months|\n",
      "|                 and|\n",
      "|approx_count_dist...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SHOW SYSTEM FUNCTIONS\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|function|\n",
      "+--------+\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SHOW USER FUNCTIONS\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|          function|\n",
      "+------------------+\n",
      "|            second|\n",
      "|         sentences|\n",
      "|               sha|\n",
      "|              sha1|\n",
      "|              sha2|\n",
      "|         shiftleft|\n",
      "|        shiftright|\n",
      "|shiftrightunsigned|\n",
      "|              sign|\n",
      "|            signum|\n",
      "|               sin|\n",
      "|              sinh|\n",
      "|              size|\n",
      "|          skewness|\n",
      "|          smallint|\n",
      "|        sort_array|\n",
      "|           soundex|\n",
      "|             space|\n",
      "|spark_partition_id|\n",
      "|             split|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SHOW FUNCTIONS \"s*\"\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|    function|\n",
      "+------------+\n",
      "|collect_list|\n",
      "| collect_set|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SHOW FUNCTIONS LIKE \"collect*\"\n",
    "\"\"\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|current_database()|\n",
      "+------------------+\n",
      "|      kranthidr_db|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select current_database()\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|dest_country_name|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|           Canada|\n",
      "|           Mexico|\n",
      "|   United Kingdom|\n",
      "|            Japan|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT dest_country_name FROM flights\n",
    "GROUP BY dest_country_name ORDER BY sum(count) DESC LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|               Egypt|      United States|   15|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|               Italy|      United States|  382|\n",
      "|            Pakistan|      United States|   12|\n",
      "|             Iceland|      United States|  181|\n",
      "|    Marshall Islands|      United States|   42|\n",
      "|          Luxembourg|      United States|  155|\n",
      "|            Honduras|      United States|  362|\n",
      "|         The Bahamas|      United States|  955|\n",
      "|         El Salvador|      United States|  561|\n",
      "|               Samoa|      United States|   25|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM flights\n",
    "WHERE origin_country_name IN (SELECT dest_country_name FROM flights\n",
    "      GROUP BY dest_country_name ORDER BY sum(count) DESC LIMIT 5)\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|   DEST_COUNTRY_NAME| ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+--------------------+-----+\n",
      "|       United States|             Romania|   15|\n",
      "|       United States|             Croatia|    1|\n",
      "|       United States|             Ireland|  344|\n",
      "|               Egypt|       United States|   15|\n",
      "|       United States|               India|   62|\n",
      "|       United States|           Singapore|    1|\n",
      "|       United States|             Grenada|   62|\n",
      "|          Costa Rica|       United States|  588|\n",
      "|             Senegal|       United States|   40|\n",
      "|       United States|        Sint Maarten|  325|\n",
      "|       United States|    Marshall Islands|   39|\n",
      "|              Guyana|       United States|   64|\n",
      "|               Malta|       United States|    1|\n",
      "|            Anguilla|       United States|   41|\n",
      "|             Bolivia|       United States|   30|\n",
      "|       United States|            Paraguay|    6|\n",
      "|Turks and Caicos ...|       United States|  230|\n",
      "|               Italy|       United States|  382|\n",
      "|       United States|Federated States ...|   69|\n",
      "|       United States|              Russia|  161|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM flights f1\n",
    "WHERE EXISTS (SELECT 1 FROM flights f2\n",
    "            WHERE f1.dest_country_name = f2.origin_country_name)\n",
    "AND EXISTS (SELECT 1 FROM flights f2\n",
    "            WHERE f2.dest_country_name = f1.origin_country_name)\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+-------+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|maximum|\n",
      "+--------------------+-------------------+-----+-------+\n",
      "|       United States|            Romania|   15| 370002|\n",
      "|       United States|            Croatia|    1| 370002|\n",
      "|       United States|            Ireland|  344| 370002|\n",
      "|               Egypt|      United States|   15| 370002|\n",
      "|       United States|              India|   62| 370002|\n",
      "|       United States|          Singapore|    1| 370002|\n",
      "|       United States|            Grenada|   62| 370002|\n",
      "|          Costa Rica|      United States|  588| 370002|\n",
      "|             Senegal|      United States|   40| 370002|\n",
      "|             Moldova|      United States|    1| 370002|\n",
      "|       United States|       Sint Maarten|  325| 370002|\n",
      "|       United States|   Marshall Islands|   39| 370002|\n",
      "|              Guyana|      United States|   64| 370002|\n",
      "|               Malta|      United States|    1| 370002|\n",
      "|            Anguilla|      United States|   41| 370002|\n",
      "|             Bolivia|      United States|   30| 370002|\n",
      "|       United States|           Paraguay|    6| 370002|\n",
      "|             Algeria|      United States|    4| 370002|\n",
      "|Turks and Caicos ...|      United States|  230| 370002|\n",
      "|       United States|          Gibraltar|    1| 370002|\n",
      "+--------------------+-------------------+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT *, (SELECT max(count) FROM flights) AS maximum FROM flights\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                 key|value|\n",
      "+--------------------+-----+\n",
      "|spark.sql.shuffle...|   20|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SET spark.sql.shuffle.partitions=20\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|(1 + 1)|\n",
      "+-------+\n",
      "|      2|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT 1 + 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "spark.read.json(data_path)\n",
    "  .createOrReplaceTempView(\"some_sql_view_scala\") // DF => SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [DEST_COUNTRY_NAME#655, ORIGIN_COUNTRY_NAME#656, count#657L]\n",
      "+- *(1) Filter (isnotnull(dest_country_name#655) && (dest_country_name#655 = United States))\n",
      "   +- *(1) FileScan json [DEST_COUNTRY_NAME#655,ORIGIN_COUNTRY_NAME#656,count#657L] Batched: false, Format: JSON, Location: InMemoryFileIndex[hdfs://nn01.itversity.com:8020/user/kranthidr/dataSets/spark-guide/flight-data/..., PartitionFilters: [], PushedFilters: [IsNotNull(DEST_COUNTRY_NAME), EqualTo(DEST_COUNTRY_NAME,United States)], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:bigint>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "flights_scala = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n",
       "just_usa_df_scala = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, sum(count)\n",
    "FROM some_sql_view_scala GROUP BY DEST_COUNTRY_NAME\n",
    "\"\"\")\n",
    "  .where(\"DEST_COUNTRY_NAME like 'S%'\").where(\"`sum(count)` > 10\")\n",
    "  .count() // SQL => DF\n",
    "\n",
    "\n",
    "// COMMAND ----------\n",
    "\n",
    "val flights_scala = spark.read.format(\"json\")\n",
    "  .load(data_path)\n",
    "\n",
    "val just_usa_df_scala = flights_scala.where(\"dest_country_name = 'United States'\")\n",
    "\n",
    "just_usa_df_scala.selectExpr(\"*\").explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "power3_scalaf: (number: Double)Double\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function1>,DoubleType,Some(List(DoubleType)))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "def power3_scalaf(number:Double):Double = number * number * number\n",
    "\n",
    "spark.udf.register(\"power3_scala\", power3_scalaf(_:Double):Double)\n",
    "\n",
    "\n",
    "// COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------------+\n",
      "|count|UDF:power3_scala(cast(count as double))|\n",
      "+-----+---------------------------------------+\n",
      "|   15|                                 3375.0|\n",
      "|    1|                                    1.0|\n",
      "|  344|                            4.0707584E7|\n",
      "|   15|                                 3375.0|\n",
      "|   62|                               238328.0|\n",
      "|    1|                                    1.0|\n",
      "|   62|                               238328.0|\n",
      "|  588|                           2.03297472E8|\n",
      "|   40|                                64000.0|\n",
      "|    1|                                    1.0|\n",
      "|  325|                            3.4328125E7|\n",
      "|   39|                                59319.0|\n",
      "|   64|                               262144.0|\n",
      "|    1|                                    1.0|\n",
      "|   41|                                68921.0|\n",
      "|   30|                                27000.0|\n",
      "|    6|                                  216.0|\n",
      "|    4|                                   64.0|\n",
      "|  230|                               1.2167E7|\n",
      "|    1|                                    1.0|\n",
      "+-----+---------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT count, power3_scala(count) FROM flights\n",
    " \"\"\").show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark - Scala",
   "language": "scala",
   "name": "spark_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
