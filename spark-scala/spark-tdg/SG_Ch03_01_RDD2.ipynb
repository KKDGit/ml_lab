{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@1b24af2c"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "http://gw02.itversity.com:4053"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.driver.appUIAddress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getType: (o: Any)String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "def getType(o: Any) = o.getClass.getTypeName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "os_name = Linux\n",
       "hdfs_home = /user/kkdosapati\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "/user/kkdosapati"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val os_name = System.getProperty(\"os.name\")\n",
    "val hdfs_home = \"/user/\" + System.getenv(\"HOME\").split(\"/\")(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path = /user/kkdosapati/dataSets/samples/auto_data.csv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "/user/kkdosapati/dataSets/samples/auto_data.csv"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val path = hdfs_home + \"/dataSets/samples/auto_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "raw_data1 = [value: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[value: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val raw_data1 = spark.read.text(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|MAKE,FUELTYPE,ASP...|\n",
      "|subaru,gas,std,tw...|\n",
      "|chevrolet,gas,std...|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data1.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([MAKE,FUELTYPE,ASPIRE,DOORS,BODY,DRIVE,CYLINDERS,HP,RPM,MPG-CITY,MPG-HWY,PRICE], [subaru,gas,std,two,hatchback,fwd,four,69,4900,31,36,5118], [chevrolet,gas,std,two,hatchback,fwd,three,48,5100,47,53,5151], [mazda,gas,std,two,hatchback,fwd,four,68,5000,30,31,5195], [toyota,gas,std,two,hatchback,fwd,four,62,4800,35,39,5348])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org.apache.spark.sql.Dataset\n",
      "org.apache.spark.sql.Row[]\n",
      "org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema\n"
     ]
    }
   ],
   "source": [
    "println(getType(raw_data1))\n",
    "println(getType(raw_data1.take(1)))\n",
    "println(getType(raw_data1.take(1)(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "raw_data2 = /user/kkdosapati/dataSets/samples/auto_data.csv MapPartitionsRDD[17] at textFile at <console>:31\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "/user/kkdosapati/dataSets/samples/auto_data.csv MapPartitionsRDD[17] at textFile at <console>:31"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val raw_data2 = sc.textFile(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(MAKE,FUELTYPE,ASPIRE,DOORS,BODY,DRIVE,CYLINDERS,HP,RPM,MPG-CITY,MPG-HWY,PRICE, subaru,gas,std,two,hatchback,fwd,four,69,4900,31,36,5118, chevrolet,gas,std,two,hatchback,fwd,three,48,5100,47,53,5151, mazda,gas,std,two,hatchback,fwd,four,68,5000,30,31,5195, toyota,gas,std,two,hatchback,fwd,four,62,4800,35,39,5348)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org.apache.spark.rdd.MapPartitionsRDD\n",
      "java.lang.String[]\n",
      "java.lang.String\n"
     ]
    }
   ],
   "source": [
    "println(getType(raw_data2))\n",
    "println(getType(raw_data2.take(1)))\n",
    "println(getType(raw_data2.take(1)(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|MAKE,FUELTYPE,ASP...|\n",
      "|subaru,gas,std,tw...|\n",
      "|chevrolet,gas,std...|\n",
      "|mazda,gas,std,two...|\n",
      "|toyota,gas,std,tw...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "raw_data2DF1 = [value: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[value: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val raw_data2DF1 = raw_data2.toDF()\n",
    "raw_data2DF1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org.apache.spark.sql.Dataset\n",
      "org.apache.spark.sql.Row[]\n",
      "org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema\n"
     ]
    }
   ],
   "source": [
    "println(getType(raw_data2DF1))\n",
    "println(getType(raw_data2DF1.take(1)))\n",
    "println(getType(raw_data2DF1.take(1)(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.Row\n",
    "\n",
    "//val raw_data2DF2 = raw_data2.map(x => Row(x)).toDF(\"k\")\n",
    "//val raw_data2DF3 = raw_data2.map(x => Row(x)).toDF()\n",
    "//raw_data2DF2.show(2)\n",
    "//raw_data2DF3.show(2)\n",
    "//error: value toDF is not a member of org.apache.spark.rdd.RDD[org.apache.spark.sql.Row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "raw_dataDF1 = [k: string]\n",
       "raw_dataDF2 = [value: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[value: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val raw_dataDF1 = raw_data1.toDF(\"k\")\n",
    "val raw_dataDF2 = raw_data1.toDF() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                   k|\n",
      "+--------------------+\n",
      "|MAKE,FUELTYPE,ASP...|\n",
      "|subaru,gas,std,tw...|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_dataDF1.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|MAKE,FUELTYPE,ASP...|\n",
      "|subaru,gas,std,tw...|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_dataDF2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- k: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_dataDF1.printSchema()\n",
    "raw_dataDF2.printSchema()\n",
    "raw_data2DF1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "raw_dataDF = [value: string]\n",
       "d1 = [value: array<string>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[value: array<string>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val raw_dataDF = raw_data1.toDF(\"value\")\n",
    "val d1  = raw_dataDF.selectExpr(\"split(value, ',') as value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org.apache.spark.sql.Dataset\n",
      "org.apache.spark.sql.Row[]\n",
      "org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema\n"
     ]
    }
   ],
   "source": [
    "println(getType(d1))\n",
    "println(getType(d1.take(1)))\n",
    "println(getType(d1.take(1)(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|[MAKE, FUELTYPE, ...|\n",
      "|[subaru, gas, std...|\n",
      "|[chevrolet, gas, ...|\n",
      "|[mazda, gas, std,...|\n",
      "+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d1.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d2 = [value[0]: string, value[1]: string ... 6 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[value[0]: string, value[1]: string ... 6 more fields]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val d2 = d1.selectExpr(\"value[0]\", \"value[1]\", \"value[2]\", \"value[3]\", \"value[4]\", \"value[5]\", \"value[6]\", \"value[7]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------+--------+---------+--------+---------+--------+\n",
      "| value[0]|value[1]|value[2]|value[3]| value[4]|value[5]| value[6]|value[7]|\n",
      "+---------+--------+--------+--------+---------+--------+---------+--------+\n",
      "|     MAKE|FUELTYPE|  ASPIRE|   DOORS|     BODY|   DRIVE|CYLINDERS|      HP|\n",
      "|   subaru|     gas|     std|     two|hatchback|     fwd|     four|      69|\n",
      "|chevrolet|     gas|     std|     two|hatchback|     fwd|    three|      48|\n",
      "+---------+--------+--------+--------+---------+--------+---------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d2.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value[0]: string (nullable = true)\n",
      " |-- value[1]: string (nullable = true)\n",
      " |-- value[2]: string (nullable = true)\n",
      " |-- value[3]: string (nullable = true)\n",
      " |-- value[4]: string (nullable = true)\n",
      " |-- value[5]: string (nullable = true)\n",
      " |-- value[6]: string (nullable = true)\n",
      " |-- value[7]: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [MAKE: string, FUELTYPE: string ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[MAKE: string, FUELTYPE: string ... 10 more fields]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.option(\"header\", true).option(\"inferSchema\", true).csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+-----+---------+-----+---------+---+----+--------+-------+-----+\n",
      "|     MAKE|FUELTYPE|ASPIRE|DOORS|     BODY|DRIVE|CYLINDERS| HP| RPM|MPG-CITY|MPG-HWY|PRICE|\n",
      "+---------+--------+------+-----+---------+-----+---------+---+----+--------+-------+-----+\n",
      "|   subaru|     gas|   std|  two|hatchback|  fwd|     four| 69|4900|      31|     36| 5118|\n",
      "|chevrolet|     gas|   std|  two|hatchback|  fwd|    three| 48|5100|      47|     53| 5151|\n",
      "|    mazda|     gas|   std|  two|hatchback|  fwd|     four| 68|5000|      30|     31| 5195|\n",
      "+---------+--------+------+-----+---------+-----+---------+---+----+--------+-------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MAKE: string (nullable = true)\n",
      " |-- FUELTYPE: string (nullable = true)\n",
      " |-- ASPIRE: string (nullable = true)\n",
      " |-- DOORS: string (nullable = true)\n",
      " |-- BODY: string (nullable = true)\n",
      " |-- DRIVE: string (nullable = true)\n",
      " |-- CYLINDERS: string (nullable = true)\n",
      " |-- HP: integer (nullable = true)\n",
      " |-- RPM: integer (nullable = true)\n",
      " |-- MPG-CITY: integer (nullable = true)\n",
      " |-- MPG-HWY: integer (nullable = true)\n",
      " |-- PRICE: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_spark - Scala",
   "language": "scala",
   "name": "my_spark_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
