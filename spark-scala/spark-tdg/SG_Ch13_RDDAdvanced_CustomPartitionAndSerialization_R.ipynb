{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ul>\n",
       "<li><a href=\"Some(http://gw02.itversity.com:4044)\" target=\"new_tab\">Spark UI: application_1540458187951_76531</a></li>\n",
       "</ul>"
      ],
      "text/plain": [
       "Spark application_1540458187951_76531: Some(http://gw02.itversity.com:4044)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "http://rm01.itversity.com:19288/proxy/application_1540458187951_76531"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.getConf.getAll.filter(_._2.contains(\"/proxy/\"))(0)._2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getType: (o: Any)String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getType(o: Any) = o.getClass.getCanonicalName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "os_name = Linux\n",
       "hdfs_home = /user/kranthidr\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/user/kranthidr"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val os_name = System.getProperty(\"os.name\")\n",
    "val hdfs_home = \"/user/\" + System.getenv(\"HOME\").split(\"/\")(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path = /user/kranthidr/dataSets/spark-guide/retail-data/all/\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/user/kranthidr/dataSets/spark-guide/retail-data/all/"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val path = hdfs_home+\"/dataSets/spark-guide/retail-data/all/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myCollection = Array(Spark, The, Definitive, Guide, :, Big, Data, Processing, Made, Simple)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Spark, The, Definitive, Guide, :, Big, Data, Processing, Made, Simple]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// in Scala\n",
    "val myCollection = \"Spark The Definitive Guide : Big Data Processing Made Simple\"\n",
    "  .split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "words = ParallelCollectionRDD[0] at parallelize at <console>:29\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at parallelize at <console>:29"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val words = spark.sparkContext.parallelize(myCollection, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|        _1| _2|\n",
      "+----------+---+\n",
      "|     spark|  1|\n",
      "|       the|  1|\n",
      "|definitive|  1|\n",
      "|     guide|  1|\n",
      "|         :|  1|\n",
      "|       big|  1|\n",
      "|      data|  1|\n",
      "|processing|  1|\n",
      "|      made|  1|\n",
      "|    simple|  1|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "words.map(word => (word.toLowerCase, 1)).toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword = MapPartitionsRDD[2] at keyBy at <console>:34\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[2] at keyBy at <console>:34"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "val keyword = words.keyBy(word => word.toLowerCase.toSeq(0).toString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(s,SPARK), (t,THE), (d,DEFINITIVE), (g,GUIDE), (:,:), (b,BIG), (d,DATA), (p,PROCESSING), (m,MADE), (s,SIMPLE)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "keyword.mapValues(word => word.toUpperCase).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(s,S), (s,P), (s,A), (s,R), (s,K), (t,T), (t,H), (t,E), (d,D), (d,E), (d,F), (d,I), (d,N), (d,I), (d,T), (d,I), (d,V), (d,E), (g,G), (g,U), (g,I), (g,D), (g,E), (:,:), (b,B), (b,I), (b,G), (d,D), (d,A), (d,T), (d,A), (p,P), (p,R), (p,O), (p,C), (p,E), (p,S), (p,S), (p,I), (p,N), (p,G), (m,M), (m,A), (m,D), (m,E), (s,S), (s,I), (s,M), (s,P), (s,L), (s,E)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "keyword.flatMapValues(word => word.toUpperCase).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[s, t, d, g, :, b, d, p, m, s]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "keyword.keys.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Spark, The, Definitive, Guide, :, Big, Data, Processing, Made, Simple]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword.values.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WrappedArray(Spark, Simple)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "keyword.lookup(\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distinctChars = Array(d, p, t, b, h, n, f, v, :, r, l, s, e, a, i, k, u, o, g, m, c)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[d, p, t, b, h, n, f, v, :, r, l, s, e, a, i, k, u, o, g, m, c]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "val distinctChars = words.flatMap(word => word.toLowerCase.toSeq).distinct\n",
    "  .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sampleMap = Map(e -> 0.6184628471903946, s -> 0.7845831995585668, n -> 0.2106425190634641, t -> 0.5605833127553262, u -> 0.8500050896937804, f -> 0.4276723646796573, a -> 0.4064772189611612, m -> 0.9637564021549372, i -> 0.2984677866622836, v -> 0.23795567636921955, b -> 0.13741314562606688, g -> 0.16359595149990858, l -> 0.9946906427009541, p -> 0.9735165938620162, c -> 0.10244068917001692, h -> 0.41350901295072573, r -> 0.4677198202405577, : -> 0.13442695453682418, k -> 0.472442227058679, o -> 0.9718735784579532, d -> 0.6653115438651054)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(s,Spark), (t,The), (d,Definitive)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.util.Random\n",
    "val sampleMap = distinctChars.map(c => (c, new Random().nextDouble())).toMap\n",
    "\n",
    "words.map(word => (word.toLowerCase.toSeq(0), word))\n",
    "  .sampleByKey(true, sampleMap, 6L)\n",
    "  .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(s,Spark), (t,The), (d,Definitive), (d,Definitive), (g,Guide), (:,:), (b,Big), (p,Processing), (m,Made), (s,Simple)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "words.map(word => (word.toLowerCase.toSeq(0), word))\n",
    "  .sampleByKeyExact(true, sampleMap, 6L).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chars = MapPartitionsRDD[26] at flatMap at <console>:37\n",
       "KVcharacters = MapPartitionsRDD[27] at map at <console>:38\n",
       "nums = ParallelCollectionRDD[28] at parallelize at <console>:41\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "maxFunc: (left: Int, right: Int)Int\n",
       "addFunc: (left: Int, right: Int)Int\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[28] at parallelize at <console>:41"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "val chars = words.flatMap(word => word.toLowerCase.toSeq)\n",
    "val KVcharacters = chars.map(letter => (letter, 1))\n",
    "def maxFunc(left:Int, right:Int) = math.max(left, right)\n",
    "def addFunc(left:Int, right:Int) = left + right\n",
    "val nums = sc.parallelize(1 to 30, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timeout = 1000\n",
       "confidence = 0.95\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map(e -> 7, s -> 4, n -> 2, t -> 3, u -> 1, f -> 1, a -> 4, m -> 2, i -> 7, v -> 1, b -> 1, g -> 3, l -> 1, p -> 3, c -> 1, h -> 1, r -> 2, : -> 1, k -> 1, o -> 1, d -> 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "val timeout = 1000L //milliseconds\n",
    "val confidence = 0.95\n",
    "KVcharacters.countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(final: Map(e -> [7.000, 7.000], s -> [4.000, 4.000], n -> [2.000, 2.000], t -> [3.000, 3.000], u -> [1.000, 1.000], f -> [1.000, 1.000], a -> [4.000, 4.000], m -> [2.000, 2.000], i -> [7.000, 7.000], v -> [1.000, 1.000], b -> [1.000, 1.000], g -> [3.000, 3.000], l -> [1.000, 1.000], p -> [3.000, 3.000], c -> [1.000, 1.000], h -> [1.000, 1.000], r -> [2.000, 2.000], : -> [1.000, 1.000], k -> [1.000, 1.000], o -> [1.000, 1.000], d -> [4.000, 4.000]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KVcharacters.countByKeyApprox(timeout, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(d,4), (p,3), (t,3), (b,1), (h,1), (n,2), (f,1), (v,1), (:,1), (r,2), (l,1), (s,4), (e,7), (a,4), (i,7), (k,1), (u,1), (o,1), (g,3), (m,2), (c,1)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "KVcharacters.groupByKey().map(row => (row._1, row._2.reduce(addFunc))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(d,4), (p,3), (t,3), (b,1), (h,1), (n,2), (f,1), (v,1), (:,1), (r,2), (l,1), (s,4), (e,7), (a,4), (i,7), (k,1), (u,1), (o,1), (g,3), (m,2), (c,1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "KVcharacters.reduceByKey(addFunc).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "nums.aggregate(0)(maxFunc, addFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "depth = 3\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "val depth = 3\n",
    "nums.treeAggregate(0)(maxFunc, addFunc, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(d,2), (p,2), (t,2), (b,1), (h,1), (n,1), (f,1), (v,1), (:,1), (r,1), (l,1), (s,3), (e,4), (a,3), (i,4), (k,1), (u,1), (o,1), (g,2), (m,2), (c,1)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "KVcharacters.aggregateByKey(0)(addFunc, maxFunc).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "valToCombiner = > List[Int] = <function1>\n",
       "mergeValuesFunc = > List[Int] = <function2>\n",
       "mergeCombinerFunc = > List[Int] = <function2>\n",
       "outputPartitions = 6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(f,List(1)), (r,List(1, 1)), (l,List(1)), (s,List(1, 1, 1, 1)), (a,List(1, 1, 1, 1)), (g,List(1, 1, 1)), (m,List(1, 1)), (t,List(1, 1, 1)), (b,List(1)), (h,List(1)), (n,List(1, 1)), (i,List(1, 1, 1, 1, 1, 1, 1)), (u,List(1)), (o,List(1)), (c,List(1)), (d,List(1, 1, 1, 1)), (p,List(1, 1, 1)), (v,List(1)), (:,List(1)), (e,List(1, 1, 1, 1, 1, 1, 1)), (k,List(1))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "val valToCombiner = (value:Int) => List(value)\n",
    "val mergeValuesFunc = (vals:List[Int], valToAppend:Int) => valToAppend :: vals\n",
    "val mergeCombinerFunc = (vals1:List[Int], vals2:List[Int]) => vals1 ::: vals2\n",
    "// now we define these as function variables\n",
    "val outputPartitions = 6\n",
    "KVcharacters\n",
    "  .combineByKey(\n",
    "    valToCombiner,\n",
    "    mergeValuesFunc,\n",
    "    mergeCombinerFunc,\n",
    "    outputPartitions)\n",
    "  .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(d,4), (p,3), (t,3), (b,1), (h,1), (n,2), (f,1), (v,1), (:,1), (r,2), (l,1), (s,4), (e,7), (a,4), (i,7), (k,1), (u,1), (o,1), (g,3), (m,2), (c,1)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "KVcharacters.foldByKey(0)(addFunc).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distinctChars = MapPartitionsRDD[54] at distinct at <console>:39\n",
       "charRDD = MapPartitionsRDD[55] at map at <console>:40\n",
       "charRDD2 = MapPartitionsRDD[56] at map at <console>:41\n",
       "charRDD3 = MapPartitionsRDD[57] at map at <console>:42\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[57] at map at <console>:42"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import scala.util.Random\n",
    "val distinctChars = words.flatMap(word => word.toLowerCase.toSeq).distinct\n",
    "val charRDD = distinctChars.map(c => (c, new Random().nextDouble()))\n",
    "val charRDD2 = distinctChars.map(c => (c, new Random().nextDouble()))\n",
    "val charRDD3 = distinctChars.map(c => (c, new Random().nextDouble()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(d,(CompactBuffer(0.8093996293802868),CompactBuffer(0.2576426530985749),CompactBuffer(0.07854134431538351))), (p,(CompactBuffer(0.9902233880206357),CompactBuffer(0.756885006665238),CompactBuffer(0.7720121808369217))), (t,(CompactBuffer(0.45972017740317606),CompactBuffer(0.5228545206331409),CompactBuffer(0.9020812714475281))), (b,(CompactBuffer(0.35869338711899634),CompactBuffer(0.6173175490934096),CompactBuffer(0.30091427866907694))), (h,(CompactBuffer(0.12715546650223375),CompactBuffer(0.8318093196789016),CompactBuffer(0.4857932280812478)))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charRDD.cogroup(charRDD2, charRDD3).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyedChars = MapPartitionsRDD[60] at map at <console>:42\n",
       "outputPartitions = 10\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "val keyedChars = distinctChars.map(c => (c, new Random().nextDouble()))\n",
    "val outputPartitions = 10\n",
    "KVcharacters.join(keyedChars).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KVcharacters.join(keyedChars, outputPartitions).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numRange = ParallelCollectionRDD[67] at parallelize at <console>:39\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(Spark,0), (The,1), (Definitive,2), (Guide,3), (:,4), (Big,5), (Data,6), (Processing,7), (Made,8), (Simple,9)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "val numRange = sc.parallelize(0 to 9, 2)\n",
    "words.zip(numRange).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "words.coalesce(1).getNumPartitions // 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[73] at repartition at <console>:37"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "words.repartition(10) // gives us 10 partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.getNumPartitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [InvoiceNo: string, StockCode: string ... 6 more fields]\n",
       "rdd = MapPartitionsRDD[87] at rdd at <console>:39\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[87] at rdd at <console>:39"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "val df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\")\n",
    "  .csv(path)\n",
    "val rdd = df.coalesce(10).rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17850\n",
      "17850\n",
      "17850\n",
      "17850\n",
      "17850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "keyedRDD = MapPartitionsRDD[89] at keyBy at <console>:42\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[89] at keyBy at <console>:42"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.HashPartitioner\n",
    "rdd.map(r => r(6)).take(5).foreach(println)\n",
    "val keyedRDD = rdd.keyBy(row => row(6).asInstanceOf[Int].toDouble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15100.0,[536374,21258,VICTORIAN SEWING BOX LARGE,32,12/1/2010 9:09,10.95,15100,United Kingdom]), (16250.0,[536388,21754,HOME BUILDING BLOCK WORD,3,12/1/2010 9:59,5.95,16250,United Kingdom]), (16250.0,[536388,21755,LOVE BUILDING BLOCK WORD,3,12/1/2010 9:59,5.95,16250,United Kingdom]), (16250.0,[536388,21523,DOORMAT FANCY FONT HOME SWEET HOME,2,12/1/2010 9:59,7.95,16250,United Kingdom]), (16250.0,[536388,21363,HOME SMALL WOOD LETTERS,3,12/1/2010 9:59,4.95,16250,United Kingdom]), (16250.0,[536388,21411,GINGHAM HEART  DOORSTOP RED,3,12/1/2010 9:59,4.25,16250,United Kingdom]), (16250.0,[536388,22318,FIVE HEART HANGING DECORATION,6,12/1/2010 9:59,2.95,16250,United Kingdom]), (16250.0,[536388,22464,HANGING METAL HEART LANTERN,12,12/1/2010 9:59,1.65,16250,United Kingdom]), (16250.0,[536388,22915,ASSORTED BOTTLE TOP  MAGNETS ,12,12/1/2010 9:59,0.42,16250,United Kingdom]), (16250.0,[536388,22922,FRIDGE MAGNETS US DINER ASSORTED,12,12/1/2010 9:59,0.85,16250,United Kingdom])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "keyedRDD.partitionBy(new HashPartitioner(10)).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class DomainPartitioner\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.Partitioner\n",
    "class DomainPartitioner extends Partitioner {\n",
    " def numPartitions = 3\n",
    " def getPartition(key: Any): Int = {\n",
    "   val customerId = key.asInstanceOf[Double].toInt\n",
    "   if (customerId == 17850.0 || customerId == 12583.0) {\n",
    "     return 0\n",
    "   } else {\n",
    "     return new java.util.Random().nextInt(2) + 1\n",
    "   }\n",
    " }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4304, 4300]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyedRDD\n",
    "  .partitionBy(new DomainPartitioner).map(_._1).glom().map(_.toSet.toSeq.length)\n",
    "  .take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class SomeClass\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "class SomeClass extends Serializable {\n",
    "  var someValue = 0\n",
    "  def setSomeValue(i:Int) = {\n",
    "    someValue = i\n",
    "    this\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[98] at map at <console>:34"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(1 to 10).map(num => new SomeClass().setSomeValue(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "\n",
    "//How to register classes for Kyro Serialization\n",
    "\n",
    "// val conf = new SparkConf().setMaster(...).setAppName(...)\n",
    "\n",
    "// conf.registerKryoClasses(Array(classOf[MyClass1], classOf[MyClass2]))\n",
    "\n",
    "// val sc = new SparkContext(conf)\n",
    "\n",
    "\n",
    "// COMMAND ----------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark - Scala",
   "language": "scala",
   "name": "spark_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
