{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ul>\n",
       "<li><a href=\"Some(http://gw02.itversity.com:4054)\" target=\"new_tab\">Spark UI: application_1540458187951_76700</a></li>\n",
       "</ul>"
      ],
      "text/plain": [
       "Spark application_1540458187951_76700: Some(http://gw02.itversity.com:4054)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "http://rm01.itversity.com:19288/proxy/application_1540458187951_76700"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.getConf.getAll.filter(_._2.contains(\"/proxy/\"))(0)._2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getType: (o: Any)String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getType(o: Any) = o.getClass.getCanonicalName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "os_name = Linux\n",
       "hdfs_home = /user/kranthidr\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/user/kranthidr"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val os_name = System.getProperty(\"os.name\")\n",
    "val hdfs_home = \"/user/\" + System.getenv(\"HOME\").split(\"/\")(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sales_path = /user/kranthidr/dataSets/spark-guide/retail-data/by-day/*.csv\n",
       "fakeIntDF_path = /user/kranthidr/dataSets/spark-guide/simple-ml-integers\n",
       "simpleDF_path = /user/kranthidr/dataSets/spark-guide/simple-ml\n",
       "scaleDF_path = /user/kranthidr/dataSets/spark-guide/simple-ml-scaling\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/user/kranthidr/dataSets/spark-guide/simple-ml-scaling"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sales_path = hdfs_home +\"/dataSets/spark-guide/retail-data/by-day/*.csv\"\n",
    "val fakeIntDF_path = hdfs_home +\"/dataSets/spark-guide/simple-ml-integers\"\n",
    "var simpleDF_path = hdfs_home +\"/dataSets/spark-guide/simple-ml\"\n",
    "val scaleDF_path = hdfs_home +\"/dataSets/spark-guide/simple-ml-scaling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sales = [InvoiceNo: string, StockCode: string ... 6 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[InvoiceNo: string, StockCode: string ... 6 more fields]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// in Scala\n",
    "val sales = spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .load(sales_path)\n",
    "  .coalesce(5)\n",
    "  .where(\"Description IS NOT NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fakeIntDF = [int1: int, int2: int ... 1 more field]\n",
       "simpleDF = [color: string, lab: string ... 2 more fields]\n",
       "scaleDF = [id: int, features: vector]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[id: int, features: vector]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fakeIntDF = spark.read.parquet(fakeIntDF_path)\n",
    "var simpleDF = spark.read.json(simpleDF_path)\n",
    "val scaleDF = spark.read.parquet(scaleDF_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   580538|    23084|  RABBIT NIGHT LIGHT|      48|2011-12-05 08:38:00|     1.79|   14075.0|United Kingdom|\n",
      "|   580538|    23077| DOUGHNUT LIP GLOSS |      20|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n",
      "|   580538|    22906|12 MESSAGE CARDS ...|      24|2011-12-05 08:38:00|     1.65|   14075.0|United Kingdom|\n",
      "|   580538|    21914|BLUE HARMONICA IN...|      24|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n",
      "|   580538|    22467|   GUMBALL COAT RACK|       6|2011-12-05 08:38:00|     2.55|   14075.0|United Kingdom|\n",
      "|   580538|    21544|SKULLS  WATER TRA...|      48|2011-12-05 08:38:00|     0.85|   14075.0|United Kingdom|\n",
      "|   580538|    23126|FELTCRAFT GIRL AM...|       8|2011-12-05 08:38:00|     4.95|   14075.0|United Kingdom|\n",
      "|   580538|    21833|CAMOUFLAGE LED TORCH|      24|2011-12-05 08:38:00|     1.69|   14075.0|United Kingdom|\n",
      "|   580539|    21479|WHITE SKULL HOT W...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "|   580539|   84030E|ENGLISH ROSE HOT ...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "|   580539|    23355|HOT WATER BOTTLE ...|       4|2011-12-05 08:39:00|     4.95|   18180.0|United Kingdom|\n",
      "|   580539|    22111|SCOTTIE DOG HOT W...|       3|2011-12-05 08:39:00|     4.95|   18180.0|United Kingdom|\n",
      "|   580539|    21115|ROSE CARAVAN DOOR...|       8|2011-12-05 08:39:00|     1.95|   18180.0|United Kingdom|\n",
      "|   580539|    21411|GINGHAM HEART  DO...|       8|2011-12-05 08:39:00|     1.95|   18180.0|United Kingdom|\n",
      "|   580539|    23235|STORAGE TIN VINTA...|      12|2011-12-05 08:39:00|     1.25|   18180.0|United Kingdom|\n",
      "|   580539|    23239|SET OF 4 KNICK KN...|       6|2011-12-05 08:39:00|     1.65|   18180.0|United Kingdom|\n",
      "|   580539|    22197|      POPCORN HOLDER|      36|2011-12-05 08:39:00|     0.85|   18180.0|United Kingdom|\n",
      "|   580539|    22693|GROW A FLYTRAP OR...|      24|2011-12-05 08:39:00|     1.25|   18180.0|United Kingdom|\n",
      "|   580539|    22372|AIRLINE BAG VINTA...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "|   580539|    22375|AIRLINE BAG VINTA...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "sales.cache()\n",
    "sales.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+------------------------------------------+\n",
      "|Description                        |tok_c0191bb3f9eb__output                  |\n",
      "+-----------------------------------+------------------------------------------+\n",
      "|RABBIT NIGHT LIGHT                 |[rabbit, night, light]                    |\n",
      "|DOUGHNUT LIP GLOSS                 |[doughnut, lip, gloss]                    |\n",
      "|12 MESSAGE CARDS WITH ENVELOPES    |[12, message, cards, with, envelopes]     |\n",
      "|BLUE HARMONICA IN BOX              |[blue, harmonica, in, box]                |\n",
      "|GUMBALL COAT RACK                  |[gumball, coat, rack]                     |\n",
      "|SKULLS  WATER TRANSFER TATTOOS     |[skulls, , water, transfer, tattoos]      |\n",
      "|FELTCRAFT GIRL AMELIE KIT          |[feltcraft, girl, amelie, kit]            |\n",
      "|CAMOUFLAGE LED TORCH               |[camouflage, led, torch]                  |\n",
      "|WHITE SKULL HOT WATER BOTTLE       |[white, skull, hot, water, bottle]        |\n",
      "|ENGLISH ROSE HOT WATER BOTTLE      |[english, rose, hot, water, bottle]       |\n",
      "|HOT WATER BOTTLE KEEP CALM         |[hot, water, bottle, keep, calm]          |\n",
      "|SCOTTIE DOG HOT WATER BOTTLE       |[scottie, dog, hot, water, bottle]        |\n",
      "|ROSE CARAVAN DOORSTOP              |[rose, caravan, doorstop]                 |\n",
      "|GINGHAM HEART  DOORSTOP RED        |[gingham, heart, , doorstop, red]         |\n",
      "|STORAGE TIN VINTAGE LEAF           |[storage, tin, vintage, leaf]             |\n",
      "|SET OF 4 KNICK KNACK TINS POPPIES  |[set, of, 4, knick, knack, tins, poppies] |\n",
      "|POPCORN HOLDER                     |[popcorn, holder]                         |\n",
      "|GROW A FLYTRAP OR SUNFLOWER IN TIN |[grow, a, flytrap, or, sunflower, in, tin]|\n",
      "|AIRLINE BAG VINTAGE WORLD CHAMPION |[airline, bag, vintage, world, champion]  |\n",
      "|AIRLINE BAG VINTAGE JET SET BROWN  |[airline, bag, vintage, jet, set, brown]  |\n",
      "+-----------------------------------+------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tkn = tok_c0191bb3f9eb\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tok_c0191bb3f9eb"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.Tokenizer\n",
    "val tkn = new Tokenizer().setInputCol(\"Description\")\n",
    "tkn.transform(sales.select(\"Description\")).show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+------------------------------------------------------------+\n",
      "|id |features      |stdScal_cc05555257c9__output                                |\n",
      "+---+--------------+------------------------------------------------------------+\n",
      "|0  |[1.0,0.1,-1.0]|[1.1952286093343936,0.02337622911060922,-0.5976143046671968]|\n",
      "|1  |[2.0,1.1,1.0] |[2.390457218668787,0.2571385202167014,0.5976143046671968]   |\n",
      "|0  |[1.0,0.1,-1.0]|[1.1952286093343936,0.02337622911060922,-0.5976143046671968]|\n",
      "|1  |[2.0,1.1,1.0] |[2.390457218668787,0.2571385202167014,0.5976143046671968]   |\n",
      "|1  |[3.0,10.1,3.0]|[3.5856858280031805,2.3609991401715313,1.7928429140015902]  |\n",
      "+---+--------------+------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ss = stdScal_cc05555257c9\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "stdScal_cc05555257c9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.StandardScaler\n",
    "val ss = new StandardScaler().setInputCol(\"features\")\n",
    "ss.fit(scaleDF).transform(scaleDF).show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+------------------+--------------------+-----+\n",
      "|color| lab|value1|            value2|            features|label|\n",
      "+-----+----+------+------------------+--------------------+-----+\n",
      "|green|good|     1|14.386294994851129|(10,[1,2,3,5,8],[...|  1.0|\n",
      "| blue| bad|     8|14.386294994851129|(10,[2,3,6,9],[8....|  0.0|\n",
      "| blue| bad|    12|14.386294994851129|(10,[2,3,6,9],[12...|  0.0|\n",
      "|green|good|    15| 38.97187133755819|(10,[1,2,3,5,8],[...|  1.0|\n",
      "|green|good|    12|14.386294994851129|(10,[1,2,3,5,8],[...|  1.0|\n",
      "|green| bad|    16|14.386294994851129|(10,[1,2,3,5,8],[...|  0.0|\n",
      "|  red|good|    35|14.386294994851129|(10,[0,2,3,4,7],[...|  1.0|\n",
      "|  red| bad|     1| 38.97187133755819|(10,[0,2,3,4,7],[...|  0.0|\n",
      "|  red| bad|     2|14.386294994851129|(10,[0,2,3,4,7],[...|  0.0|\n",
      "|  red| bad|    16|14.386294994851129|(10,[0,2,3,4,7],[...|  0.0|\n",
      "|  red|good|    45| 38.97187133755819|(10,[0,2,3,4,7],[...|  1.0|\n",
      "|green|good|     1|14.386294994851129|(10,[1,2,3,5,8],[...|  1.0|\n",
      "| blue| bad|     8|14.386294994851129|(10,[2,3,6,9],[8....|  0.0|\n",
      "| blue| bad|    12|14.386294994851129|(10,[2,3,6,9],[12...|  0.0|\n",
      "|green|good|    15| 38.97187133755819|(10,[1,2,3,5,8],[...|  1.0|\n",
      "|green|good|    12|14.386294994851129|(10,[1,2,3,5,8],[...|  1.0|\n",
      "|green| bad|    16|14.386294994851129|(10,[1,2,3,5,8],[...|  0.0|\n",
      "|  red|good|    35|14.386294994851129|(10,[0,2,3,4,7],[...|  1.0|\n",
      "|  red| bad|     1| 38.97187133755819|(10,[0,2,3,4,7],[...|  0.0|\n",
      "|  red| bad|     2|14.386294994851129|(10,[0,2,3,4,7],[...|  0.0|\n",
      "+-----+----+------+------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "supervised = RFormula(lab ~ . + color:value1 + color:value2) (uid=rFormula_d970cd13cc35)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RFormula(lab ~ . + color:value1 + color:value2) (uid=rFormula_d970cd13cc35)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.RFormula\n",
    "val supervised = new RFormula()\n",
    "  .setFormula(\"lab ~ . + color:value1 + color:value2\")\n",
    "supervised.fit(simpleDF).transform(simpleDF).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+----------+\n",
      "|sum(Quantity)|count(1)|CustomerID|\n",
      "+-------------+--------+----------+\n",
      "|          854|     117|   17884.0|\n",
      "|          541|      27|   14285.0|\n",
      "|         1140|      30|   13918.0|\n",
      "|         1542|      30|   13094.0|\n",
      "|          204|      76|   13533.0|\n",
      "|          109|      11|   13973.0|\n",
      "|          206|      23|   12493.0|\n",
      "|          491|     152|   13956.0|\n",
      "|           88|       7|   14473.0|\n",
      "|          290|      98|   13607.0|\n",
      "|           34|       6|   14768.0|\n",
      "|           97|      12|   16596.0|\n",
      "|          630|      72|   17633.0|\n",
      "|          244|      31|   16561.0|\n",
      "|          493|      64|   16629.0|\n",
      "|          159|      38|   17267.0|\n",
      "|          138|      18|   15776.0|\n",
      "|          150|      16|   14024.0|\n",
      "|          119|      62|   14452.0|\n",
      "|          440|     143|   16916.0|\n",
      "+-------------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "basicTransformation = sql_16f6206a0cd2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sql_16f6206a0cd2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.SQLTransformer\n",
    "\n",
    "val basicTransformation = new SQLTransformer()\n",
    "  .setStatement(\"\"\"\n",
    "    SELECT sum(Quantity), count(*), CustomerID\n",
    "    FROM __THIS__\n",
    "    GROUP BY CustomerID\n",
    "  \"\"\")\n",
    "\n",
    "basicTransformation.transform(sales).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+---------------------------------+\n",
      "|int1|int2|int3|vecAssembler_67b742cb1c97__output|\n",
      "+----+----+----+---------------------------------+\n",
      "|   1|   2|   3|                    [1.0,2.0,3.0]|\n",
      "|   4|   5|   6|                    [4.0,5.0,6.0]|\n",
      "|   7|   8|   9|                    [7.0,8.0,9.0]|\n",
      "+----+----+----+---------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "va = vecAssembler_67b742cb1c97\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vecAssembler_67b742cb1c97"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "val va = new VectorAssembler().setInputCols(Array(\"int1\", \"int2\", \"int3\"))\n",
    "va.transform(fakeIntDF).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contDF = [id: double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[id: double]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "val contDF = spark.range(20).selectExpr(\"cast(id as double)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------------------+\n",
      "|  id|bucketizer_5414679ff0ef__output|\n",
      "+----+-------------------------------+\n",
      "| 0.0|                            0.0|\n",
      "| 1.0|                            0.0|\n",
      "| 2.0|                            0.0|\n",
      "| 3.0|                            0.0|\n",
      "| 4.0|                            0.0|\n",
      "| 5.0|                            1.0|\n",
      "| 6.0|                            1.0|\n",
      "| 7.0|                            1.0|\n",
      "| 8.0|                            1.0|\n",
      "| 9.0|                            1.0|\n",
      "|10.0|                            2.0|\n",
      "|11.0|                            2.0|\n",
      "|12.0|                            2.0|\n",
      "|13.0|                            2.0|\n",
      "|14.0|                            2.0|\n",
      "|15.0|                            2.0|\n",
      "|16.0|                            2.0|\n",
      "|17.0|                            2.0|\n",
      "|18.0|                            2.0|\n",
      "|19.0|                            2.0|\n",
      "+----+-------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bucketBorders = Array(-1.0, 5.0, 10.0, 250.0, 600.0)\n",
       "bucketer = bucketizer_5414679ff0ef\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "bucketizer_5414679ff0ef"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.Bucketizer\n",
    "val bucketBorders = Array(-1.0, 5.0, 10.0, 250.0, 600.0)\n",
    "val bucketer = new Bucketizer().setSplits(bucketBorders).setInputCol(\"id\")\n",
    "bucketer.transform(contDF).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|  id|buckets|\n",
      "+----+-------+\n",
      "| 0.0|    0.0|\n",
      "| 1.0|    0.0|\n",
      "| 2.0|    0.0|\n",
      "| 3.0|    1.0|\n",
      "| 4.0|    1.0|\n",
      "| 5.0|    1.0|\n",
      "| 6.0|    1.0|\n",
      "| 7.0|    2.0|\n",
      "| 8.0|    2.0|\n",
      "| 9.0|    2.0|\n",
      "|10.0|    2.0|\n",
      "|11.0|    2.0|\n",
      "|12.0|    3.0|\n",
      "|13.0|    3.0|\n",
      "|14.0|    3.0|\n",
      "|15.0|    4.0|\n",
      "|16.0|    4.0|\n",
      "|17.0|    4.0|\n",
      "|18.0|    4.0|\n",
      "|19.0|    4.0|\n",
      "+----+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bucketer = quantileDiscretizer_a32c132e9617\n",
       "fittedBucketer = quantileDiscretizer_a32c132e9617\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "quantileDiscretizer_a32c132e9617"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.QuantileDiscretizer\n",
    "val bucketer = new QuantileDiscretizer().setNumBuckets(5).setInputCol(\"id\").setOutputCol(\"buckets\")\n",
    "val fittedBucketer = bucketer.fit(contDF)\n",
    "fittedBucketer.transform(contDF).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+----------------------------+\n",
      "| id|      features|stdScal_146c02cb8067__output|\n",
      "+---+--------------+----------------------------+\n",
      "|  0|[1.0,0.1,-1.0]|        [1.19522860933439...|\n",
      "|  1| [2.0,1.1,1.0]|        [2.39045721866878...|\n",
      "|  0|[1.0,0.1,-1.0]|        [1.19522860933439...|\n",
      "|  1| [2.0,1.1,1.0]|        [2.39045721866878...|\n",
      "|  1|[3.0,10.1,3.0]|        [3.58568582800318...|\n",
      "+---+--------------+----------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sScaler = stdScal_146c02cb8067\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "stdScal_146c02cb8067"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.StandardScaler\n",
    "val sScaler = new StandardScaler().setInputCol(\"features\")\n",
    "sScaler.fit(scaleDF).transform(scaleDF).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+-------------------------------+\n",
      "| id|      features|minMaxScal_fccd0a94edc4__output|\n",
      "+---+--------------+-------------------------------+\n",
      "|  0|[1.0,0.1,-1.0]|                  [5.0,5.0,5.0]|\n",
      "|  1| [2.0,1.1,1.0]|                  [7.5,5.5,7.5]|\n",
      "|  0|[1.0,0.1,-1.0]|                  [5.0,5.0,5.0]|\n",
      "|  1| [2.0,1.1,1.0]|                  [7.5,5.5,7.5]|\n",
      "|  1|[3.0,10.1,3.0]|               [10.0,10.0,10.0]|\n",
      "+---+--------------+-------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "minMax = minMaxScal_fccd0a94edc4\n",
       "fittedminMax = minMaxScal_fccd0a94edc4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "minMaxScal_fccd0a94edc4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.MinMaxScaler\n",
    "val minMax = new MinMaxScaler().setMin(5).setMax(10).setInputCol(\"features\")\n",
    "val fittedminMax = minMax.fit(scaleDF)\n",
    "fittedminMax.transform(scaleDF).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+-------------------------------+\n",
      "| id|      features|maxAbsScal_a0affd6200d8__output|\n",
      "+---+--------------+-------------------------------+\n",
      "|  0|[1.0,0.1,-1.0]|           [0.33333333333333...|\n",
      "|  1| [2.0,1.1,1.0]|           [0.66666666666666...|\n",
      "|  0|[1.0,0.1,-1.0]|           [0.33333333333333...|\n",
      "|  1| [2.0,1.1,1.0]|           [0.66666666666666...|\n",
      "|  1|[3.0,10.1,3.0]|                  [1.0,1.0,1.0]|\n",
      "+---+--------------+-------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "maScaler = maxAbsScal_a0affd6200d8\n",
       "fittedmaScaler = maxAbsScal_a0affd6200d8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "maxAbsScal_a0affd6200d8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.MaxAbsScaler\n",
    "val maScaler = new MaxAbsScaler().setInputCol(\"features\")\n",
    "val fittedmaScaler = maScaler.fit(scaleDF)\n",
    "fittedmaScaler.transform(scaleDF).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+-----------------------------+\n",
      "| id|      features|elemProd_f9ae05b007b5__output|\n",
      "+---+--------------+-----------------------------+\n",
      "|  0|[1.0,0.1,-1.0]|             [10.0,1.5,-20.0]|\n",
      "|  1| [2.0,1.1,1.0]|             [20.0,16.5,20.0]|\n",
      "|  0|[1.0,0.1,-1.0]|             [10.0,1.5,-20.0]|\n",
      "|  1| [2.0,1.1,1.0]|             [20.0,16.5,20.0]|\n",
      "|  1|[3.0,10.1,3.0]|            [30.0,151.5,60.0]|\n",
      "+---+--------------+-----------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "scaleUpVec = [10.0,15.0,20.0]\n",
       "scalingUp = elemProd_f9ae05b007b5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "elemProd_f9ae05b007b5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.ElementwiseProduct\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "val scaleUpVec = Vectors.dense(10.0, 15.0, 20.0)\n",
    "val scalingUp = new ElementwiseProduct()\n",
    "  .setScalingVec(scaleUpVec)\n",
    "  .setInputCol(\"features\")\n",
    "scalingUp.transform(scaleDF).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+-------------------------------+\n",
      "| id|      features|normalizer_a1d94d61198b__output|\n",
      "+---+--------------+-------------------------------+\n",
      "|  0|[1.0,0.1,-1.0]|           [0.47619047619047...|\n",
      "|  1| [2.0,1.1,1.0]|           [0.48780487804878...|\n",
      "|  0|[1.0,0.1,-1.0]|           [0.47619047619047...|\n",
      "|  1| [2.0,1.1,1.0]|           [0.48780487804878...|\n",
      "|  1|[3.0,10.1,3.0]|           [0.18633540372670...|\n",
      "+---+--------------+-------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "manhattanDistance = normalizer_a1d94d61198b\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "normalizer_a1d94d61198b"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.Normalizer\n",
    "val manhattanDistance = new Normalizer().setP(1).setInputCol(\"features\")\n",
    "manhattanDistance.transform(scaleDF).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+------------------+--------+\n",
      "|color| lab|value1|            value2|labelInd|\n",
      "+-----+----+------+------------------+--------+\n",
      "|green|good|     1|14.386294994851129|     1.0|\n",
      "| blue| bad|     8|14.386294994851129|     0.0|\n",
      "| blue| bad|    12|14.386294994851129|     0.0|\n",
      "|green|good|    15| 38.97187133755819|     1.0|\n",
      "|green|good|    12|14.386294994851129|     1.0|\n",
      "|green| bad|    16|14.386294994851129|     0.0|\n",
      "|  red|good|    35|14.386294994851129|     1.0|\n",
      "|  red| bad|     1| 38.97187133755819|     0.0|\n",
      "|  red| bad|     2|14.386294994851129|     0.0|\n",
      "|  red| bad|    16|14.386294994851129|     0.0|\n",
      "|  red|good|    45| 38.97187133755819|     1.0|\n",
      "|green|good|     1|14.386294994851129|     1.0|\n",
      "| blue| bad|     8|14.386294994851129|     0.0|\n",
      "| blue| bad|    12|14.386294994851129|     0.0|\n",
      "|green|good|    15| 38.97187133755819|     1.0|\n",
      "|green|good|    12|14.386294994851129|     1.0|\n",
      "|green| bad|    16|14.386294994851129|     0.0|\n",
      "|  red|good|    35|14.386294994851129|     1.0|\n",
      "|  red| bad|     1| 38.97187133755819|     0.0|\n",
      "|  red| bad|     2|14.386294994851129|     0.0|\n",
      "+-----+----+------+------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lblIndxr = strIdx_5471bf0041ad\n",
       "idxRes = [color: string, lab: string ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[color: string, lab: string ... 3 more fields]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.StringIndexer\n",
    "val lblIndxr = new StringIndexer().setInputCol(\"lab\").setOutputCol(\"labelInd\")\n",
    "val idxRes = lblIndxr.fit(simpleDF).transform(simpleDF)\n",
    "idxRes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+------------------+--------+\n",
      "|color| lab|value1|            value2|valueInd|\n",
      "+-----+----+------+------------------+--------+\n",
      "|green|good|     1|14.386294994851129|     2.0|\n",
      "| blue| bad|     8|14.386294994851129|     4.0|\n",
      "| blue| bad|    12|14.386294994851129|     0.0|\n",
      "|green|good|    15| 38.97187133755819|     5.0|\n",
      "|green|good|    12|14.386294994851129|     0.0|\n",
      "|green| bad|    16|14.386294994851129|     1.0|\n",
      "|  red|good|    35|14.386294994851129|     6.0|\n",
      "|  red| bad|     1| 38.97187133755819|     2.0|\n",
      "|  red| bad|     2|14.386294994851129|     7.0|\n",
      "|  red| bad|    16|14.386294994851129|     1.0|\n",
      "|  red|good|    45| 38.97187133755819|     3.0|\n",
      "|green|good|     1|14.386294994851129|     2.0|\n",
      "| blue| bad|     8|14.386294994851129|     4.0|\n",
      "| blue| bad|    12|14.386294994851129|     0.0|\n",
      "|green|good|    15| 38.97187133755819|     5.0|\n",
      "|green|good|    12|14.386294994851129|     0.0|\n",
      "|green| bad|    16|14.386294994851129|     1.0|\n",
      "|  red|good|    35|14.386294994851129|     6.0|\n",
      "|  red| bad|     1| 38.97187133755819|     2.0|\n",
      "|  red| bad|     2|14.386294994851129|     7.0|\n",
      "+-----+----+------+------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "valIndexer = strIdx_1025312f9da9\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "strIdx_1025312f9da9"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "val valIndexer = new StringIndexer()\n",
    "  .setInputCol(\"value1\")\n",
    "  .setOutputCol(\"valueInd\")\n",
    "\n",
    "valIndexer.fit(simpleDF).transform(simpleDF).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "strIdx_1025312f9da9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "valIndexer.setHandleInvalid(\"skip\")\n",
    "valIndexer.fit(simpleDF).setHandleInvalid(\"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+------------------+--------+-----------------------------+\n",
      "|color| lab|value1|            value2|labelInd|idxToStr_1e939612dd7f__output|\n",
      "+-----+----+------+------------------+--------+-----------------------------+\n",
      "|green|good|     1|14.386294994851129|     1.0|                         good|\n",
      "| blue| bad|     8|14.386294994851129|     0.0|                          bad|\n",
      "| blue| bad|    12|14.386294994851129|     0.0|                          bad|\n",
      "|green|good|    15| 38.97187133755819|     1.0|                         good|\n",
      "|green|good|    12|14.386294994851129|     1.0|                         good|\n",
      "|green| bad|    16|14.386294994851129|     0.0|                          bad|\n",
      "|  red|good|    35|14.386294994851129|     1.0|                         good|\n",
      "|  red| bad|     1| 38.97187133755819|     0.0|                          bad|\n",
      "|  red| bad|     2|14.386294994851129|     0.0|                          bad|\n",
      "|  red| bad|    16|14.386294994851129|     0.0|                          bad|\n",
      "|  red|good|    45| 38.97187133755819|     1.0|                         good|\n",
      "|green|good|     1|14.386294994851129|     1.0|                         good|\n",
      "| blue| bad|     8|14.386294994851129|     0.0|                          bad|\n",
      "| blue| bad|    12|14.386294994851129|     0.0|                          bad|\n",
      "|green|good|    15| 38.97187133755819|     1.0|                         good|\n",
      "|green|good|    12|14.386294994851129|     1.0|                         good|\n",
      "|green| bad|    16|14.386294994851129|     0.0|                          bad|\n",
      "|  red|good|    35|14.386294994851129|     1.0|                         good|\n",
      "|  red| bad|     1| 38.97187133755819|     0.0|                          bad|\n",
      "|  red| bad|     2|14.386294994851129|     0.0|                          bad|\n",
      "+-----+----+------+------------------+--------+-----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "labelReverse = idxToStr_1e939612dd7f\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "idxToStr_1e939612dd7f"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.IndexToString\n",
    "val labelReverse = new IndexToString().setInputCol(\"labelInd\")\n",
    "labelReverse.transform(idxRes).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+-------------+\n",
      "|     features|label|        idxed|\n",
      "+-------------+-----+-------------+\n",
      "|[1.0,2.0,3.0]|    1|[0.0,2.0,3.0]|\n",
      "|[2.0,5.0,6.0]|    2|[1.0,5.0,6.0]|\n",
      "|[1.0,8.0,9.0]|    3|[0.0,8.0,9.0]|\n",
      "+-------------+-----+-------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "idxIn = [features: vector, label: int]\n",
       "indxr = vecIdx_397a85d55f52\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vecIdx_397a85d55f52"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.VectorIndexer\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "val idxIn = spark.createDataFrame(Seq(\n",
    "  (Vectors.dense(1, 2, 3),1),\n",
    "  (Vectors.dense(2, 5, 6),2),\n",
    "  (Vectors.dense(1, 8, 9),3)\n",
    ")).toDF(\"features\", \"label\")\n",
    "val indxr = new VectorIndexer()\n",
    "  .setInputCol(\"features\")\n",
    "  .setOutputCol(\"idxed\")\n",
    "  .setMaxCategories(2)\n",
    "indxr.fit(idxIn).transform(idxIn).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+---------------------------+\n",
      "|color|colorInd|oneHot_48b48c72bfc3__output|\n",
      "+-----+--------+---------------------------+\n",
      "|green|     1.0|              (2,[1],[1.0])|\n",
      "| blue|     2.0|                  (2,[],[])|\n",
      "| blue|     2.0|                  (2,[],[])|\n",
      "|green|     1.0|              (2,[1],[1.0])|\n",
      "|green|     1.0|              (2,[1],[1.0])|\n",
      "|green|     1.0|              (2,[1],[1.0])|\n",
      "|  red|     0.0|              (2,[0],[1.0])|\n",
      "|  red|     0.0|              (2,[0],[1.0])|\n",
      "|  red|     0.0|              (2,[0],[1.0])|\n",
      "|  red|     0.0|              (2,[0],[1.0])|\n",
      "|  red|     0.0|              (2,[0],[1.0])|\n",
      "|green|     1.0|              (2,[1],[1.0])|\n",
      "| blue|     2.0|                  (2,[],[])|\n",
      "| blue|     2.0|                  (2,[],[])|\n",
      "|green|     1.0|              (2,[1],[1.0])|\n",
      "|green|     1.0|              (2,[1],[1.0])|\n",
      "|green|     1.0|              (2,[1],[1.0])|\n",
      "|  red|     0.0|              (2,[0],[1.0])|\n",
      "|  red|     0.0|              (2,[0],[1.0])|\n",
      "|  red|     0.0|              (2,[0],[1.0])|\n",
      "+-----+--------+---------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lblIndxr = strIdx_53e1ee5267ed\n",
       "colorLab = [color: string, colorInd: double]\n",
       "ohe = oneHot_48b48c72bfc3\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "warning: there was one deprecation warning; re-run with -deprecation for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "oneHot_48b48c72bfc3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.{StringIndexer, OneHotEncoder}\n",
    "val lblIndxr = new StringIndexer().setInputCol(\"color\").setOutputCol(\"colorInd\")\n",
    "val colorLab = lblIndxr.fit(simpleDF).transform(simpleDF.select(\"color\"))\n",
    "val ohe = new OneHotEncoder().setInputCol(\"colorInd\")\n",
    "ohe.transform(colorLab).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+------------------------------------------+\n",
      "|Description                        |DescOut                                   |\n",
      "+-----------------------------------+------------------------------------------+\n",
      "|RABBIT NIGHT LIGHT                 |[rabbit, night, light]                    |\n",
      "|DOUGHNUT LIP GLOSS                 |[doughnut, lip, gloss]                    |\n",
      "|12 MESSAGE CARDS WITH ENVELOPES    |[12, message, cards, with, envelopes]     |\n",
      "|BLUE HARMONICA IN BOX              |[blue, harmonica, in, box]                |\n",
      "|GUMBALL COAT RACK                  |[gumball, coat, rack]                     |\n",
      "|SKULLS  WATER TRANSFER TATTOOS     |[skulls, , water, transfer, tattoos]      |\n",
      "|FELTCRAFT GIRL AMELIE KIT          |[feltcraft, girl, amelie, kit]            |\n",
      "|CAMOUFLAGE LED TORCH               |[camouflage, led, torch]                  |\n",
      "|WHITE SKULL HOT WATER BOTTLE       |[white, skull, hot, water, bottle]        |\n",
      "|ENGLISH ROSE HOT WATER BOTTLE      |[english, rose, hot, water, bottle]       |\n",
      "|HOT WATER BOTTLE KEEP CALM         |[hot, water, bottle, keep, calm]          |\n",
      "|SCOTTIE DOG HOT WATER BOTTLE       |[scottie, dog, hot, water, bottle]        |\n",
      "|ROSE CARAVAN DOORSTOP              |[rose, caravan, doorstop]                 |\n",
      "|GINGHAM HEART  DOORSTOP RED        |[gingham, heart, , doorstop, red]         |\n",
      "|STORAGE TIN VINTAGE LEAF           |[storage, tin, vintage, leaf]             |\n",
      "|SET OF 4 KNICK KNACK TINS POPPIES  |[set, of, 4, knick, knack, tins, poppies] |\n",
      "|POPCORN HOLDER                     |[popcorn, holder]                         |\n",
      "|GROW A FLYTRAP OR SUNFLOWER IN TIN |[grow, a, flytrap, or, sunflower, in, tin]|\n",
      "|AIRLINE BAG VINTAGE WORLD CHAMPION |[airline, bag, vintage, world, champion]  |\n",
      "|AIRLINE BAG VINTAGE JET SET BROWN  |[airline, bag, vintage, jet, set, brown]  |\n",
      "+-----------------------------------+------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tkn = tok_742fb4b72cd1\n",
       "tokenized = [Description: string, DescOut: array<string>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Description: string, DescOut: array<string>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.Tokenizer\n",
    "val tkn = new Tokenizer().setInputCol(\"Description\").setOutputCol(\"DescOut\")\n",
    "val tokenized = tkn.transform(sales.select(\"Description\"))\n",
    "tokenized.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+------------------------------------------+\n",
      "|Description                        |DescOut                                   |\n",
      "+-----------------------------------+------------------------------------------+\n",
      "|RABBIT NIGHT LIGHT                 |[rabbit, night, light]                    |\n",
      "|DOUGHNUT LIP GLOSS                 |[doughnut, lip, gloss]                    |\n",
      "|12 MESSAGE CARDS WITH ENVELOPES    |[12, message, cards, with, envelopes]     |\n",
      "|BLUE HARMONICA IN BOX              |[blue, harmonica, in, box]                |\n",
      "|GUMBALL COAT RACK                  |[gumball, coat, rack]                     |\n",
      "|SKULLS  WATER TRANSFER TATTOOS     |[skulls, water, transfer, tattoos]        |\n",
      "|FELTCRAFT GIRL AMELIE KIT          |[feltcraft, girl, amelie, kit]            |\n",
      "|CAMOUFLAGE LED TORCH               |[camouflage, led, torch]                  |\n",
      "|WHITE SKULL HOT WATER BOTTLE       |[white, skull, hot, water, bottle]        |\n",
      "|ENGLISH ROSE HOT WATER BOTTLE      |[english, rose, hot, water, bottle]       |\n",
      "|HOT WATER BOTTLE KEEP CALM         |[hot, water, bottle, keep, calm]          |\n",
      "|SCOTTIE DOG HOT WATER BOTTLE       |[scottie, dog, hot, water, bottle]        |\n",
      "|ROSE CARAVAN DOORSTOP              |[rose, caravan, doorstop]                 |\n",
      "|GINGHAM HEART  DOORSTOP RED        |[gingham, heart, doorstop, red]           |\n",
      "|STORAGE TIN VINTAGE LEAF           |[storage, tin, vintage, leaf]             |\n",
      "|SET OF 4 KNICK KNACK TINS POPPIES  |[set, of, 4, knick, knack, tins, poppies] |\n",
      "|POPCORN HOLDER                     |[popcorn, holder]                         |\n",
      "|GROW A FLYTRAP OR SUNFLOWER IN TIN |[grow, a, flytrap, or, sunflower, in, tin]|\n",
      "|AIRLINE BAG VINTAGE WORLD CHAMPION |[airline, bag, vintage, world, champion]  |\n",
      "|AIRLINE BAG VINTAGE JET SET BROWN  |[airline, bag, vintage, jet, set, brown]  |\n",
      "+-----------------------------------+------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rt = regexTok_3af1d614c34c\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "regexTok_3af1d614c34c"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.RegexTokenizer\n",
    "val rt = new RegexTokenizer()\n",
    "  .setInputCol(\"Description\")\n",
    "  .setOutputCol(\"DescOut\")\n",
    "  .setPattern(\" \") // simplest expression\n",
    "  .setToLowercase(true)\n",
    "rt.transform(sales.select(\"Description\")).show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+------------------+\n",
      "|Description                        |DescOut           |\n",
      "+-----------------------------------+------------------+\n",
      "|RABBIT NIGHT LIGHT                 |[ ,  ]            |\n",
      "|DOUGHNUT LIP GLOSS                 |[ ,  ,  ]         |\n",
      "|12 MESSAGE CARDS WITH ENVELOPES    |[ ,  ,  ,  ]      |\n",
      "|BLUE HARMONICA IN BOX              |[ ,  ,  ,  ]      |\n",
      "|GUMBALL COAT RACK                  |[ ,  ]            |\n",
      "|SKULLS  WATER TRANSFER TATTOOS     |[ ,  ,  ,  ,  ]   |\n",
      "|FELTCRAFT GIRL AMELIE KIT          |[ ,  ,  ]         |\n",
      "|CAMOUFLAGE LED TORCH               |[ ,  ]            |\n",
      "|WHITE SKULL HOT WATER BOTTLE       |[ ,  ,  ,  ,  ]   |\n",
      "|ENGLISH ROSE HOT WATER BOTTLE      |[ ,  ,  ,  ]      |\n",
      "|HOT WATER BOTTLE KEEP CALM         |[ ,  ,  ,  ]      |\n",
      "|SCOTTIE DOG HOT WATER BOTTLE       |[ ,  ,  ,  ]      |\n",
      "|ROSE CARAVAN DOORSTOP              |[ ,  ]            |\n",
      "|GINGHAM HEART  DOORSTOP RED        |[ ,  ,  ,  ]      |\n",
      "|STORAGE TIN VINTAGE LEAF           |[ ,  ,  ]         |\n",
      "|SET OF 4 KNICK KNACK TINS POPPIES  |[ ,  ,  ,  ,  ,  ]|\n",
      "|POPCORN HOLDER                     |[ ]               |\n",
      "|GROW A FLYTRAP OR SUNFLOWER IN TIN |[ ,  ,  ,  ,  ,  ]|\n",
      "|AIRLINE BAG VINTAGE WORLD CHAMPION |[ ,  ,  ,  ,  ]   |\n",
      "|AIRLINE BAG VINTAGE JET SET BROWN  |[ ,  ,  ,  ,  ]   |\n",
      "+-----------------------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rt = regexTok_e8cc4d6e75e6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "regexTok_e8cc4d6e75e6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.RegexTokenizer\n",
    "val rt = new RegexTokenizer()\n",
    "  .setInputCol(\"Description\")\n",
    "  .setOutputCol(\"DescOut\")\n",
    "  .setPattern(\" \")\n",
    "  .setGaps(false)\n",
    "  .setToLowercase(true)\n",
    "rt.transform(sales.select(\"Description\")).show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------------------+\n",
      "|         Description|             DescOut|stopWords_5ce66be0f9f4__output|\n",
      "+--------------------+--------------------+------------------------------+\n",
      "|  RABBIT NIGHT LIGHT|[rabbit, night, l...|          [rabbit, night, l...|\n",
      "| DOUGHNUT LIP GLOSS |[doughnut, lip, g...|          [doughnut, lip, g...|\n",
      "|12 MESSAGE CARDS ...|[12, message, car...|          [12, message, car...|\n",
      "|BLUE HARMONICA IN...|[blue, harmonica,...|          [blue, harmonica,...|\n",
      "|   GUMBALL COAT RACK|[gumball, coat, r...|          [gumball, coat, r...|\n",
      "|SKULLS  WATER TRA...|[skulls, , water,...|          [skulls, , water,...|\n",
      "|FELTCRAFT GIRL AM...|[feltcraft, girl,...|          [feltcraft, girl,...|\n",
      "|CAMOUFLAGE LED TORCH|[camouflage, led,...|          [camouflage, led,...|\n",
      "|WHITE SKULL HOT W...|[white, skull, ho...|          [white, skull, ho...|\n",
      "|ENGLISH ROSE HOT ...|[english, rose, h...|          [english, rose, h...|\n",
      "|HOT WATER BOTTLE ...|[hot, water, bott...|          [hot, water, bott...|\n",
      "|SCOTTIE DOG HOT W...|[scottie, dog, ho...|          [scottie, dog, ho...|\n",
      "|ROSE CARAVAN DOOR...|[rose, caravan, d...|          [rose, caravan, d...|\n",
      "|GINGHAM HEART  DO...|[gingham, heart, ...|          [gingham, heart, ...|\n",
      "|STORAGE TIN VINTA...|[storage, tin, vi...|          [storage, tin, vi...|\n",
      "|SET OF 4 KNICK KN...|[set, of, 4, knic...|          [set, 4, knick, k...|\n",
      "|      POPCORN HOLDER|   [popcorn, holder]|             [popcorn, holder]|\n",
      "|GROW A FLYTRAP OR...|[grow, a, flytrap...|          [grow, flytrap, s...|\n",
      "|AIRLINE BAG VINTA...|[airline, bag, vi...|          [airline, bag, vi...|\n",
      "|AIRLINE BAG VINTA...|[airline, bag, vi...|          [airline, bag, vi...|\n",
      "+--------------------+--------------------+------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "englishStopWords = Array(i, me, my, myself, we, our, ours, ourselves, you, your, yours, yourself, yourselves, he, him, his, himself, she, her, hers, herself, it, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, ver...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[i, me, my, myself, we, our, ours, ourselves, you, your, yours, yourself, yourselves, he, him, his, himself, she, her, hers, herself, it, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, should, now, i'll, you'll, he'll, she'll, we'll, they'll, i'd, you'd, he'd, she'd, we'd, they'd, i'm, you're, he's, she's, it's, we're, they're, i've, we've, you've, they've, isn't, aren't, wasn't, weren't, haven't, hasn't, hadn't, don't, doesn't, didn't, won't, wouldn't, shan't, shouldn't, mustn't, can't, couldn't, cannot, could, here's, how's, let's, ought, that's, there's, what's, when's, where's, who's, why's, would]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.StopWordsRemover\n",
    "val englishStopWords = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "val stops = new StopWordsRemover()\n",
    "  .setStopWords(englishStopWords)\n",
    "  .setInputCol(\"DescOut\")\n",
    "stops.transform(tokenized).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+------------------------------------------+\n",
      "|DescOut                                   |ngram_d598d1ea91f8__output                |\n",
      "+------------------------------------------+------------------------------------------+\n",
      "|[rabbit, night, light]                    |[rabbit, night, light]                    |\n",
      "|[doughnut, lip, gloss]                    |[doughnut, lip, gloss]                    |\n",
      "|[12, message, cards, with, envelopes]     |[12, message, cards, with, envelopes]     |\n",
      "|[blue, harmonica, in, box]                |[blue, harmonica, in, box]                |\n",
      "|[gumball, coat, rack]                     |[gumball, coat, rack]                     |\n",
      "|[skulls, , water, transfer, tattoos]      |[skulls, , water, transfer, tattoos]      |\n",
      "|[feltcraft, girl, amelie, kit]            |[feltcraft, girl, amelie, kit]            |\n",
      "|[camouflage, led, torch]                  |[camouflage, led, torch]                  |\n",
      "|[white, skull, hot, water, bottle]        |[white, skull, hot, water, bottle]        |\n",
      "|[english, rose, hot, water, bottle]       |[english, rose, hot, water, bottle]       |\n",
      "|[hot, water, bottle, keep, calm]          |[hot, water, bottle, keep, calm]          |\n",
      "|[scottie, dog, hot, water, bottle]        |[scottie, dog, hot, water, bottle]        |\n",
      "|[rose, caravan, doorstop]                 |[rose, caravan, doorstop]                 |\n",
      "|[gingham, heart, , doorstop, red]         |[gingham, heart, , doorstop, red]         |\n",
      "|[storage, tin, vintage, leaf]             |[storage, tin, vintage, leaf]             |\n",
      "|[set, of, 4, knick, knack, tins, poppies] |[set, of, 4, knick, knack, tins, poppies] |\n",
      "|[popcorn, holder]                         |[popcorn, holder]                         |\n",
      "|[grow, a, flytrap, or, sunflower, in, tin]|[grow, a, flytrap, or, sunflower, in, tin]|\n",
      "|[airline, bag, vintage, world, champion]  |[airline, bag, vintage, world, champion]  |\n",
      "|[airline, bag, vintage, jet, set, brown]  |[airline, bag, vintage, jet, set, brown]  |\n",
      "+------------------------------------------+------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------------------------------------------+-------------------------------------------------------------------+\n",
      "|DescOut                                   |ngram_e23490dc63d7__output                                         |\n",
      "+------------------------------------------+-------------------------------------------------------------------+\n",
      "|[rabbit, night, light]                    |[rabbit night, night light]                                        |\n",
      "|[doughnut, lip, gloss]                    |[doughnut lip, lip gloss]                                          |\n",
      "|[12, message, cards, with, envelopes]     |[12 message, message cards, cards with, with envelopes]            |\n",
      "|[blue, harmonica, in, box]                |[blue harmonica, harmonica in, in box]                             |\n",
      "|[gumball, coat, rack]                     |[gumball coat, coat rack]                                          |\n",
      "|[skulls, , water, transfer, tattoos]      |[skulls ,  water, water transfer, transfer tattoos]                |\n",
      "|[feltcraft, girl, amelie, kit]            |[feltcraft girl, girl amelie, amelie kit]                          |\n",
      "|[camouflage, led, torch]                  |[camouflage led, led torch]                                        |\n",
      "|[white, skull, hot, water, bottle]        |[white skull, skull hot, hot water, water bottle]                  |\n",
      "|[english, rose, hot, water, bottle]       |[english rose, rose hot, hot water, water bottle]                  |\n",
      "|[hot, water, bottle, keep, calm]          |[hot water, water bottle, bottle keep, keep calm]                  |\n",
      "|[scottie, dog, hot, water, bottle]        |[scottie dog, dog hot, hot water, water bottle]                    |\n",
      "|[rose, caravan, doorstop]                 |[rose caravan, caravan doorstop]                                   |\n",
      "|[gingham, heart, , doorstop, red]         |[gingham heart, heart ,  doorstop, doorstop red]                   |\n",
      "|[storage, tin, vintage, leaf]             |[storage tin, tin vintage, vintage leaf]                           |\n",
      "|[set, of, 4, knick, knack, tins, poppies] |[set of, of 4, 4 knick, knick knack, knack tins, tins poppies]     |\n",
      "|[popcorn, holder]                         |[popcorn holder]                                                   |\n",
      "|[grow, a, flytrap, or, sunflower, in, tin]|[grow a, a flytrap, flytrap or, or sunflower, sunflower in, in tin]|\n",
      "|[airline, bag, vintage, world, champion]  |[airline bag, bag vintage, vintage world, world champion]          |\n",
      "|[airline, bag, vintage, jet, set, brown]  |[airline bag, bag vintage, vintage jet, jet set, set brown]        |\n",
      "+------------------------------------------+-------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "unigram = ngram_d598d1ea91f8\n",
       "bigram = ngram_e23490dc63d7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ngram_e23490dc63d7"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.NGram\n",
    "val unigram = new NGram().setInputCol(\"DescOut\").setN(1)\n",
    "val bigram = new NGram().setInputCol(\"DescOut\").setN(2)\n",
    "unigram.transform(tokenized.select(\"DescOut\")).show(false)\n",
    "bigram.transform(tokenized.select(\"DescOut\")).show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+------------------------------------------+---------------------------------------------------+\n",
      "|Description                        |DescOut                                   |countVec                                           |\n",
      "+-----------------------------------+------------------------------------------+---------------------------------------------------+\n",
      "|RABBIT NIGHT LIGHT                 |[rabbit, night, light]                    |(500,[149,185,212],[1.0,1.0,1.0])                  |\n",
      "|DOUGHNUT LIP GLOSS                 |[doughnut, lip, gloss]                    |(500,[462,463,492],[1.0,1.0,1.0])                  |\n",
      "|12 MESSAGE CARDS WITH ENVELOPES    |[12, message, cards, with, envelopes]     |(500,[35,41,166],[1.0,1.0,1.0])                    |\n",
      "|BLUE HARMONICA IN BOX              |[blue, harmonica, in, box]                |(500,[10,16,36,352],[1.0,1.0,1.0,1.0])             |\n",
      "|GUMBALL COAT RACK                  |[gumball, coat, rack]                     |(500,[228,281,408],[1.0,1.0,1.0])                  |\n",
      "|SKULLS  WATER TRANSFER TATTOOS     |[skulls, , water, transfer, tattoos]      |(500,[11,40,133],[1.0,1.0,1.0])                    |\n",
      "|FELTCRAFT GIRL AMELIE KIT          |[feltcraft, girl, amelie, kit]            |(500,[60,64,69],[1.0,1.0,1.0])                     |\n",
      "|CAMOUFLAGE LED TORCH               |[camouflage, led, torch]                  |(500,[263],[1.0])                                  |\n",
      "|WHITE SKULL HOT WATER BOTTLE       |[white, skull, hot, water, bottle]        |(500,[15,34,39,40,118],[1.0,1.0,1.0,1.0,1.0])      |\n",
      "|ENGLISH ROSE HOT WATER BOTTLE      |[english, rose, hot, water, bottle]       |(500,[34,39,40,46,169],[1.0,1.0,1.0,1.0,1.0])      |\n",
      "|HOT WATER BOTTLE KEEP CALM         |[hot, water, bottle, keep, calm]          |(500,[34,39,40,147,148],[1.0,1.0,1.0,1.0,1.0])     |\n",
      "|SCOTTIE DOG HOT WATER BOTTLE       |[scottie, dog, hot, water, bottle]        |(500,[34,39,40,146,386],[1.0,1.0,1.0,1.0,1.0])     |\n",
      "|ROSE CARAVAN DOORSTOP              |[rose, caravan, doorstop]                 |(500,[46,297],[1.0,1.0])                           |\n",
      "|GINGHAM HEART  DOORSTOP RED        |[gingham, heart, , doorstop, red]         |(500,[3,4,11,143,297],[1.0,1.0,1.0,1.0,1.0])       |\n",
      "|STORAGE TIN VINTAGE LEAF           |[storage, tin, vintage, leaf]             |(500,[6,45,109,162],[1.0,1.0,1.0,1.0])             |\n",
      "|SET OF 4 KNICK KNACK TINS POPPIES  |[set, of, 4, knick, knack, tins, poppies] |(500,[0,1,49,70,365,366],[1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|POPCORN HOLDER                     |[popcorn, holder]                         |(500,[21,296],[1.0,1.0])                           |\n",
      "|GROW A FLYTRAP OR SUNFLOWER IN TIN |[grow, a, flytrap, or, sunflower, in, tin]|(500,[36,45,378],[1.0,1.0,1.0])                    |\n",
      "|AIRLINE BAG VINTAGE WORLD CHAMPION |[airline, bag, vintage, world, champion]  |(500,[2,6,328],[1.0,1.0,1.0])                      |\n",
      "|AIRLINE BAG VINTAGE JET SET BROWN  |[airline, bag, vintage, jet, set, brown]  |(500,[0,2,6,328,405],[1.0,1.0,1.0,1.0,1.0])        |\n",
      "+-----------------------------------+------------------------------------------+---------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cv = cntVec_cc5b21a018ef\n",
       "fittedCV = cntVec_cc5b21a018ef\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "cntVec_cc5b21a018ef"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.CountVectorizer\n",
    "val cv = new CountVectorizer()\n",
    "  .setInputCol(\"DescOut\")\n",
    "  .setOutputCol(\"countVec\")\n",
    "  .setVocabSize(500)\n",
    "  .setMinTF(1)\n",
    "  .setMinDF(2)\n",
    "val fittedCV = cv.fit(tokenized)\n",
    "fittedCV.transform(tokenized).show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+\n",
      "|DescOut                               |\n",
      "+--------------------------------------+\n",
      "|[wooden, advent, calendar, red]       |\n",
      "|[wrap, red, vintage, doily]           |\n",
      "|[alarm, clock, bakelike, red]         |\n",
      "|[alarm, clock, bakelike, red]         |\n",
      "|[red, diner, wall, clock]             |\n",
      "|[red, apples, chopping, board]        |\n",
      "|[red, kitchen, scales]                |\n",
      "|[airline, bag, vintage, jet, set, red]|\n",
      "|[red, retrospot, charlotte, bag]      |\n",
      "|[pin, cushion, babushka, red]         |\n",
      "+--------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tfIdfIn = [DescOut: array<string>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[DescOut: array<string>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "val tfIdfIn = tokenized\n",
    "  .where(\"array_contains(DescOut, 'red')\")\n",
    "  .select(\"DescOut\")\n",
    "  .limit(10)\n",
    "tfIdfIn.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf = hashingTF_beae0d33235e\n",
       "idf = idf_b0d3a2391ddf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "idf_b0d3a2391ddf"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.{HashingTF, IDF}\n",
    "val tf = new HashingTF()\n",
    "  .setInputCol(\"DescOut\")\n",
    "  .setOutputCol(\"TFOut\")\n",
    "  .setNumFeatures(10000)\n",
    "val idf = new IDF()\n",
    "  .setInputCol(\"TFOut\")\n",
    "  .setOutputCol(\"IDFOut\")\n",
    "  .setMinDocFreq(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+--------------------------------------------------------+--------------------------------------------------------------+\n",
      "|DescOut                                |TFOut                                                   |IDFOut                                                        |\n",
      "+---------------------------------------+--------------------------------------------------------+--------------------------------------------------------------+\n",
      "|[red, hanging, heart, t-light, holder] |(10000,[538,3348,4291,6152,9160],[1.0,1.0,1.0,1.0,1.0]) |(10000,[538,3348,4291,6152,9160],[0.0,0.0,0.0,0.0,0.0])       |\n",
      "|[set/10, red, polkadot, party, candles]|(10000,[3686,4291,5092,9195,9369],[1.0,1.0,1.0,1.0,1.0])|(10000,[3686,4291,5092,9195,9369],[0.0,0.0,0.0,0.0,0.0])      |\n",
      "|[jumbo, bag, red, retrospot]           |(10000,[155,1174,2591,4291],[1.0,1.0,1.0,1.0])          |(10000,[155,1174,2591,4291],[1.2992829841302609,0.0,0.0,0.0]) |\n",
      "|[vintage, red, kitchen, cabinet]       |(10000,[3067,3461,4291,8150],[1.0,1.0,1.0,1.0])         |(10000,[3067,3461,4291,8150],[0.0,0.0,0.0,1.2992829841302609])|\n",
      "|[frying, pan, red, retrospot]          |(10000,[2591,4291,6677,9365],[1.0,1.0,1.0,1.0])         |(10000,[2591,4291,6677,9365],[0.0,0.0,0.0,0.0])               |\n",
      "|[milk, pan, red, retrospot]            |(10000,[2591,4291,5949,6677],[1.0,1.0,1.0,1.0])         |(10000,[2591,4291,5949,6677],[0.0,0.0,0.0,0.0])               |\n",
      "|[mini, ladle, love, heart, red]        |(10000,[547,4291,6240,7104,9160],[1.0,1.0,1.0,1.0,1.0]) |(10000,[547,4291,6240,7104,9160],[0.0,0.0,0.0,0.0,0.0])       |\n",
      "|[retrospot, red, washing, up, gloves]  |(10000,[128,2263,2591,4291,9538],[1.0,1.0,1.0,1.0,1.0]) |(10000,[128,2263,2591,4291,9538],[0.0,0.0,0.0,0.0,0.0])       |\n",
      "|[red, diner, wall, clock]              |(10000,[4291,6404,8873,9668],[1.0,1.0,1.0,1.0])         |(10000,[4291,6404,8873,9668],[0.0,0.0,0.0,1.0116009116784799])|\n",
      "|[doormat, red, retrospot]              |(10000,[2591,4291,7733],[1.0,1.0,1.0])                  |(10000,[2591,4291,7733],[0.0,0.0,0.0])                        |\n",
      "+---------------------------------------+--------------------------------------------------------+--------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "idf.fit(tf.transform(tfIdfIn)).transform(tf.transform(tfIdfIn)).show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "documentDF = [text: array<string>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[text: array<string>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.Word2Vec\n",
    "import org.apache.spark.ml.linalg.Vector\n",
    "import org.apache.spark.sql.Row\n",
    "// Input data: Each row is a bag of words from a sentence or document.\n",
    "val documentDF = spark.createDataFrame(Seq(\n",
    "  \"Hi I heard about Spark\".split(\" \"),\n",
    "  \"I wish Java could use case classes\".split(\" \"),\n",
    "  \"Logistic regression models are neat\".split(\" \")\n",
    ").map(Tuple1.apply)).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word2Vec = w2v_907d03a2d51b\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "w2v_907d03a2d51b"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Learn a mapping from words to Vectors.\n",
    "val word2Vec = new Word2Vec()\n",
    "  .setInputCol(\"text\")\n",
    "  .setOutputCol(\"result\")\n",
    "  .setVectorSize(3)\n",
    "  .setMinCount(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model = w2v_907d03a2d51b\n",
       "result = [text: array<string>, result: vector]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[text: array<string>, result: vector]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = word2Vec.fit(documentDF)\n",
    "val result = model.transform(documentDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: [Hi, I, heard, about, Spark] => \n",
      "Vector: [-0.008301425352692604,0.020340083539485933,0.03263562321662903]\n",
      "\n",
      "Text: [I, wish, Java, could, use, case, classes] => \n",
      "Vector: [0.04305013721542699,0.035192844324878285,0.02361524730388607]\n",
      "\n",
      "Text: [Logistic, regression, models, are, neat] => \n",
      "Vector: [0.0386008620262146,-0.032484661601483826,-0.015685077011585235]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.collect().foreach { case Row(text: Seq[_], features: Vector) =>\n",
    "  println(s\"Text: [${text.mkString(\", \")}] => \\nVector: $features\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+------------------------------------------+\n",
      "|id |features      |pca_6948161da487__output                  |\n",
      "+---+--------------+------------------------------------------+\n",
      "|0  |[1.0,0.1,-1.0]|[0.07137194992484153,-0.45266548881478463]|\n",
      "|1  |[2.0,1.1,1.0] |[-1.6804946984073725,1.2593401322219144]  |\n",
      "|0  |[1.0,0.1,-1.0]|[0.07137194992484153,-0.45266548881478463]|\n",
      "|1  |[2.0,1.1,1.0] |[-1.6804946984073725,1.2593401322219144]  |\n",
      "|1  |[3.0,10.1,3.0]|[-10.872398139848944,0.030962697060149758]|\n",
      "+---+--------------+------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pca = pca_6948161da487\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pca_6948161da487"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.PCA\n",
    "val pca = new PCA().setInputCol(\"features\").setK(2)\n",
    "pca.fit(scaleDF).transform(scaleDF).show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+-----------------------------------------------------------------------------------+\n",
      "|id |features      |poly_d59f6f8e9e1b__output                                                          |\n",
      "+---+--------------+-----------------------------------------------------------------------------------+\n",
      "|0  |[1.0,0.1,-1.0]|[1.0,1.0,0.1,0.1,0.010000000000000002,-1.0,-1.0,-0.1,1.0]                          |\n",
      "|1  |[2.0,1.1,1.0] |[2.0,4.0,1.1,2.2,1.2100000000000002,1.0,2.0,1.1,1.0]                               |\n",
      "|0  |[1.0,0.1,-1.0]|[1.0,1.0,0.1,0.1,0.010000000000000002,-1.0,-1.0,-0.1,1.0]                          |\n",
      "|1  |[2.0,1.1,1.0] |[2.0,4.0,1.1,2.2,1.2100000000000002,1.0,2.0,1.1,1.0]                               |\n",
      "|1  |[3.0,10.1,3.0]|[3.0,9.0,10.1,30.299999999999997,102.00999999999999,3.0,9.0,30.299999999999997,9.0]|\n",
      "+---+--------------+-----------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pe = poly_d59f6f8e9e1b\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "poly_d59f6f8e9e1b"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.PolynomialExpansion\n",
    "val pe = new PolynomialExpansion().setInputCol(\"features\").setDegree(2)\n",
    "pe.transform(scaleDF).show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   580538|    23084|  RABBIT NIGHT LIGHT|      48|2011-12-05 08:38:00|     1.79|   14075.0|United Kingdom|\n",
      "|   580538|    23077| DOUGHNUT LIP GLOSS |      20|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n",
      "|   580538|    22906|12 MESSAGE CARDS ...|      24|2011-12-05 08:38:00|     1.65|   14075.0|United Kingdom|\n",
      "|   580538|    21914|BLUE HARMONICA IN...|      24|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n",
      "|   580538|    22467|   GUMBALL COAT RACK|       6|2011-12-05 08:38:00|     2.55|   14075.0|United Kingdom|\n",
      "|   580538|    21544|SKULLS  WATER TRA...|      48|2011-12-05 08:38:00|     0.85|   14075.0|United Kingdom|\n",
      "|   580538|    23126|FELTCRAFT GIRL AM...|       8|2011-12-05 08:38:00|     4.95|   14075.0|United Kingdom|\n",
      "|   580538|    21833|CAMOUFLAGE LED TORCH|      24|2011-12-05 08:38:00|     1.69|   14075.0|United Kingdom|\n",
      "|   580539|    21479|WHITE SKULL HOT W...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "|   580539|   84030E|ENGLISH ROSE HOT ...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "|   580539|    23355|HOT WATER BOTTLE ...|       4|2011-12-05 08:39:00|     4.95|   18180.0|United Kingdom|\n",
      "|   580539|    22111|SCOTTIE DOG HOT W...|       3|2011-12-05 08:39:00|     4.95|   18180.0|United Kingdom|\n",
      "|   580539|    21115|ROSE CARAVAN DOOR...|       8|2011-12-05 08:39:00|     1.95|   18180.0|United Kingdom|\n",
      "|   580539|    21411|GINGHAM HEART  DO...|       8|2011-12-05 08:39:00|     1.95|   18180.0|United Kingdom|\n",
      "|   580539|    23235|STORAGE TIN VINTA...|      12|2011-12-05 08:39:00|     1.25|   18180.0|United Kingdom|\n",
      "|   580539|    23239|SET OF 4 KNICK KN...|       6|2011-12-05 08:39:00|     1.65|   18180.0|United Kingdom|\n",
      "|   580539|    22197|      POPCORN HOLDER|      36|2011-12-05 08:39:00|     0.85|   18180.0|United Kingdom|\n",
      "|   580539|    22693|GROW A FLYTRAP OR...|      24|2011-12-05 08:39:00|     1.25|   18180.0|United Kingdom|\n",
      "|   580539|    22372|AIRLINE BAG VINTA...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "|   580539|    22375|AIRLINE BAG VINTA...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "// import org.apache.spark.ml.feature.{ChiSqSelector, Tokenizer}\n",
    "// val tkn = new Tokenizer().setInputCol(\"Description\").setOutputCol(\"DescOut\")\n",
    "\n",
    "// val tokenized = tkn\n",
    "//   .transform(sales.select(\"Description\", \"CustomerID\"))\n",
    "//   .where(\"CustomerID IS NOT NULL\")\n",
    "\n",
    "// tokenized.show()\n",
    "//val prechi = fittedCV.transform(tokenized)\n",
    "\n",
    "//// val prechi = fittedCV.transform(tokenized).join(sales.select(\"Description\", \"CustomerID\"),\"Description\")\n",
    "//// .where(\"CustomerID IS NOT NULL\")\n",
    "\n",
    "// prechi.show()\n",
    "\n",
    "// val chisq = new ChiSqSelector().setFeaturesCol(\"countVec\").setLabelCol(\"CustomerID\").setNumTopFeatures(2)\n",
    "\n",
    "// chisq.fit(prechi).transform(prechi)\n",
    "//   .drop(\"CustomerID\", \"Description\", \"DescOut\").show()\n",
    "\n",
    "//CHECK THIS TAKING TOO LONG ...AND CHECK CODE for JOIN which I inserted!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fittedPCA = pca_6948161da487\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pca_6948161da487"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "val fittedPCA = pca.fit(scaleDF)\n",
    "fittedPCA.write.overwrite().save(\"/tmp/fittedPCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+------------------------+\n",
      "| id|      features|pca_6948161da487__output|\n",
      "+---+--------------+------------------------+\n",
      "|  0|[1.0,0.1,-1.0]|    [0.07137194992484...|\n",
      "|  1| [2.0,1.1,1.0]|    [-1.6804946984073...|\n",
      "|  0|[1.0,0.1,-1.0]|    [0.07137194992484...|\n",
      "|  1| [2.0,1.1,1.0]|    [-1.6804946984073...|\n",
      "|  1|[3.0,10.1,3.0]|    [-10.872398139848...|\n",
      "+---+--------------+------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "loadedPCA = pca_6948161da487\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pca_6948161da487"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "// in Scala\n",
    "import org.apache.spark.ml.feature.PCAModel\n",
    "val loadedPCA = PCAModel.load(\"/tmp/fittedPCA\")\n",
    "loadedPCA.transform(scaleDF).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class MyTokenizer\n",
       "defined object MyTokenizer\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.apache.spark.ml.UnaryTransformer\n",
    "import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n",
    "import org.apache.spark.sql.types.{ArrayType, StringType, DataType}\n",
    "import org.apache.spark.ml.param.{IntParam, ParamValidators}\n",
    "\n",
    "class MyTokenizer(override val uid: String) \n",
    "    extends UnaryTransformer[String, Seq[String], MyTokenizer] \n",
    "    with DefaultParamsWritable {\n",
    "\n",
    "  def this() = this(Identifiable.randomUID(\"myTokenizer\"))\n",
    "\n",
    "  val maxWords: IntParam = new IntParam(this, \n",
    "                                        \"maxWords\",\n",
    "                                        \"The max number of words to return.\",\n",
    "                                        ParamValidators.gtEq(0))\n",
    "\n",
    "  def setMaxWords(value: Int): this.type = set(maxWords, value)\n",
    "\n",
    "  def getMaxWords: Integer = $(maxWords)\n",
    "\n",
    "  override protected def createTransformFunc: String => Seq[String] = (\n",
    "    inputString: String) => {\n",
    "      inputString.split(\"\\\\s\").take($(maxWords))\n",
    "  }\n",
    "\n",
    "  override protected def validateInputType(inputType: DataType): Unit = {\n",
    "    require(\n",
    "      inputType == StringType, s\"Bad input type: $inputType. Requires String.\")\n",
    "  }\n",
    "\n",
    "  override protected def outputDataType: DataType = new ArrayType(StringType,\n",
    "    true)\n",
    "}\n",
    "// this will allow you to read it back in by using this object.\n",
    "object MyTokenizer extends DefaultParamsReadable[MyTokenizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+--------------------------------+\n",
      "|someCol                           |myTokenizer_82829566c98d__output|\n",
      "+----------------------------------+--------------------------------+\n",
      "|hello world. This text won't show.|[hello, world.]                 |\n",
      "+----------------------------------+--------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "myT = myTokenizer_82829566c98d\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "myTokenizer_82829566c98d"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// COMMAND ----------\n",
    "\n",
    "val myT = new MyTokenizer().setInputCol(\"someCol\").setMaxWords(2)\n",
    "\n",
    "myT.transform(Seq(\"hello world. This text won't show.\").toDF(\"someCol\")).show(3, false)\n",
    "\n",
    "\n",
    "// COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+--------------------------------+\n",
      "|someCol                           |myTokenizer_72ed2fed1f48__output|\n",
      "+----------------------------------+--------------------------------+\n",
      "|hello world. This text won't show.|[hello, world., This]           |\n",
      "+----------------------------------+--------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "myT1 = myTokenizer_72ed2fed1f48\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "myTokenizer_72ed2fed1f48"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val myT1 = new MyTokenizer().setInputCol(\"someCol\").setMaxWords(3)\n",
    "\n",
    "myT1.transform(Seq(\"hello world. This text won't show.\").toDF(\"someCol\")).show(3, false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark - Scala",
   "language": "scala",
   "name": "spark_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
