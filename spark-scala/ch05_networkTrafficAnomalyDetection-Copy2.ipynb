{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ul>\n",
       "<li><a href=\"Some(http://gw02.itversity.com:4048)\" target=\"new_tab\">Spark UI: application_1533622723243_5217</a></li>\n",
       "</ul>"
      ],
      "text/plain": [
       "Spark application_1533622723243_5217: Some(http://gw02.itversity.com:4048)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types will be printed.\n"
     ]
    }
   ],
   "source": [
    "%showtypes on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// val spark2 = spark\n",
    "// import spark2.implicits._\n",
    "// import org.apache.spark.sql.SQLImplicits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.DataFrame\n",
    "import util.Random\n",
    "\n",
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.clustering.{KMeans, KMeansModel}\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.ml.feature.StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dataWithoutHeader = [_c0: int, _c1: string ... 40 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[_c0: int, _c1: string ... 40 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataWithoutHeader = spark\n",
    "                        .read\n",
    "                        .option(\"inferSchema\",true)\n",
    "                        .option(\"header\",false)\n",
    "                        .csv(\"hdfs:///user/kranthidr/dataSets/KDDCup1999DataSet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class org.apache.spark.sql.Dataset\n"
     ]
    }
   ],
   "source": [
    "println(dataWithoutHeader.getClass())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: integer (nullable = true)\n",
      " |-- _c5: integer (nullable = true)\n",
      " |-- _c6: integer (nullable = true)\n",
      " |-- _c7: integer (nullable = true)\n",
      " |-- _c8: integer (nullable = true)\n",
      " |-- _c9: integer (nullable = true)\n",
      " |-- _c10: integer (nullable = true)\n",
      " |-- _c11: integer (nullable = true)\n",
      " |-- _c12: integer (nullable = true)\n",
      " |-- _c13: integer (nullable = true)\n",
      " |-- _c14: integer (nullable = true)\n",
      " |-- _c15: integer (nullable = true)\n",
      " |-- _c16: integer (nullable = true)\n",
      " |-- _c17: integer (nullable = true)\n",
      " |-- _c18: integer (nullable = true)\n",
      " |-- _c19: integer (nullable = true)\n",
      " |-- _c20: integer (nullable = true)\n",
      " |-- _c21: integer (nullable = true)\n",
      " |-- _c22: integer (nullable = true)\n",
      " |-- _c23: integer (nullable = true)\n",
      " |-- _c24: double (nullable = true)\n",
      " |-- _c25: double (nullable = true)\n",
      " |-- _c26: double (nullable = true)\n",
      " |-- _c27: double (nullable = true)\n",
      " |-- _c28: double (nullable = true)\n",
      " |-- _c29: double (nullable = true)\n",
      " |-- _c30: double (nullable = true)\n",
      " |-- _c31: integer (nullable = true)\n",
      " |-- _c32: integer (nullable = true)\n",
      " |-- _c33: double (nullable = true)\n",
      " |-- _c34: double (nullable = true)\n",
      " |-- _c35: double (nullable = true)\n",
      " |-- _c36: double (nullable = true)\n",
      " |-- _c37: double (nullable = true)\n",
      " |-- _c38: double (nullable = true)\n",
      " |-- _c39: double (nullable = true)\n",
      " |-- _c40: double (nullable = true)\n",
      " |-- _c41: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataWithoutHeader.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><td>0</td><td>tcp</td><td>http</td><td>SF</td><td>215</td><td>45076</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>normal.</td></tr>\n",
       "<tr><td>0</td><td>tcp</td><td>http</td><td>SF</td><td>162</td><td>4528</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>2</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1</td><td>1</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>normal.</td></tr>\n",
       "<tr><td>0</td><td>tcp</td><td>http</td><td>SF</td><td>236</td><td>1228</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>2</td><td>2</td><td>1.0</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>normal.</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "+-----+-----+------+-----+-----+-------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+---------+\n",
       "| 0   | tcp | http | SF  | 215 | 45076 | 0   | 0   | 0   | 0   | 0   | 1   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 1   | 1   | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0   | 0   | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | normal. |\n",
       "| 0   | tcp | http | SF  | 162 | 4528  | 0   | 0   | 0   | 0   | 0   | 1   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 2   | 2   | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1   | 1   | 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | normal. |\n",
       "| 0   | tcp | http | SF  | 236 | 1228  | 0   | 0   | 0   | 0   | 0   | 1   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 1   | 1   | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 2   | 2   | 1.0 | 0.0 | 0.5 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | normal. |\n",
       "+-----+-----+------+-----+-----+-------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+---------+"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataWithoutHeader.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataDF = [duration: int, protocol_type: string ... 40 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[duration: int, protocol_type: string ... 40 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataDF = dataWithoutHeader.toDF(\n",
    "        \"duration\", \"protocol_type\", \"service\", \"flag\",\n",
    "        \"src_bytes\", \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\",\n",
    "        \"hot\", \"num_failed_logins\", \"logged_in\", \"num_compromised\",\n",
    "        \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\",\n",
    "        \"num_shells\", \"num_access_files\", \"num_outbound_cmds\",\n",
    "        \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\",\n",
    "        \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\",\n",
    "        \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\",\n",
    "        \"dst_host_count\", \"dst_host_srv_count\",\n",
    "        \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\",\n",
    "        \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\",\n",
    "        \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
    "        \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\",\n",
    "        \"label\").cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- protocol_type: string (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- src_bytes: integer (nullable = true)\n",
      " |-- dst_bytes: integer (nullable = true)\n",
      " |-- land: integer (nullable = true)\n",
      " |-- wrong_fragment: integer (nullable = true)\n",
      " |-- urgent: integer (nullable = true)\n",
      " |-- hot: integer (nullable = true)\n",
      " |-- num_failed_logins: integer (nullable = true)\n",
      " |-- logged_in: integer (nullable = true)\n",
      " |-- num_compromised: integer (nullable = true)\n",
      " |-- root_shell: integer (nullable = true)\n",
      " |-- su_attempted: integer (nullable = true)\n",
      " |-- num_root: integer (nullable = true)\n",
      " |-- num_file_creations: integer (nullable = true)\n",
      " |-- num_shells: integer (nullable = true)\n",
      " |-- num_access_files: integer (nullable = true)\n",
      " |-- num_outbound_cmds: integer (nullable = true)\n",
      " |-- is_host_login: integer (nullable = true)\n",
      " |-- is_guest_login: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- srv_count: integer (nullable = true)\n",
      " |-- serror_rate: double (nullable = true)\n",
      " |-- srv_serror_rate: double (nullable = true)\n",
      " |-- rerror_rate: double (nullable = true)\n",
      " |-- srv_rerror_rate: double (nullable = true)\n",
      " |-- same_srv_rate: double (nullable = true)\n",
      " |-- diff_srv_rate: double (nullable = true)\n",
      " |-- srv_diff_host_rate: double (nullable = true)\n",
      " |-- dst_host_count: integer (nullable = true)\n",
      " |-- dst_host_srv_count: integer (nullable = true)\n",
      " |-- dst_host_same_srv_rate: double (nullable = true)\n",
      " |-- dst_host_diff_srv_rate: double (nullable = true)\n",
      " |-- dst_host_same_src_port_rate: double (nullable = true)\n",
      " |-- dst_host_srv_diff_host_rate: double (nullable = true)\n",
      " |-- dst_host_serror_rate: double (nullable = true)\n",
      " |-- dst_host_srv_serror_rate: double (nullable = true)\n",
      " |-- dst_host_rerror_rate: double (nullable = true)\n",
      " |-- dst_host_srv_rerror_rate: double (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numericOnly = [duration: int, src_bytes: int ... 37 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[duration: int, src_bytes: int ... 37 more fields]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val numericOnly = dataDF.drop(\"protocol_type\", \"service\", \"flag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class org.apache.spark.sql.Dataset\n",
      "class org.apache.spark.sql.Dataset\n"
     ]
    }
   ],
   "source": [
    "println(numericOnly.getClass())\n",
    "println(dataDF.getClass())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clusterScore1: (data: org.apache.spark.sql.DataFrame, k: Int)Double\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clusterScore1(data: DataFrame, k: Int) = {\n",
    "    \n",
    "    val assembler = new VectorAssembler().setInputCols(data.columns.filter(_!=\"label\")).setOutputCol(\"featureVector\")\n",
    "    \n",
    "    val kmeans = new KMeans().\n",
    "        setSeed(Random.nextLong()).\n",
    "        setK(k).\n",
    "        setMaxIter(40).\n",
    "        setTol(1.0e-5).\n",
    "        setPredictionCol(\"cluster\").\n",
    "        setFeaturesCol(\"featureVector\")\n",
    "    \n",
    "    val pipeline = new Pipeline().setStages(Array(assembler, kmeans))\n",
    "    \n",
    "    val pipelineModel = pipeline.fit(data)\n",
    "    \n",
    "    val kmeansModel = pipelineModel.stages.last.asInstanceOf[KMeansModel]\n",
    "    \n",
    "    kmeansModel.computeCost(pipelineModel.transform(data))/ data.count()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k_kScore1 = Vector((30,2.289764131601541E7), (60,8470305.30670904), (90,7095383.880835814), (120,4857860.611231016), (150,5993846.780990699), (180,5215423.540799868), (210,6989822.2398211965))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Vector((30,2.289764131601541E7), (60,8470305.30670904), (90,7095383.880835814), (120,4857860.611231016), (150,5993846.780990699), (180,5215423.540799868), (210,6989822.2398211965))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val k_kScore1 = (30 to 210 by 30).map(k => (k, clusterScore1(numericOnly, k))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clusterScore2: (data: org.apache.spark.sql.DataFrame, k: Int)Double\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clusterScore2(data: DataFrame, k: Int) = {\n",
    "    \n",
    "    val assembler = new VectorAssembler().setInputCols(data.columns.filter(_!=\"label\")).setOutputCol(\"featureVector\")\n",
    "    \n",
    "    val scalar = new StandardScaler().setInputCol(\"featureVector\").setOutputCol(\"scaledFeatureVector\").\n",
    "        setWithStd(true).\n",
    "        setWithMean(false)\n",
    "    \n",
    "     val kmeans = new KMeans().\n",
    "        setSeed(Random.nextLong()).\n",
    "        setK(k).\n",
    "        setMaxIter(40).\n",
    "        setTol(1.0e-5).\n",
    "        setFeaturesCol(\"scaledFeatureVector\").\n",
    "        setPredictionCol(\"cluster\")\n",
    "   \n",
    "    val pipeline = new Pipeline().setStages(Array(assembler, scalar, kmeans))\n",
    "    \n",
    "    val pipelineModel = pipeline.fit(data)\n",
    "    \n",
    "    val kmeansModel = pipelineModel.stages.last.asInstanceOf[KMeansModel]\n",
    "    \n",
    "    kmeansModel.computeCost(pipelineModel.transform(data))/ data.count()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k_kScore2 = Vector((30,5.030221895764377), (60,1.1585834080429747), (90,0.7305037798805409), (120,0.4999779246027878), (150,0.4005762879937056), (180,0.33266622855714906), (210,0.2796240282743122))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Vector((30,5.030221895764377), (60,1.1585834080429747), (90,0.7305037798805409), (120,0.4999779246027878), (150,0.4005762879937056), (180,0.33266622855714906), (210,0.2796240282743122))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val k_kScore2 = (30 to 210 by 30).map(k => (k, clusterScore2(numericOnly, k))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "warning: there was one deprecation warning; re-run with -deprecation for details\n",
       "oneHotPipeline: (inputCol: String)(org.apache.spark.ml.Pipeline, String)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer}\n",
    "\n",
    "def oneHotPipeline(inputCol: String):(Pipeline, String) = {\n",
    "    val indexer = new StringIndexer().setInputCol(inputCol).setOutputCol(inputCol + \"_indexed\")\n",
    "    val encoder = new OneHotEncoder().setInputCol(inputCol + \"_indexed\").setOutputCol(inputCol + \"_vec\")\n",
    "    val pipeline = new Pipeline().setStages(Array(indexer, encoder))\n",
    "    (pipeline, inputCol +\"_vec\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clusterScore3: (data: org.apache.spark.sql.DataFrame, k: Int)Double\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clusterScore3(data: DataFrame, k: Int) = {\n",
    "    \n",
    "    val (protoTypeEncoder, protoTypeVecCol) = oneHotPipeline(\"protocol_type\")\n",
    "    val (serviceEncoder, serviceVecCol) = oneHotPipeline(\"service\")\n",
    "    val (flagEncoder, flagVecCol) = oneHotPipeline(\"flag\")\n",
    "\n",
    "    // Original columns, without label / string columns, but with new vector encoded cols\n",
    "    val assembleCols = Set(data.columns: _*) --\n",
    "      Seq(\"label\", \"protocol_type\", \"service\", \"flag\")--\n",
    "      Seq(\"protocol_type_indexed\", \"service_indexed\", \"flag_indexed\") ++\n",
    "      Seq(protoTypeVecCol, serviceVecCol, flagVecCol)\n",
    "    \n",
    "    val assembler = new VectorAssembler().\n",
    "      setInputCols(assembleCols.toArray).\n",
    "      setOutputCol(\"featureVector\")\n",
    "    \n",
    "    val scalar = new StandardScaler().setInputCol(\"featureVector\").setOutputCol(\"scaledFeatureVector\").\n",
    "        setWithStd(true).\n",
    "        setWithMean(false)\n",
    "    \n",
    "     val kmeans = new KMeans().\n",
    "        setSeed(Random.nextLong()).\n",
    "        setK(k).\n",
    "        setMaxIter(40).\n",
    "        setTol(1.0e-5).\n",
    "        setPredictionCol(\"cluster\").\n",
    "        setFeaturesCol(\"scaledFeatureVector\")\n",
    "   \n",
    "    val pipeline = new Pipeline().setStages(\n",
    "      Array(protoTypeEncoder, serviceEncoder, flagEncoder, assembler, scalar, kmeans))\n",
    "    \n",
    "    val pipelineModel = pipeline.fit(data)\n",
    "    \n",
    "    val kmeansModel = pipelineModel.stages.last.asInstanceOf[KMeansModel]\n",
    "    \n",
    "    kmeansModel.computeCost(pipelineModel.transform(data))/ data.count()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k_kScore3 = Vector((30,67.9055123176595), (60,38.632426873025395), (90,16.138219633617414), (120,3.204927274610112), (150,2.313322225784033), (180,1.6983896850381774), (210,1.2994952266802888))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Vector((30,67.9055123176595), (60,38.632426873025395), (90,16.138219633617414), (120,3.204927274610112), (150,2.313322225784033), (180,1.6983896850381774), (210,1.2994952266802888))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val k_kScore3 = (30 to 210 by 30).map(k => (k, clusterScore3(dataDF, k))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//%AddDeps co.theasi plotly_2.11 0.2.0 --transitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from http://central.maven.org/maven2/co/theasi/plotly_2.11/0.2.0/plotly_2.11-0.2.0.jar\n",
      "Finished download of plotly_2.11-0.2.0.jar\n"
     ]
    }
   ],
   "source": [
    "%addjar http://central.maven.org/maven2/co/theasi/plotly_2.11/0.2.0/plotly_2.11-0.2.0.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import co.theasi.plotly._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:46: error: not found: value k_kScore1\n",
       "       val xs =  k_kScore1.map(_._1)\n",
       "                 ^\n",
       "<console>:47: error: not found: value k_kScore1\n",
       "       val ys =  k_kScore1.map(_._2)\n",
       "                 ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val xs =  k_kScore1.map(_._1)\n",
    "val ys =  k_kScore1.map(_._2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:46: error: not found: value xs\n",
       "Error occurred in an application involving default arguments.\n",
       "       val plot = Plot().withScatter(xs, ys)\n",
       "                                     ^\n",
       "<console>:46: error: not found: value ys\n",
       "Error occurred in an application involving default arguments.\n",
       "       val plot = Plot().withScatter(xs, ys)\n",
       "                                         ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val plot = Plot().withScatter(xs, ys)\n",
    "\n",
    "draw(plot, \"clustering_elbow_ch05_traffic_anamoly1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:46: error: not found: value k_kScore2\n",
       "       val xs =  k_kScore2.map(_._1)\n",
       "                 ^\n",
       "<console>:47: error: not found: value k_kScore2\n",
       "       val ys =  k_kScore2.map(_._2)\n",
       "                 ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val xs =  k_kScore2.map(_._1)\n",
    "val ys =  k_kScore2.map(_._2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:46: error: not found: value xs\n",
       "Error occurred in an application involving default arguments.\n",
       "       val plot = Plot().withScatter(xs, ys)\n",
       "                                     ^\n",
       "<console>:46: error: not found: value ys\n",
       "Error occurred in an application involving default arguments.\n",
       "       val plot = Plot().withScatter(xs, ys)\n",
       "                                         ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val plot = Plot().withScatter(xs, ys)\n",
    "\n",
    "draw(plot, \"clustering_elbow_ch05_traffic_anamoly2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:46: error: not found: value k_kScore3\n",
       "       val xs =  k_kScore3.map(_._1)\n",
       "                 ^\n",
       "<console>:47: error: not found: value k_kScore3\n",
       "       val ys =  k_kScore3.map(_._2)\n",
       "                 ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val xs =  k_kScore3.map(_._1)\n",
    "val ys =  k_kScore3.map(_._2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:46: error: not found: value xs\n",
       "Error occurred in an application involving default arguments.\n",
       "       val plot = Plot().withScatter(xs, ys)\n",
       "                                     ^\n",
       "<console>:46: error: not found: value ys\n",
       "Error occurred in an application involving default arguments.\n",
       "       val plot = Plot().withScatter(xs, ys)\n",
       "                                         ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val plot = Plot().withScatter(xs, ys)\n",
    "\n",
    "draw(plot, \"clustering_elbow_ch05_traffic_anamoly3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:47: error: not found: value sca\n",
       "       sca\n",
       "       ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sca"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark - Scala",
   "language": "scala",
   "name": "spark_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
