{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the clickstream of abc.com who's funnel is in order of pages\n",
    " listing -> review -> payments -> thankyou. \n",
    "\n",
    "Generate the data feed for Drop Off Notifications for Re-targeting users with their most recent and relevant intent (search criteria) of the user. \n",
    "\n",
    "Write code for this.\n",
    "\n",
    "Note:\n",
    "1) Intent is the search criteria for which customer is most likely to book\n",
    "2) Booking is confirmed on thankyou page.\n",
    "3) A search criteria is relevant when departure date is a future date that is greater than current date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getenv(\"HOME\") +\"/data/mmt_data/\"\n",
    "spark_home = \"/usr/hdp/current/spark2-client\"\n",
    "mode = \"local[*]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kranthidr/data/mmt_data/\n",
      "/usr/hdp/current/spark2-client\n"
     ]
    }
   ],
   "source": [
    "print(path)\n",
    "print(spark_home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/hdp/current/spark2-client'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init(spark_home)\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(mode).appName(\"clickStreamAnalysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://gw02.itversity.com:4044\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0.2.6.5.0-292</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>clickStreamAnalysis</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x76f86eeba750>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in sc._conf.getAll():\n",
    "    if '/proxy/' in x[1]:\n",
    "        print(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"file://\"+path+\"clickStream.csv\",header= True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userd id: string (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- destination: string (nullable = true)\n",
      " |-- departure date: string (nullable = true)\n",
      " |-- page name: string (nullable = true)\n",
      " |-- search date time: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----------+--------------+---------+----------------+\n",
      "|userd id|origin|destination|departure date|page name|search date time|\n",
      "+--------+------+-----------+--------------+---------+----------------+\n",
      "|      u1|   DEL|        BLR|     9/25/2018|  listing|  9/5/2018 10:00|\n",
      "|      u1|   DEL|        BLR|     9/25/2018|   review|  9/5/2018 10:00|\n",
      "|      u1|   DEL|        BLR|     9/25/2018| payments|  9/5/2018 10:01|\n",
      "|      u1|   DEL|        BLR|     9/24/2018|   review| 9/10/2018 16:01|\n",
      "|      u1|   DEL|        BLR|     9/25/2018|  listing| 9/10/2018 16:01|\n",
      "|      u1|   DEL|        BLR|     9/24/2018|  listing| 9/10/2018 16:00|\n",
      "|      u1|   DEL|        BLR|     9/25/2018|   review| 9/10/2018 16:01|\n",
      "|      u1|   DEL|        GOI|    12/25/2018| payments| 9/10/2018 16:03|\n",
      "|      u1|   DEL|        GOI|    12/25/2018|  listing| 9/10/2018 16:02|\n",
      "|      u1|   DEL|        GOI|    12/25/2018|   review| 9/10/2018 16:03|\n",
      "|      u1|   DEL|        GOI|    12/25/2018| thankyou| 9/10/2018 16:04|\n",
      "|      u1|   DEL|        BLR|     9/12/2018|  listing| 9/10/2018 20:00|\n",
      "|      u1|   DEL|        BLR|     9/12/2018| payments| 9/10/2018 20:01|\n",
      "|      u2|   DEL|        BOM|     9/25/2018|  listing| 9/10/2018 20:01|\n",
      "|      u2|   DEL|        BOM|     9/12/2018|  listing| 9/11/2018 20:02|\n",
      "|      u1|   DEL|        BLR|     9/12/2018|   review| 9/10/2018 20:01|\n",
      "+--------+------+-----------+--------------+---------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark2.7_home",
   "language": "python",
   "name": "pyspark2.7_home"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
