/*
1. Using sqoop, import orders table into hdfs to folders /user/cloudera/problem1/orders. File should be loaded as Avro File and use snappy compression
2. Using sqoop, import order_items  table into hdfs to folders /user/cloudera/problem1/order-items. Files should be loaded as avro file and use snappy compression

8. create a mysql table named result and load data from /user/cloudera/problem1/result4a-csv to mysql table named result 
*/

0.
hadoop fs -mkdir -p /user/kranthidr/arun/problem1

1.
sqoop import \
--connect 'jdbc:mysql://ms.itversity.com:3306/retail_db' --username retail_user --password itversity \
--table orders \
--target-dir '/user/kranthidr/arun/problem1/orders' \
--compress \
--compression-codec snappy \
--as-avrodatafile
/*
compression-codec snappy ----seems working
*/
2.
sqoop import \
--connect 'jdbc:mysql://ms.itversity.com:3306/retail_db' --username retail_user --password itversity \
--table order_items \
--target-dir '/user/kranthidr/arun/problem1/order-items' \
--compress \
--compression-codec org.apache.hadoop.io.compress.SnappyCodec \
--as-avrodatafile

avro-tools getmeta hdfs://nn01.itversity.com:8020/user/kranthidr/arun/problem1/orders/part-m-00000.avro
avro-tools getmeta hdfs://nn01.itversity.com:8020/user/kranthidr/arun/problem1/order-items/part-m-00000.avro

8.
mysql -h ms.itversity.com -uretail_user -pitversity
>>use retail_export;
>>create table kkd_result(order_date varchar(255), order_status varchar(255), total_orders int, total_amount double);

/*
create table kkd_result(
order_date varchar(255) not null,
order_status varchar(255) not null, 
total_orders int, 
total_amount numeric(8,2),
constraint pk_order_result primary key (order_date,order_status)
); 
# numeric(8,2) and decimal(8,2) both are same
*/

sqoop export \
--connect 'jdbc:mysql://ms.itversity.com:3306/retail_export' --username retail_user --password itversity \
--table kkd_result \
--columns 'order_date,order_status,total_orders,total_amount' \
--export-dir '/user/kranthidr/arun/problem1/result4a-csv'




