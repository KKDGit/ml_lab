prob6

hive -e "create database kkd_problem6 location '/user/cloudera/arun/kkd_problem6'"

sqoop import-all-tables \
--connect 'jdbc:mysql://quickstart.cloudera:3306/retail_db' --username root --password cloudera \
--hive-import --hive-database kkd_problem6 \
--num-mappers 1

spark.conf.set("spark.sql.shuffle.partitions",10)
spark.sql("use kkd_problem6")

val deps = spark.sql("select * from departments")
val cats = spark.sql("select * from categories")
val prods = spark.sql("select * from products")
val cust = spark.sql("select * from customers")
val ords = spark.sql("select * from orders")
val items = spark.sql("select * from order_items")

val join = prods.join(cats,'product_category_id === 'category_id).join(deps,'department_id === 'category_department_id).cache()

import org.apache.{spark => spr}

import spr.sql.expressions.Window

val win = Window.partitionBy('department_name).orderBy('product_price.desc)
val ran = rank().over(win).as("rank")

val op = join.select('*, ran).orderBy('department_name.asc, 'rank.desc)
//-------------------------------------------------------------------------
val join1 = cust.join(ords,'customer_id === 'order_customer_id).join(items,'order_id === 'order_item_order_id).cache()

val top10 = join1.groupBy('customer_id).agg(countDistinct('order_item_product_id).as("no_prods")).orderBy('no_prods.desc,'customer_id).limit(10)
//---------------------------------

val join2 = prods.join(cats,'product_category_id === 'category_id).join(deps,'department_id === 'category_department_id).filter("product_price < 100").cache()

val op_le100 = join2.select('*, ran).orderBy('department_name.asc, 'rank.desc)
//-------------------------------------------------------------------------
val join3 = cust.join(ords,'customer_id === 'order_customer_id).join(items,'order_id === 'order_item_order_id).filter("order_item_product_price < 100")cache()

val top10_le100 = join3.groupBy('customer_id).agg(countDistinct('order_item_product_id).as("no_prods")).orderBy('no_prods.desc,'customer_id).limit(10)

