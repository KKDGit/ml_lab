Problem 7:

1.
This step comprises of three substeps. Please perform tasks under each subset completely  
A.
using sqoop pull data from MYSQL orders table into /user/cloudera/problem7/prework as AVRO data file using only one mapper
B.
Pull the file from \user\cloudera\problem7\prework into a local folder named flume-avro
C.
create a flume agent configuration such that it has an avro source at localhost and port number 11112,  a jdbc channel and an hdfs file sink at /user/cloudera/problem7/sink
D.
Use the following command to run an avro client flume-ng avro-client -H localhost -p 11112 -F <<Provide your avro file path here>>

2.
The CDH comes prepackaged with a log generating job. start_logs, stop_logs and tail_logs. Using these as an aid and provide a solution to below problem. The generated logs can be found at path /opt/gen_logs/logs/access.log

A.
run start_logs
B.
write a flume configuration such that the logs generated by start_logs are dumped into HDFS at location /user/cloudera/problem7/step2. The channel should be non-durable and hence fastest in nature. The channel should be able to hold a maximum of 1000 messages and should commit after every 200 messages. 
C.
Run the agent. 
D.
confirm if logs are getting dumped to hdfs.  
E.
run stop_logs.